#!/usr/bin/env python3
"""
æœªè®­ç»ƒåŒ…æ£€æµ‹å·¥å…·
ç”¨äºæ£€æµ‹å“ªäº›åŒ…è¿˜æ²¡æœ‰å¯¹åº”çš„LoRAæ¨¡å‹ï¼Œå¸®åŠ©è§„åˆ’è®­ç»ƒä»»åŠ¡
"""

import os
import json
import argparse
import logging
from datetime import datetime
from collections import defaultdict

# å¯¼å…¥å¿…è¦çš„æ¨¡å—
from utils.getDatasetPacks import getPackVersions
from utils.loraTrain.loraTrainUtils import loraModelExists
from benchmark.config.code.config_lora import LORA_CONFIG_PATH, load_config
from utils.loraPathConfigure import pathConfigurator

def setup_logging():
    """è®¾ç½®æ—¥å¿—é…ç½®"""
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s',
        handlers=[
            logging.StreamHandler()
        ]
    )

def load_package_versions(benchmark_data_path):
    """
    ä»benchmarkæ•°æ®ä¸­åŠ è½½åŒ…ç‰ˆæœ¬ä¿¡æ¯
    
    Args:
        benchmark_data_path: benchmarkæ•°æ®æ–‡ä»¶è·¯å¾„
        
    Returns:
        dict: åŒ…ç‰ˆæœ¬ä¿¡æ¯ {pkg: [version1, version2, ...]}
    """
    try:
        with open(benchmark_data_path, "r") as f:
            datas = json.load(f)
        
        pack_versions = getPackVersions(datas)
        logging.info(f"ä» {benchmark_data_path} åŠ è½½äº† {len(pack_versions)} ä¸ªåŒ…")
        
        total_versions = sum(len(versions) for versions in pack_versions.values())
        logging.info(f"æ€»è®¡ {total_versions} ä¸ªåŒ…ç‰ˆæœ¬ç»„åˆ")
        
        return pack_versions
        
    except Exception as e:
        logging.error(f"åŠ è½½åŒ…ç‰ˆæœ¬ä¿¡æ¯å¤±è´¥: {e}")
        return {}

def check_package_models(pack_versions, model_name, config, knowledge_types=['docstring', 'srccodes']):
    """
    æ£€æŸ¥åŒ…æ¨¡å‹çš„å­˜åœ¨æƒ…å†µ
    
    Args:
        pack_versions: åŒ…ç‰ˆæœ¬ä¿¡æ¯
        model_name: æ¨¡å‹åç§°
        config: é…ç½®ä¿¡æ¯
        knowledge_types: è¦æ£€æŸ¥çš„çŸ¥è¯†ç±»å‹åˆ—è¡¨
        
    Returns:
        dict: æ£€æŸ¥ç»“æœ
    """
    results = {}
    
    for knowledge_type in knowledge_types:
        logging.info(f"\n=== æ£€æŸ¥ {knowledge_type} æ¨¡å‹ ===")
        
        existing_packages = []
        missing_packages = []
        error_packages = []
        
        for pkg, versions in pack_versions.items():
            for version in versions:
                try:
                    if loraModelExists(pkg, version,model_name,config,knowledge_type): # , model_name, config, knowledge_type
                        existing_packages.append((pkg, version))
                        logging.debug(f"âœ“ {pkg}-{version} ({knowledge_type}) - æ¨¡å‹å­˜åœ¨")
                    else:
                        missing_packages.append((pkg, version))
                        logging.debug(f"âœ— {pkg}-{version} ({knowledge_type}) - æ¨¡å‹ç¼ºå¤±")
                        
                except Exception as e:
                    error_packages.append((pkg, version, str(e)))
                    logging.warning(f"âš  {pkg}-{version} ({knowledge_type}) - æ£€æŸ¥å‡ºé”™: {e}")
        
        results[knowledge_type] = {
            'existing': existing_packages,
            'missing': missing_packages,
            'errors': error_packages,
            'total': len(existing_packages) + len(missing_packages) + len(error_packages)
        }
        
        logging.info(f"{knowledge_type} ç»Ÿè®¡:")
        logging.info(f"  å·²å­˜åœ¨: {len(existing_packages)}")
        logging.info(f"  ç¼ºå¤±: {len(missing_packages)}")
        logging.info(f"  é”™è¯¯: {len(error_packages)}")
        logging.info(f"  æ€»è®¡: {results[knowledge_type]['total']}")
    
    return results

def generate_training_plan(results, knowledge_types):
    """
    ç”Ÿæˆè®­ç»ƒè®¡åˆ’
    
    Args:
        results: æ£€æŸ¥ç»“æœ
        knowledge_types: çŸ¥è¯†ç±»å‹åˆ—è¡¨
        
    Returns:
        dict: è®­ç»ƒè®¡åˆ’
    """
    plan = {}
    
    for knowledge_type in knowledge_types:
        if knowledge_type not in results:
            continue
            
        missing = results[knowledge_type]['missing']
        
        # æŒ‰åŒ…åˆ†ç»„
        packages_to_train = defaultdict(list)
        for pkg, version in missing:
            packages_to_train[pkg].append(version)
        
        plan[knowledge_type] = {
            'packages_count': len(packages_to_train),
            'versions_count': len(missing),
            'packages': dict(packages_to_train)
        }
    
    return plan

def save_results_to_file(results, plan, output_file):
    """
    å°†ç»“æœä¿å­˜åˆ°æ–‡ä»¶
    
    Args:
        results: æ£€æŸ¥ç»“æœ
        plan: è®­ç»ƒè®¡åˆ’
        output_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„
    """
    report = {
        'timestamp': datetime.now().isoformat(),
        'summary': {},
        'detailed_results': results,
        'training_plan': plan
    }
    
    # ç”Ÿæˆæ‘˜è¦
    for knowledge_type, result in results.items():
        report['summary'][knowledge_type] = {
            'total_packages': result['total'],
            'existing_packages': len(result['existing']),
            'missing_packages': len(result['missing']),
            'error_packages': len(result['errors']),
            'completion_rate': f"{len(result['existing']) / result['total'] * 100:.1f}%" if result['total'] > 0 else "0.0%"
        }
    
    try:
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        logging.info(f"ç»“æœå·²ä¿å­˜åˆ°: {output_file}")
    except Exception as e:
        logging.error(f"ä¿å­˜ç»“æœæ–‡ä»¶å¤±è´¥: {e}")

def print_summary(results, plan):
    """
    æ‰“å°æ‘˜è¦ä¿¡æ¯
    """
    print("\n" + "=" * 60)
    print("æœªè®­ç»ƒåŒ…æ£€æµ‹ç»“æœæ‘˜è¦")
    print("=" * 60)
    
    for knowledge_type, result in results.items():
        total = result['total']
        existing = len(result['existing'])
        missing = len(result['missing'])
        errors = len(result['errors'])
        
        completion_rate = (existing / total * 100) if total > 0 else 0
        
        print(f"\nğŸ“Š {knowledge_type.upper()} æ¨¡å‹ç»Ÿè®¡:")
        print(f"  æ€»åŒ…æ•°: {total}")
        print(f"  å·²è®­ç»ƒ: {existing} ({completion_rate:.1f}%)")
        print(f"  æœªè®­ç»ƒ: {missing}")
        print(f"  æ£€æŸ¥é”™è¯¯: {errors}")
        
        if missing > 0:
            print(f"\nğŸ¯ {knowledge_type.upper()} è®­ç»ƒè®¡åˆ’:")
            pkg_plan = plan.get(knowledge_type, {})
            print(f"  éœ€è¦è®­ç»ƒçš„åŒ…: {pkg_plan.get('packages_count', 0)} ä¸ª")
            print(f"  éœ€è¦è®­ç»ƒçš„ç‰ˆæœ¬: {pkg_plan.get('versions_count', 0)} ä¸ª")
            
            if args.show_missing and 'packages' in pkg_plan:
                print(f"\nğŸ“ ç¼ºå¤±çš„åŒ…åˆ—è¡¨ ({knowledge_type}):")
                for pkg, versions in list(pkg_plan['packages'].items())[:10]:  # åªæ˜¾ç¤ºå‰10ä¸ª
                    versions_str = ', '.join(versions[:3])  # åªæ˜¾ç¤ºå‰3ä¸ªç‰ˆæœ¬
                    if len(versions) > 3:
                        versions_str += f" ... (å…±{len(versions)}ä¸ªç‰ˆæœ¬)"
                    print(f"    {pkg}: {versions_str}")
                
                if len(pkg_plan['packages']) > 10:
                    print(f"    ... è¿˜æœ‰ {len(pkg_plan['packages']) - 10} ä¸ªåŒ… (ä½¿ç”¨ --show-missing æŸ¥çœ‹å®Œæ•´åˆ—è¡¨)")

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="æ£€æµ‹æœªè®­ç»ƒçš„LoRAæ¨¡å‹åŒ…")
    parser.add_argument("--benchmark_data_path", type=str, 
                       default="benchmark/data/VersiBCB_Benchmark/vace_datas.json",
                       help="benchmarkæ•°æ®æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--model_name", type=str,
                       default="/datanfs2/chenrongyi/models/Llama-3.1-8B",
                       help="æ¨¡å‹åç§°")
    parser.add_argument("--knowledge_types", nargs='+', 
                       default=['docstring', 'srccodes'],
                       choices=['docstring', 'srccodes'],
                       help="è¦æ£€æŸ¥çš„çŸ¥è¯†ç±»å‹")
    parser.add_argument("--output_file", type=str,
                       default=None,
                       help="è¾“å‡ºç»“æœæ–‡ä»¶è·¯å¾„ (JSONæ ¼å¼)")
    parser.add_argument("--show_missing", action="store_true",
                       help="æ˜¾ç¤ºæ‰€æœ‰ç¼ºå¤±çš„åŒ…åˆ—è¡¨")
    parser.add_argument("--verbose", action="store_true",
                       help="æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯")
    
    global args
    args = parser.parse_args()
    
    # è®¾ç½®æ—¥å¿—çº§åˆ«
    if args.verbose:
        logging.getLogger().setLevel(logging.DEBUG)
    
    setup_logging()
    
    logging.info("å¼€å§‹æ£€æµ‹æœªè®­ç»ƒçš„LoRAæ¨¡å‹åŒ…...")
    logging.info(f"Benchmarkæ•°æ®: {args.benchmark_data_path}")
    logging.info(f"æ¨¡å‹åç§°: {args.model_name}")
    logging.info(f"çŸ¥è¯†ç±»å‹: {args.knowledge_types}")
    
    # åŠ è½½é…ç½®
    try:
        config = load_config(LORA_CONFIG_PATH)
        config["model_name"] = args.model_name
        logging.info("é…ç½®åŠ è½½æˆåŠŸ")
    except Exception as e:
        logging.error(f"é…ç½®åŠ è½½å¤±è´¥: {e}")
        return
    
    # è·å–æ¨¡å‹åç§°ï¼ˆç”¨äºè·¯å¾„æ£€æŸ¥ï¼‰
    model_name = args.model_name.split("/")[-1]
    
    # åŠ è½½åŒ…ç‰ˆæœ¬ä¿¡æ¯
    pack_versions = load_package_versions(args.benchmark_data_path)
    if not pack_versions:
        logging.error("æ— æ³•è·å–åŒ…ç‰ˆæœ¬ä¿¡æ¯ï¼Œé€€å‡º")
        return
    
    # æ£€æŸ¥æ¨¡å‹å­˜åœ¨æƒ…å†µ
    results = check_package_models(pack_versions, model_name, config, args.knowledge_types)
    
    # ç”Ÿæˆè®­ç»ƒè®¡åˆ’
    plan = generate_training_plan(results, args.knowledge_types)
    
    # æ‰“å°æ‘˜è¦
    print_summary(results, plan)
    
    # ä¿å­˜ç»“æœåˆ°æ–‡ä»¶
    if args.output_file:
        save_results_to_file(results, plan, args.output_file)
    else:
        # è‡ªåŠ¨ç”Ÿæˆè¾“å‡ºæ–‡ä»¶å
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        output_file = f"untrained_packages_report_{timestamp}.json"
        save_results_to_file(results, plan, output_file)
    
    print(f"\nâœ… æ£€æµ‹å®Œæˆï¼")

if __name__ == "__main__":
    main()