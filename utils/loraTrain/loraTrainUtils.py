from utils.loraPathConfigure import pathConfigurator
import os
import json
from utils.loraTrain.buildandloadData import TextDataset,collate_fn
from torch.utils.data import DataLoader
# from benchmark.config.code.config import CORPUS_PATH
from peft import get_peft_model, LoraConfig, TaskType, PeftModel
from tqdm import tqdm
import torch
from benchmark.config.code.config_lora import MODEL_SOURCE
if MODEL_SOURCE == "modelscope":
    from modelscope import AutoTokenizer
    from modelscope import Model
else:
    from transformers import AutoTokenizer
    from transformers import AutoModelForCausalLM as Model
from accelerate import load_checkpoint_and_dispatch
from benchmark.config.code.config_lora import LORA_CONFIG_PATH,load_config
from utils.loraTrain.buildandloadData import QADataset
import traceback
import requests
import time
from together import Together
import logging
from safetensors.torch import load_file
from utils.memoryDebug.memoryCheck import GPUMemoryProfiler
profiler = GPUMemoryProfiler()
# ä¿å­˜ LoRA æ¨¡å‹
def save_lora_model(lora_model, save_path):
    """ä¿å­˜ LoRA æ¨¡å‹"""
    lora_model.save_pretrained(save_path)

# åŠ è½½ LoRA æ¨¡å‹
def load_lora_model_withPeft(base_model, load_path):
    """åŠ è½½ LoRA æ¨¡å‹"""
    return PeftModel.from_pretrained(base_model, load_path)
# åŠ è½½åŸºç¡€æ¨¡å‹å’Œåˆ†è¯å™¨
# è®­ç»ƒ LoRA æ¨¡å‹
# åˆ›å»º LoRA é…ç½®
def create_lora_config(target_modules, layers_to_transform=[0,1,2], r=8, alpha=16):
    """åˆ›å»º LoRA é…ç½®"""
    # æ„å»º target_modules åˆ—è¡¨ï¼ŒåŒ…å«ç‰¹å®šå±‚çš„ç‰¹å®šæ¨¡å—
    # å¯¹äº Mistral MoEï¼Œæˆ‘ä»¬éœ€è¦é’ˆå¯¹ä¸“å®¶å±‚è¿›è¡Œé…ç½®
    return LoraConfig(
        task_type=TaskType.CAUSAL_LM,
        r=r,
        lora_alpha=alpha,
        layers_to_transform=layers_to_transform,
        target_modules=target_modules,
        lora_dropout=0.05,
        bias="none",
        modules_to_save=None,
    )
def train_lora_model(lora_model, dataloader, num_epochs=10, learning_rate=1e-3, train_config=None,output_adaptor_path=None):
    """
    è®­ç»ƒå› æœè¯­è¨€æ¨¡å‹çš„LoRAé€‚é…å™¨
    
    Args:
        lora_model: LoRAæ¨¡å‹å®ä¾‹
        dataloader: è®­ç»ƒæ•°æ®åŠ è½½å™¨
        num_epochs: è®­ç»ƒè½®æ•°
        learning_rate: å­¦ä¹ ç‡
        config: è®­ç»ƒé…ç½®å­—å…¸ï¼ŒåŒ…å«ä»¥ä¸‹å¯é€‰å‚æ•°:
            - target_batch_size (int): ç›®æ ‡æ‰¹æ¬¡å¤§å°ï¼Œç”¨äºæ¢¯åº¦ç´¯ç§¯è®¡ç®—ï¼Œé»˜è®¤16
            - precision (str): è®­ç»ƒç²¾åº¦ï¼Œå¯é€‰["float32", "float16", "bfloat16"]ï¼Œé»˜è®¤"float32"
            - save_path_base (str): ä¿å­˜è·¯å¾„åŸºç¡€ç›®å½•ï¼Œé»˜è®¤"/datanfs2/chenrongyi/models/versiBCB"
            - å…¶ä»–å‚æ•°ä¼šè¢«å¿½ç•¥ï¼Œä¸å½±å“è®­ç»ƒè¿‡ç¨‹
        output_adaptor_path: è¾“å‡ºé€‚é…å™¨è·¯å¾„
        
    Returns:
        lora_model: è®­ç»ƒå¥½çš„LoRAæ¨¡å‹
        
    Note:
        æ­¤å‡½æ•°ä¸“æ³¨äºè®­ç»ƒè¿‡ç¨‹ï¼Œconfigä¸­åªä½¿ç”¨è®­ç»ƒç›¸å…³çš„å‚æ•°ã€‚
        è·¯å¾„ç›¸å…³çš„å‚æ•°(å¦‚model_name, knowledge_typeç­‰)åº”åœ¨è°ƒç”¨æ­¤å‡½æ•°å‰å¤„ç†å¥½ã€‚
    """
    from llmfoundry.optim import DecoupledLionW
    import os
    
    # å°è¯•å¯¼å…¥matplotlibï¼Œå¦‚æœå¤±è´¥åˆ™ç¦ç”¨ç»˜å›¾åŠŸèƒ½
    try:
        import matplotlib
        matplotlib.use('Agg')  # è®¾ç½®ä¸ºéäº¤äº’å¼åç«¯
        import matplotlib.pyplot as plt
        plotting_enabled = True
    except ImportError:
        print("è­¦å‘Šï¼šæ— æ³•å¯¼å…¥matplotlibï¼ŒæŸå¤±æ›²çº¿ç»˜å›¾åŠŸèƒ½å°†è¢«ç¦ç”¨ã€‚")
        print("å¯ä»¥å°è¯•è¿è¡Œ 'pip install matplotlib' æ¥å¯ç”¨æŸå¤±æ›²çº¿ç»˜å›¾åŠŸèƒ½ã€‚")
        plotting_enabled = False
    
    # ä½¿ç”¨ DecoupledLionW ä¼˜åŒ–å™¨
    optimizer = DecoupledLionW(
        lora_model.parameters(),
        lr=float(learning_rate),
        betas=(0.9, 0.95),
        weight_decay=1e-6
    )
    
    # ç®€åŒ–è®¾å¤‡æ£€æŸ¥ - åªæ‰“å°åŸºæœ¬ä¿¡æ¯
    print("æ¨¡å‹è®¾å¤‡ä¿¡æ¯:")
    if hasattr(lora_model, 'hf_device_map'):
        print(f"è®¾å¤‡æ˜ å°„: {lora_model.hf_device_map}")
    else:
        first_param_device = next(lora_model.parameters()).device
        print(f"æ¨¡å‹è®¾å¤‡: {first_param_device}")
    
    # æ¢¯åº¦ç´¯ç§¯è®¾ç½®
    actual_batch_size = dataloader.batch_size
    target_batch_size = 16  # é»˜è®¤ç›®æ ‡æ‰¹æ¬¡å¤§å°
    
    # å¦‚æœæä¾›äº†configï¼Œä»ä¸­è¯»å–ç›®æ ‡æ‰¹æ¬¡å¤§å°
    if train_config and "target_batch_size" in train_config:
        target_batch_size = train_config["target_batch_size"]
        print(f"ä»é…ç½®ä¸­è¯»å–ç›®æ ‡æ‰¹æ¬¡å¤§å°: {target_batch_size}")
    
    accumulation_steps = max(1, target_batch_size // actual_batch_size)
    print(f"ä½¿ç”¨æ¢¯åº¦ç´¯ç§¯: å®é™…æ‰¹æ¬¡å¤§å°={actual_batch_size}, ç›®æ ‡æ‰¹æ¬¡å¤§å°={target_batch_size}, ç´¯ç§¯æ­¥æ•°={accumulation_steps}")
    
    # åˆ›å»ºä¿å­˜æ—¥å¿—å’Œæ¨¡å‹çš„ç›®å½•
    save_path_base = train_config.get("save_path_base", "/datanfs2/chenrongyi/models/versiBCB") if train_config else "/datanfs2/chenrongyi/models/versiBCB"
    log_dir = os.path.join(output_adaptor_path, "training_logs")
    checkpoint_dir = os.path.join(output_adaptor_path, "checkpoints")
    os.makedirs(log_dir, exist_ok=True)
    os.makedirs(checkpoint_dir, exist_ok=True)
    
    # ä¸ºæœ¬æ¬¡è®­ç»ƒåˆ›å»ºå”¯ä¸€çš„æ—¶é—´æˆ³
    from datetime import datetime
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    
    # åˆ›å»ºæ—¥å¿—æ–‡ä»¶è·¯å¾„å’Œcheckpointè·¯å¾„åŸºç¡€
    log_file = os.path.join(log_dir, f"training_log_{timestamp}.csv")
    log_plot = os.path.join(log_dir, f"loss_curve_{timestamp}.png")
    checkpoint_base = os.path.join(checkpoint_dir, f"checkpoint_{timestamp}")
    
    # åˆå§‹åŒ–æŸå¤±è®°å½•
    epoch_losses = []
    step_losses = []
    
    # åˆå§‹åŒ–batchçº§åˆ«çš„æŸå¤±è®°å½•
    batch_losses = []  # è®°å½•æ¯ä¸ªbatchçš„loss
    
    # å†™å…¥æ—¥å¿—æ–‡ä»¶å¤´
    with open(log_file, "w") as f:
        f.write("epoch,step,batch,loss\n")
    
    for epoch in tqdm(range(num_epochs)):
        total_loss = 0
        batch_count = 0
        valid_batch_count = 0  # Count of batches with valid (non-NaN) losses
        step_count = 0
        epoch_step_losses = []  # è®°å½•å½“å‰epochçš„æ¯ä¸ªstepçš„loss
        
        # åœ¨æ¯ä¸ªepochå¼€å§‹å‰æ¸…é›¶æ¢¯åº¦
        optimizer.zero_grad()
        
        for batch in tqdm(dataloader):
            profiler.record("è®­ç»ƒæ¨¡å‹")
            # æå–batchæ•°æ®
            
            inputs = batch["input_ids"]
            labels = batch["labels"]
            attention_mask = batch["attention_mask"]
            
            # æ‰“å°è¾“å…¥æ•°æ®ç»´åº¦ä¿¡æ¯
            print(f"ğŸ“Š Epoch {epoch+1}, Batch {batch_count+1} è¾“å…¥ç»´åº¦:")
            print(f"  input_ids: {inputs.shape} (dtype: {inputs.dtype})")
            print(f"  labels: {labels.shape} (dtype: {labels.dtype})")
            print(f"  attention_mask: {attention_mask.shape} (dtype: {attention_mask.dtype})")
            print(f"  è®¾å¤‡: {inputs.device}")
            
            # ç®€åŒ–è®¾å¤‡å¤„ç† - è®©æ¨¡å‹è‡ªå·±å¤„ç†è®¾å¤‡åˆ†é…
            # ä¸æ‰‹åŠ¨ç§»åŠ¨æ•°æ®ï¼Œè®©transformersçš„device_mapè‡ªåŠ¨å¤„ç†
            
            # è·å–ç²¾åº¦è®¾ç½®
            # precision = train_config.get("precision")
            # torch_dtype = torch.float32
            # if precision == "float16":
            #     torch_dtype = torch.float16
            # elif precision == "bfloat16":
            #     torch_dtype = torch.bfloat16
            
            try:
                profiler.record("å‰å‘ä¼ æ’­ä¹‹å‰")
                # å‰å‘ä¼ æ’­ - ä½¿ç”¨autocastä½†è®©æ¨¡å‹è‡ªå·±å¤„ç†è®¾å¤‡
                # with torch.amp.autocast(device_type='cuda', dtype=torch_dtype, enabled=torch.cuda.is_available()):
                    
                outputs = lora_model(
                    input_ids=inputs,
                    attention_mask=attention_mask,
                    labels=labels
                )
                print(f"ğŸ“Š Epoch {epoch+1}, Batch {batch_count+1} è¾“å…¥ç»´åº¦:")
                print(f"  input_ids: {inputs.shape} (dtype: {inputs.dtype})")
                print(f"  labels: {labels.shape} (dtype: {labels.dtype})")
                print(f"  attention_mask: {attention_mask.shape} (dtype: {attention_mask.dtype})")
                print(f"  è®¾å¤‡: {inputs.device}")
                            
                profiler.record("å‰å‘ä¼ æ’­ä¹‹å")
                loss = outputs.loss
                loss = loss / accumulation_steps
                
                # åå‘ä¼ æ’­
                profiler.record("åå‘ä¼ æ’­ä¹‹å‰")
                loss.backward()
                profiler.record("åå‘ä¼ æ’­ä¹‹å")
                # æ›´æ–°ç´¯ç§¯æŸå¤±ï¼ˆç”¨äºæ—¥å¿—è®°å½•ï¼‰
                current_loss = loss.item() * accumulation_steps  # æ¢å¤åŸå§‹æŸå¤±å¤§å°ç”¨äºè®°å½•
                
                # æ£€æŸ¥lossæ˜¯å¦ä¸ºNaNï¼Œåªæœ‰éNaNå€¼æ‰è®¡å…¥å¹³å‡å€¼
                if not torch.isnan(loss) and not torch.isinf(loss):
                    total_loss += current_loss
                    valid_batch_count += 1
                    # è®°å½•æ¯ä¸ªbatchçš„loss
                    batch_losses.append(current_loss)
                else:
                    print(f"Warning: NaN or Inf loss detected in Epoch {epoch+1}, Batch {batch_count+1}. Ignoring this batch for average calculation.")
                
                batch_count += 1
                step_count += 1
                
                # æ¯ä¸ªbatchéƒ½è¾“å‡ºå½“å‰batchçš„loss
                if batch_count % 10 == 0:  # æ¯10ä¸ªbatchè¾“å‡ºä¸€æ¬¡ï¼Œå‡å°‘è¾“å‡ºé¢‘ç‡
                    print(f"Epoch {epoch+1}/{num_epochs}, Batch {batch_count}/{len(dataloader)}, Current Batch Loss: {current_loss:.4f}")
                
                # æ¯accumulation_stepsæ­¥æ›´æ–°ä¸€æ¬¡å‚æ•°
                if step_count % accumulation_steps == 0 or batch_count == len(dataloader):
                    # æ¢¯åº¦è£å‰ªï¼Œé˜²æ­¢æ¢¯åº¦çˆ†ç‚¸
                    torch.nn.utils.clip_grad_norm_(lora_model.parameters(), max_norm=1.0)
                    
                    # å‚æ•°æ›´æ–°
                    optimizer.step()
                    optimizer.zero_grad()
                    
                    # é‡Šæ”¾æœªä½¿ç”¨çš„GPUå†…å­˜ç¼“å­˜
                    if torch.cuda.is_available():
                        torch.cuda.empty_cache()
                    
                    # è®¡ç®—å½“å‰æ­¥éª¤çš„å¹³å‡æŸå¤±ï¼Œåªä½¿ç”¨æœ‰æ•ˆçš„batch
                    if valid_batch_count > 0:
                        avg_loss = total_loss / valid_batch_count
                    else:
                        avg_loss = float('nan')  # å¦‚æœæ²¡æœ‰æœ‰æ•ˆbatchï¼Œè®¾ç½®ä¸ºNaN
                    
                    if not torch.isnan(torch.tensor(avg_loss)) and not torch.isinf(torch.tensor(avg_loss)):
                        epoch_step_losses.append(avg_loss)
                        step_losses.append(avg_loss)
                    
                    # è®°å½•åˆ°æ—¥å¿—æ–‡ä»¶
                    with open(log_file, "a") as f:
                        f.write(f"{epoch+1},{step_count // accumulation_steps},{batch_count},{avg_loss:.6f}\n")
                    
                    # æ¯2ä¸ªæ›´æ–°æ­¥éª¤è¾“å‡ºä¸€æ¬¡å½“å‰avg loss
                    if (step_count // accumulation_steps) % 2 == 0:
                        print(f"Epoch {epoch+1}/{num_epochs}, Step {step_count // accumulation_steps}, Batch {batch_count}/{len(dataloader)}, Avg Loss: {avg_loss:.4f}")
                
            except RuntimeError as e:
                if "expected all tensors to be on the same device" in str(e).lower():
                    print(f"è®¾å¤‡ä¸ä¸€è‡´é”™è¯¯: {e}")
                    print("è·³è¿‡æ­¤batchå¹¶ç»§ç»­è®­ç»ƒ...")
                    
                    # è·³è¿‡è¿™ä¸ªbatch
                    print(f"è·³è¿‡ Epoch {epoch+1}, Batch {batch_count+1} ç”±äºè®¾å¤‡ä¸ä¸€è‡´é”™è¯¯")
                    batch_count += 1
                    step_count += 1
                    
                    # æ¸…ç†æ¢¯åº¦
                    optimizer.zero_grad()
                    
                    # ç»§ç»­ä¸‹ä¸€ä¸ªbatch
                    continue
                elif "out of memory" in str(e).lower():
                    print(f"GPUå†…å­˜ä¸è¶³: {e}")
                    print("æ¸…ç†ç¼“å­˜å¹¶è·³è¿‡æ­¤batch...")
                    torch.cuda.empty_cache()
                    
                    batch_count += 1
                    step_count += 1
                    optimizer.zero_grad()
                    continue
                else:
                    # å…¶ä»–RuntimeErrorï¼Œæ·»åŠ tracebackå¹¶é‡æ–°æŠ›å‡º
                    print(f"è®­ç»ƒè¿‡ç¨‹ä¸­å‡ºç°RuntimeError: {e}")
                    traceback.print_exc()
                    raise e
        
        # è®¡ç®—å¹¶å­˜å‚¨æ­¤epochçš„å¹³å‡æŸå¤±
        avg_epoch_loss = total_loss / max(1, valid_batch_count)  # ä½¿ç”¨æœ‰æ•ˆbatchæ•°é‡
        epoch_losses.append(avg_epoch_loss)
        print(f"Epoch {epoch+1}/{num_epochs}, Average Loss: {avg_epoch_loss:.4f} (åŸºäº {valid_batch_count} ä¸ªæœ‰æ•ˆbatch)")
        
        # æ¯2ä¸ªepochä¿å­˜ä¸€æ¬¡æ¨¡å‹
        if (epoch + 1) % 2 == 0 or epoch == num_epochs - 1:
            checkpoint_path = f"{checkpoint_base}_epoch{epoch+1}"
            os.makedirs(checkpoint_path, exist_ok=True)
            print(f"ä¿å­˜ä¸­é—´æ£€æŸ¥ç‚¹åˆ° {checkpoint_path}")
            lora_model.save_pretrained(checkpoint_path)
            
            # ä¿å­˜æœ€æ–°çš„æŸå¤±æ›²çº¿å›¾
            if plotting_enabled:
                try:
                    plt.figure(figsize=(12, 8))
                    
                    # ç»˜åˆ¶EpochæŸå¤±æ›²çº¿
                    plt.subplot(2, 2, 1)
                    plt.plot(range(1, len(epoch_losses) + 1), epoch_losses, marker='o')
                    plt.title('Epoch Average Loss')
                    plt.xlabel('Epoch')
                    plt.ylabel('Loss')
                    plt.grid(True)
                    
                    # ç»˜åˆ¶StepæŸå¤±æ›²çº¿
                    plt.subplot(2, 2, 2)
                    plt.plot(step_losses, marker='.', linestyle='-', alpha=0.5)
                    plt.title('Training Loss per Step')
                    plt.xlabel('Step')
                    plt.ylabel('Loss')
                    plt.grid(True)
                    
                    # ç»˜åˆ¶BatchæŸå¤±æ›²çº¿
                    plt.subplot(2, 2, 3)
                    plt.plot(batch_losses, marker='.', linestyle='-', alpha=0.3, color='red')
                    plt.title('Training Loss per Batch')
                    plt.xlabel('Batch')
                    plt.ylabel('Loss')
                    plt.grid(True)
                    
                    # å¹³æ»‘çš„BatchæŸå¤±æ›²çº¿ï¼ˆä½¿ç”¨ç§»åŠ¨å¹³å‡ï¼‰
                    if len(batch_losses) > 10:
                        window_size = min(10, len(batch_losses) // 5)
                        if window_size > 0:
                            import numpy as np
                            smooth_losses = np.convolve(batch_losses, np.ones(window_size)/window_size, mode='valid')
                            plt.subplot(2, 2, 4)
                            plt.plot(smooth_losses, marker='', linestyle='-', color='green')
                            plt.title(f'Smoothed Batch Loss (Window={window_size})')
                            plt.xlabel('Batch')
                            plt.ylabel('Loss')
                            plt.grid(True)
                    
                    plt.tight_layout()
                    plt.savefig(log_plot)
                    plt.close()
                    
                    print(f"æŸå¤±æ›²çº¿å·²ä¿å­˜åˆ° {log_plot}")
                except Exception as e:
                    print(f"ç»˜åˆ¶æŸå¤±æ›²çº¿æ—¶å‡ºé”™: {e}")
    
    # è®­ç»ƒç»“æŸï¼Œä¿å­˜æœ€ç»ˆçš„æŸå¤±æ›²çº¿
    if plotting_enabled:
        try:
            plt.figure(figsize=(12, 8))
            
            # ç»˜åˆ¶EpochæŸå¤±æ›²çº¿
            plt.subplot(2, 2, 1)
            plt.plot(range(1, len(epoch_losses) + 1), epoch_losses, marker='o')
            plt.title('Epoch Average Loss')
            plt.xlabel('Epoch')
            plt.ylabel('Loss')
            plt.grid(True)
            
            # ç»˜åˆ¶StepæŸå¤±æ›²çº¿
            plt.subplot(2, 2, 2)
            plt.plot(step_losses, marker='.', linestyle='-', alpha=0.5)
            plt.title('Training Loss per Step')
            plt.xlabel('Step')
            plt.ylabel('Loss')
            plt.grid(True)
            
            # ç»˜åˆ¶BatchæŸå¤±æ›²çº¿
            plt.subplot(2, 2, 3)
            plt.plot(batch_losses, marker='.', linestyle='-', alpha=0.3, color='red')
            plt.title('Training Loss per Batch')
            plt.xlabel('Batch')
            plt.ylabel('Loss')
            plt.grid(True)
            
            # å¹³æ»‘çš„BatchæŸå¤±æ›²çº¿ï¼ˆä½¿ç”¨ç§»åŠ¨å¹³å‡ï¼‰
            if len(batch_losses) > 10:
                window_size = min(10, len(batch_losses) // 5)
                if window_size > 0:
                    import numpy as np
                    smooth_losses = np.convolve(batch_losses, np.ones(window_size)/window_size, mode='valid')
                    plt.subplot(2, 2, 4)
                    plt.plot(smooth_losses, marker='', linestyle='-', color='green')
                    plt.title(f'Smoothed Batch Loss (Window={window_size})')
                    plt.xlabel('Batch')
                    plt.ylabel('Loss')
                    plt.grid(True)
            
            plt.tight_layout()
            plt.savefig(log_plot)
            plt.close()
            
            print(f"è®­ç»ƒå®Œæˆã€‚æœ€ç»ˆæŸå¤±æ›²çº¿å·²ä¿å­˜åˆ° {log_plot}")
        except Exception as e:
            print(f"ç»˜åˆ¶æœ€ç»ˆæŸå¤±æ›²çº¿æ—¶å‡ºé”™: {e}")
    else:
        print("è®­ç»ƒå®Œæˆã€‚ç”±äºmatplotlibä¸å¯ç”¨ï¼ŒæŸå¤±æ›²çº¿æœªç»˜åˆ¶ã€‚")
    
    return lora_model

def loadTokenizer(model_name_or_path):
    tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)
    return tokenizer
def str2dtype(precision):
    """æ ¹æ®ç²¾åº¦å­—ç¬¦ä¸²è¿”å›å¯¹åº”çš„torchæ•°æ®ç±»å‹"""
    if precision == 'fp16':
        return torch.float16
    elif precision == 'fp32':
        return torch.float32
    elif precision == 'bf16':
        return torch.bfloat16
    else:
        print(f"è­¦å‘Š: ä¸æ”¯æŒçš„ç²¾åº¦ '{precision}'ï¼Œä½¿ç”¨é»˜è®¤ç²¾åº¦ fp16")
        return torch.float16
def load_base_model(model_name_or_path, device_map="auto", precision_from_arg='fp16', force_gpu=False):
    """åŠ è½½åŸºç¡€æ¨¡å‹å’Œåˆ†è¯å™¨
    
    Args:
        model_name_or_path: str, æ¨¡å‹åç§°æˆ–è·¯å¾„
        device_map: str or dict, è®¾å¤‡æ˜ å°„ç­–ç•¥ã€‚ç›´æ¥ä½¿ç”¨"auto"è¿›è¡Œè‡ªåŠ¨åˆ†é…
        precision: str, æ¨¡å‹ç²¾åº¦ ('fp16', 'fp32', 'bf16')
        force_gpu: bool, å¼ºåˆ¶å°†æ•´ä¸ªæ¨¡å‹åŠ è½½åˆ°GPUä¸Šï¼Œä¼˜å…ˆé€‰æ‹©å†…å­˜æœ€å¤šçš„GPU
    
    Returns:
        model: åŠ è½½çš„æ¨¡å‹
        tokenizer: åŠ è½½çš„åˆ†è¯å™¨
    """

    
    def get_best_gpu():
        """è·å–å¯ç”¨å†…å­˜æœ€å¤šçš„GPU"""
        if not torch.cuda.is_available():
            return None
            
        best_gpu = 0
        max_free_memory = 0
        
        for i in range(torch.cuda.device_count()):
            try:
                # æ¸…ç†GPUç¼“å­˜ä»¥è·å¾—å‡†ç¡®çš„å†…å­˜ä¿¡æ¯
                torch.cuda.set_device(i)
                torch.cuda.empty_cache()
                
                total_memory = torch.cuda.get_device_properties(i).total_memory
                allocated_memory = torch.cuda.memory_allocated(i)
                reserved_memory = torch.cuda.memory_reserved(i)
                free_memory = total_memory - max(allocated_memory, reserved_memory)
                
                print(f"GPU {i}: {free_memory/(1024**3):.1f}GB free / {total_memory/(1024**3):.1f}GB total")
                
                if free_memory > max_free_memory:
                    max_free_memory = free_memory
                    best_gpu = i
                    
            except Exception as e:
                print(f"æ£€æŸ¥GPU {i} æ—¶å‡ºé”™: {e}")
                continue
                
        print(f"é€‰æ‹©GPU {best_gpu}ï¼Œå¯ç”¨å†…å­˜: {max_free_memory/(1024**3):.1f}GB")
        return best_gpu
    
    config = load_config(LORA_CONFIG_PATH)
    if precision_from_arg:
        precision = precision_from_arg
    else:
        precision = config.get("precison","fp16")

    print(f"åŠ è½½åŸºç¡€æ¨¡å‹: {model_name_or_path}")
    print(f"å¼ºåˆ¶GPUæ¨¡å¼: {force_gpu}")
    
    # åŠ è½½tokenizer
    tokenizer = AutoTokenizer.from_pretrained(model_name_or_path, trust_remote_code=True)
    
    # ä¸º Mistral/CodeGemma ç­‰æ¨¡å‹è®¾ç½® padding token
    if tokenizer.pad_token is None:
        tokenizer.pad_token = tokenizer.eos_token
        print("è®¾ç½® pad_token = eos_token")
    
    # è·å– GPU ä¿¡æ¯
    gpu_count = torch.cuda.device_count()
    print(f"å¯ç”¨GPUæ•°é‡: {gpu_count}")
    
    # ç¡®å®šè®¾å¤‡æ˜ å°„ç­–ç•¥
    if force_gpu and torch.cuda.is_available():
        best_gpu = get_best_gpu()
        if best_gpu is not None:
            # å¼ºåˆ¶ä½¿ç”¨ç‰¹å®šGPU
            optimized_device_map = {"": best_gpu}
            print(f"å¼ºåˆ¶GPUæ¨¡å¼ï¼šå°†æ•´ä¸ªæ¨¡å‹åŠ è½½åˆ°GPU {best_gpu}")
        else:
            print("è­¦å‘Šï¼šæ— æ³•æ‰¾åˆ°åˆé€‚çš„GPUï¼Œå›é€€åˆ°autoæ¨¡å¼")
            optimized_device_map = device_map
    else:
        optimized_device_map = device_map
        print(f"ä½¿ç”¨è®¾å¤‡æ˜ å°„ç­–ç•¥: {optimized_device_map}")
    
    try:
        # æ£€æŸ¥å†…å­˜æƒ…å†µ
        for i in range(gpu_count):
            free_mem = torch.cuda.get_device_properties(i).total_memory - torch.cuda.memory_allocated(i)
            free_mem_gb = free_mem / (1024**3)
            print(f"GPU {i} å¯ç”¨å†…å­˜: {free_mem_gb:.2f} GB")
    except Exception as e:
        print(f"è·å–GPUå†…å­˜ä¿¡æ¯æ—¶å‡ºé”™: {e}")
    
    print(f"ä½¿ç”¨æ¨¡å‹ç²¾åº¦: {precision}")
    
    # ç®€åŒ–çš„æ¨¡å‹åŠ è½½æ–¹å¼ - ç›´æ¥ä½¿ç”¨AutoModelForCausalLMçš„device_map
    torch_dtype = str2dtype(precision)
    print(f"ä½¿ç”¨ç²¾åº¦ {precision} (torch_dtype: {torch_dtype}) åŠ è½½æ¨¡å‹")
    
    # æ¨¡å‹åŠ è½½å‚æ•°
    model_kwargs = {
        "device_map": optimized_device_map,
        "torch_dtype": torch_dtype,
        "trust_remote_code": True,
    }
    
    # å¦‚æœå¼ºåˆ¶GPUæ¨¡å¼ï¼Œæ·»åŠ é¢å¤–å‚æ•°ç¡®ä¿æ¨¡å‹å®Œå…¨åŠ è½½åˆ°GPU
    if force_gpu and isinstance(optimized_device_map, dict) and "" in optimized_device_map:
        target_gpu = optimized_device_map[""]
        # è®¡ç®—å¯ç”¨å†…å­˜å¹¶è®¾ç½®max_memoryä»¥ç¡®ä¿æ¨¡å‹èƒ½åŠ è½½
        try:
            torch.cuda.set_device(target_gpu)
            torch.cuda.empty_cache()
            
            total_memory = torch.cuda.get_device_properties(target_gpu).total_memory
            allocated_memory = torch.cuda.memory_allocated(target_gpu)
            free_memory = total_memory - allocated_memory
            
            # ä¸ºæ¨¡å‹é¢„ç•™90%çš„å¯ç”¨å†…å­˜
            reserved_memory_gb = (free_memory * 0.9) / (1024**3)
            model_kwargs["max_memory"] = {target_gpu: f"{reserved_memory_gb:.1f}GB"}
            print(f"ä¸ºGPU {target_gpu} è®¾ç½®æœ€å¤§å†…å­˜é™åˆ¶: {reserved_memory_gb:.1f}GB")
            
        except Exception as e:
            print(f"è®¾ç½®å†…å­˜é™åˆ¶æ—¶å‡ºé”™: {e}")
    
    try:
        print("å¼€å§‹åŠ è½½æ¨¡å‹...")
        model = Model.from_pretrained(
            model_name_or_path,
            **model_kwargs
        )
        print("æ¨¡å‹åŠ è½½æˆåŠŸ!")
        
        # æ‰“å°æ¨¡å‹åˆ†å¸ƒæƒ…å†µ
        if hasattr(model, 'hf_device_map'):
            print(f"æ¨¡å‹å±‚åˆ†å¸ƒ: {model.hf_device_map}")
            
            # æ£€æŸ¥æ˜¯å¦æœ‰å±‚åœ¨CPUä¸Š
            devices_used = set(model.hf_device_map.values())
            cpu_layers = [layer for layer, device in model.hf_device_map.items() if device == 'cpu']
            
            if cpu_layers and force_gpu:
                print(f"è­¦å‘Šï¼šå°½ç®¡å¯ç”¨äº†å¼ºåˆ¶GPUæ¨¡å¼ï¼Œä»æœ‰ {len(cpu_layers)} å±‚åœ¨CPUä¸Š:")
                print(f"CPUå±‚: {cpu_layers[:5]}{'...' if len(cpu_layers) > 5 else ''}")
            elif not cpu_layers:
                print("âœ“ æ‰€æœ‰æ¨¡å‹å±‚éƒ½åœ¨GPUä¸Š")
            
            # ç»Ÿè®¡è®¾å¤‡åˆ†å¸ƒ
            device_count = {}
            for device in devices_used:
                device_count[device] = sum(1 for d in model.hf_device_map.values() if d == device)
            
            print("è®¾å¤‡åˆ†å¸ƒç»Ÿè®¡:")
            for device, count in device_count.items():
                print(f"  {device}: {count} å±‚")
                
        else:
            print("æ¨¡å‹æœªä½¿ç”¨è®¾å¤‡æ˜ å°„")
            
    except Exception as e:
        print(f"æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        if force_gpu:
            print("å°è¯•å›é€€åˆ°éå¼ºåˆ¶GPUæ¨¡å¼...")
            model_kwargs["device_map"] = "auto"
            if "max_memory" in model_kwargs:
                del model_kwargs["max_memory"]
            
            try:
                model = Model.from_pretrained(
                    model_name_or_path,
                    **model_kwargs
                )
                print("ä½¿ç”¨å›é€€ç­–ç•¥æˆåŠŸåŠ è½½æ¨¡å‹")
            except Exception as fallback_error:
                print(f"å›é€€ç­–ç•¥ä¹Ÿå¤±è´¥: {fallback_error}")
                raise fallback_error
        else:
            raise e
    
    return model, tokenizer
def getDataExistence(corpus_path,dependency):
    '''
    Description:
        åˆ¤æ–­æ•°æ®æ˜¯å¦å­˜åœ¨
    Args:
        data: dict,æ•°æ®
    '''
    for pkg,version in dependency.items():
        files_info = []
        try:
            with open(f"{corpus_path}/{pkg}/{version}.jsonl", "r", encoding="utf-8") as f:
                for line in f:
                    line_data = json.loads(line)
                    files_info.append(str(line_data))    
        except Exception as e:
            return False
        if len(files_info) == 0:
            return False
    return True
# def load_config(config_path):
#     with open(config_path, "r") as f:
#         config = json.load(f)
#     return config
def loraModelExists(pkg,version,model_name,config,knowledge_type=None):
    if config is None:
        raise ValueError("config is None")
    pathConfig = pathConfigurator()
    if model_name is None:
        model_name = config["model_name"].split("/")[-1]
    path = pathConfig.getPath(config,pkg,version,model_name,knowledge_type=knowledge_type)
    # æ¥ç€æ£€æŸ¥å¯¹åº”æ–‡ä»¶å¤¹ä¸‹æ˜¯å¦æœ‰safetensors
    if not os.path.exists(path):
        return False
    
    for file in os.listdir(path):
        file_path = os.path.join(path, file)
        if os.path.isfile(file_path) and file.endswith(".safetensors"):
            return True
    return False
    # return os.path.exists(path)
def load_lora_model(pkg, version, config, knowledge_type, pred_args):
    '''
    Description:
        åŠ è½½loraæ¨¡å‹ï¼Œæ”¯æŒæ ¹æ®adopt_IFT_checkpointå‚æ•°é€‰æ‹©åŠ è½½IFT checkpoint
        å¢å¼ºç‰ˆï¼šä½¿ç”¨IFTæ¨¡å‹ç®¡ç†å™¨æ™ºèƒ½é€‰æ‹©æœ€ä½³åŒ¹é…çš„IFTæ¨¡å‹
        æ–°å¢ï¼šæ”¯æŒåŒ…çº§åˆ«çš„IFTå¯ç”¨æ§åˆ¶ï¼Œåªå¯¹æŒ‡å®šçš„åŒ…å¯ç”¨IFT
    Args:
        pkg: str,åŒ…å
        version: str,ç‰ˆæœ¬å·
        config: dict,é…ç½®
        knowledge_type: str,çŸ¥è¯†ç±»å‹
        pred_args: object,é¢„æµ‹å‚æ•°å¯¹è±¡ï¼ŒåŒ…å«adopt_IFT_checkpointç­‰å‚æ•°
    Returns:
        str: åŠ è½½çš„loraæ¨¡å‹è·¯å¾„
    '''
    pathConfig = pathConfigurator()
    model_name = config["model_name"].split("/")[-1]
    # ç”¨äºå…¼å®¹ç›´æ¥ä½¿ç”¨llama3.1-8Bçš„checkpoint
    # if model_name == "Llama-3.1-8B-Instruct":
    #     model_name = "Llama-3.1-8B"
    # æ£€æŸ¥æ˜¯å¦å…¨å±€å¯ç”¨IFT checkpoint
    adopt_ift_global = getattr(pred_args, 'adopt_IFT_checkpoint', False) if pred_args else False
    
    # ğŸ¯ æ–°å¢ï¼šæ£€æŸ¥åŒ…çº§åˆ«çš„IFTå¯ç”¨æ§åˆ¶
    ift_enabled_packages = getattr(pred_args, 'ift_enabled_packages', None) if pred_args else None
    
    # å†³å®šæ˜¯å¦ä¸ºå½“å‰åŒ…å¯ç”¨IFT
    adopt_ift_for_this_pkg = False
    ift_control_mode = "default"
    
    if ift_enabled_packages is not None:
        # å¦‚æœæŒ‡å®šäº†åŒ…çº§åˆ«æ§åˆ¶ï¼Œåªå¯¹æŒ‡å®šçš„åŒ…å¯ç”¨IFT
        adopt_ift_for_this_pkg = pkg in ift_enabled_packages
        ift_control_mode = "package_selective"
        if adopt_ift_for_this_pkg:
            logging.info(f"ğŸ“¦ {pkg}-{version}: åŒ…åœ¨IFTå¯ç”¨åˆ—è¡¨ä¸­ï¼Œå°†å°è¯•åŠ è½½IFTæ¨¡å‹")
        else:
            logging.info(f"ğŸ“ {pkg}-{version}: åŒ…ä¸åœ¨IFTå¯ç”¨åˆ—è¡¨ä¸­ï¼Œç›´æ¥ä½¿ç”¨LoRAæ¨¡å‹")
    elif adopt_ift_global:
        # å¦‚æœæ²¡æœ‰æŒ‡å®šåŒ…çº§åˆ«æ§åˆ¶ï¼Œä½†å…¨å±€å¯ç”¨äº†IFTï¼Œåˆ™æ‰€æœ‰åŒ…éƒ½å°è¯•IFT
        adopt_ift_for_this_pkg = True
        ift_control_mode = "global_enabled"
        logging.info(f"ğŸš€ {pkg}-{version}: å…¨å±€IFTæ¨¡å¼ï¼Œå°†å°è¯•åŠ è½½IFTæ¨¡å‹")
    else:
        # æ—¢æ²¡æœ‰åŒ…çº§åˆ«æ§åˆ¶ï¼Œä¹Ÿæ²¡æœ‰å…¨å±€å¯ç”¨ï¼Œä½¿ç”¨æ™®é€šLoRA
        adopt_ift_for_this_pkg = False
        ift_control_mode = "global_disabled"
        logging.info(f"ğŸ“ {pkg}-{version}: IFTæœªå¯ç”¨ï¼Œä½¿ç”¨æ™®é€šLoRAæ¨¡å‹")
    
    # å¦‚æœå†³å®šä¸ºå½“å‰åŒ…å¯ç”¨IFTï¼Œåˆ™å°è¯•åŠ è½½IFTæ¨¡å‹
    if adopt_ift_for_this_pkg:
        logging.info(f"ğŸ” å°è¯•é€šè¿‡IFTæ¨¡å‹ç®¡ç†å™¨åŠ è½½IFTæ¨¡å‹: {pkg}-{version} (æ§åˆ¶æ¨¡å¼: {ift_control_mode})")
        
        try:
            # ä½¿ç”¨IFTæ¨¡å‹ç®¡ç†å™¨æŸ¥æ‰¾æœ€ä½³åŒ¹é…çš„IFTæ¨¡å‹
            from utils.iftModelManager import get_default_manager as get_ift_manager
            ift_manager = get_ift_manager()
            
            # ä»pred_argsè·å–IFTé€‰æ‹©åå¥½
            preferred_data_strategy = getattr(pred_args, 'ift_data_strategy', None)
            preferred_ift_type = getattr(pred_args, 'ift_type', None)
            
            # æŸ¥æ‰¾æœ€ä½³åŒ¹é…çš„IFTæ¨¡å‹
            best_match = ift_manager.get_best_match(
                pkg=pkg,
                version=version,
                base_model=config["model_name"],
                knowledge_type=knowledge_type,
                data_strategy=preferred_data_strategy,
                ift_type=preferred_ift_type
            )
            
            if best_match:
                ift_path = best_match["ift_model_path"]
                model_id = best_match["model_id"]
                actual_strategy = best_match["data_strategy"]
                actual_ift_type = best_match["ift_type"]
                actual_knowledge_type = best_match.get("knowledge_type")
                
                # ğŸ”§ æ–°å¢ï¼šä¸¥æ ¼éªŒè¯knowledge_typeçº¦æŸ
                if knowledge_type and actual_knowledge_type != knowledge_type:
                    logging.warning(f"âŒ IFTæ¨¡å‹knowledge_typeä¸åŒ¹é…: æœŸæœ›'{knowledge_type}', å®é™…'{actual_knowledge_type}', è·³è¿‡æ­¤æ¨¡å‹")
                    best_match = None
                elif knowledge_type and knowledge_type not in ift_path:
                    logging.warning(f"âŒ IFTæ¨¡å‹è·¯å¾„ä¸åŒ…å«knowledge_type '{knowledge_type}': {ift_path}, è·³è¿‡æ­¤æ¨¡å‹")
                    best_match = None
                else:
                    logging.info(f"âœ… æ‰¾åˆ°åŒ¹é…çš„IFTæ¨¡å‹ ({pkg}-{version}):")
                    logging.info(f"  æ¨¡å‹ID: {model_id}")
                    logging.info(f"  çŸ¥è¯†ç±»å‹: {actual_knowledge_type}")
                    logging.info(f"  æ•°æ®ç­–ç•¥: {actual_strategy}")
                    logging.info(f"  IFTç±»å‹: {actual_ift_type or 'default'}")
                    logging.info(f"  æ¨¡å‹è·¯å¾„: {ift_path}")
                    
                    # éªŒè¯IFTæ¨¡å‹æ–‡ä»¶å®Œæ•´æ€§
                    if os.path.exists(ift_path):
                        ift_model_path = os.path.join(ift_path, "adapter_model.safetensors")
                        if os.path.exists(ift_model_path):
                            try:
                                _ = load_file(ift_model_path)
                                logging.info(f"âœ… æˆåŠŸéªŒè¯å¹¶åŠ è½½IFTæ¨¡å‹: {ift_path}")
                                
                                # å¦‚æœåå¥½ä¸å®é™…ä¸åŒ¹é…ï¼Œç»™å‡ºæç¤º
                                if preferred_data_strategy and preferred_data_strategy != actual_strategy:
                                    logging.info(f"æ³¨æ„: æœŸæœ›æ•°æ®ç­–ç•¥ '{preferred_data_strategy}'ï¼Œå®é™…ä½¿ç”¨ '{actual_strategy}'")
                                if preferred_ift_type and preferred_ift_type != actual_ift_type:
                                    logging.info(f"æ³¨æ„: æœŸæœ›IFTç±»å‹ '{preferred_ift_type}'ï¼Œå®é™…ä½¿ç”¨ '{actual_ift_type or 'default'}'")
                                    
                                return ift_path
                            except Exception as e:
                                logging.warning(f"IFTæ¨¡å‹æ–‡ä»¶æŸå {ift_model_path}: {e}")
                                best_match = None
                        else:
                            logging.warning(f"IFTæ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {ift_model_path}")
                            best_match = None
                    else:
                        logging.warning(f"IFTæ¨¡å‹ç›®å½•ä¸å­˜åœ¨: {ift_path}")
                        best_match = None
            
            # å¦‚æœIFTæ¨¡å‹ç®¡ç†å™¨æŸ¥æ‰¾å¤±è´¥æˆ–éªŒè¯å¤±è´¥ï¼Œå°è¯•ä¼ ç»Ÿæ–¹å¼
            if not best_match:
                logging.info(f"IFTæ¨¡å‹ç®¡ç†å™¨æœªæ‰¾åˆ°åŒ¹é…çš„IFTæ¨¡å‹ {pkg}-{version}")
                
                # å¦‚æœæŒ‡å®šäº†åå¥½ä½†æ²¡æ‰¾åˆ°ï¼Œç»™å‡ºæç¤º
                if preferred_data_strategy or preferred_ift_type:
                    logging.info(f"æœªæ‰¾åˆ°æ»¡è¶³åå¥½çš„IFTæ¨¡å‹:")
                    if preferred_data_strategy:
                        logging.info(f"  æœŸæœ›æ•°æ®ç­–ç•¥: {preferred_data_strategy}")
                    if preferred_ift_type:
                        logging.info(f"  æœŸæœ›IFTç±»å‹: {preferred_ift_type}")
                
                # å›é€€åˆ°ä¼ ç»Ÿçš„IFTæ£€æŸ¥æ–¹å¼
                logging.info(f"å›é€€åˆ°ä¼ ç»ŸIFTæ£€æŸ¥æ–¹å¼...")
                ift_exists, ift_path = pathConfig.checkIFTModelExists(config, pkg, version, model_name, knowledge_type, pred_args)
                
                if ift_exists:
                    # ğŸ”§ æ–°å¢ï¼šä¼ ç»Ÿæ–¹å¼ä¹Ÿè¦éªŒè¯knowledge_typeçº¦æŸ
                    if knowledge_type and knowledge_type not in ift_path:
                        logging.warning(f"âŒ ä¼ ç»ŸIFTæ¨¡å‹è·¯å¾„ä¸åŒ…å«knowledge_type '{knowledge_type}': {ift_path}, è·³è¿‡æ­¤æ¨¡å‹")
                        ift_exists = False
                    else:
                        # éªŒè¯IFTæ¨¡å‹æ–‡ä»¶å®Œæ•´æ€§
                        ift_model_path = os.path.join(ift_path, "adapter_model.safetensors")
                        if os.path.exists(ift_model_path):
                            try:
                                _ = load_file(ift_model_path)
                                logging.info(f"âœ… é€šè¿‡ä¼ ç»Ÿæ–¹å¼æ‰¾åˆ°å¹¶éªŒè¯IFTæ¨¡å‹: {ift_path}")
                                return ift_path
                            except Exception as e:
                                logging.warning(f"IFTæ¨¡å‹æ–‡ä»¶æŸå {ift_model_path}: {e}")
                        else:
                            logging.warning(f"IFTæ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {ift_model_path}")
                
        except Exception as e:
            logging.error(f"ä½¿ç”¨IFTæ¨¡å‹ç®¡ç†å™¨æ—¶å‘ç”Ÿé”™è¯¯ {pkg}-{version}: {e}")
            logging.info(f"å›é€€åˆ°æ™®é€šLoRAæ¨¡å‹")
    
    # åŠ è½½æ™®é€šLoRAæ¨¡å‹ï¼ˆé»˜è®¤è¡Œä¸ºæˆ–IFTåŠ è½½å¤±è´¥æ—¶çš„å›é€€ï¼‰
    if ift_control_mode == "package_selective" and not adopt_ift_for_this_pkg:
        logging.info(f"ğŸ“¦ {pkg}-{version}: æŒ‰åŒ…çº§åˆ«æ§åˆ¶ç›´æ¥åŠ è½½æ™®é€šLoRAæ¨¡å‹")
    else:
        logging.info(f"ğŸ“ {pkg}-{version}: åŠ è½½æ™®é€šLoRAæ¨¡å‹ (åŸå› : {ift_control_mode})")
    
    path = pathConfig.getPath(config, pkg, version, model_name, knowledge_type, pred_args)
    
    # ğŸ”§ æ–°å¢ï¼šéªŒè¯æ™®é€šLoRAæ¨¡å‹è·¯å¾„ä¹Ÿå¿…é¡»åŒ…å«knowledge_type
    if knowledge_type and knowledge_type not in path:
        raise ValueError(f"LoRAæ¨¡å‹è·¯å¾„ä¸åŒ…å«knowledge_type '{knowledge_type}': {path}")
    
    if os.path.exists(path):
        # åŠ è½½safetensorsæ ¼å¼çš„æ¨¡å‹
        model_path = os.path.join(path, "adapter_model.safetensors")
        if os.path.exists(model_path):
            try:
                _ = load_file(model_path)  # éªŒè¯æ–‡ä»¶å®Œæ•´æ€§
                logging.info(f"âœ… æˆåŠŸæ‰¾åˆ°å¹¶éªŒè¯LoRAæ¨¡å‹: {path}")
                return path
            except Exception as e:
                raise ValueError(f"LoRAæ¨¡å‹æ–‡ä»¶æŸå: {model_path}, é”™è¯¯: {e}")
        else:
            raise ValueError(f"LoRAæ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
    else:
        raise ValueError(f"LoRAæ¨¡å‹ç›®å½•ä¸å­˜åœ¨: {path}")
def get_dataloader(config,corpus_path,pkg,version,tokenizer):
    files_info = []
    with open(f"{corpus_path}/{pkg}/{version}.jsonl", "r", encoding="utf-8") as f:
        for line in f:
            line_data = json.loads(line)
            files_info.append(str(line_data))    
    files_info = files_info[:int(len(files_info)*config["traindata_percentage"])]
    if len(files_info) == 0:
        return None
    # print(f"{pkg} {version} {len(files_info)}")
    dataset = TextDataset(files_info, tokenizer, block_size=128,pkg=pkg,version=version)
    dataloader = DataLoader(dataset, batch_size=config["batch_size"], shuffle=True,collate_fn=collate_fn)
    return dataloader

def getEquipAdaptorModel(config):
    '''
    Description:
        ç”±foundation modelè·å–å¯¹åº”çš„peftæ¨¡å‹
    Args:
        config: dict, é…ç½®ä¿¡æ¯
            - use_balanced_device_map: bool, æ˜¯å¦ä½¿ç”¨å‡è¡¡è®¾å¤‡æ˜ å°„
            - force_balance: bool, æ˜¯å¦å¼ºåˆ¶å‡è¡¡åˆ†é…
            - exclude_cpu: bool, æ˜¯å¦æ’é™¤CPUè®¾å¤‡
            - check_r_consistency: bool, æ˜¯å¦æ£€æŸ¥rå€¼ä¸€è‡´æ€§
    Returns:
        lora_model: è®­ç»ƒå¥½çš„LoRAæ¨¡å‹
    '''
    # è®°å½•ä¼ å…¥çš„configé…ç½®
    logging.info("=" * 60)
    logging.info("getEquipAdaptorModel - æ¥æ”¶åˆ°çš„é…ç½®ä¿¡æ¯:")
    logging.info("=" * 60)
    
    # å®šä¹‰train_lora.pyä¸­çš„é»˜è®¤å‚æ•°ç”¨äºæ¯”è¾ƒ
    train_lora_defaults = {
        "use_balanced_device_map": True,
        "force_balance": True,
        "exclude_cpu": True,
        "check_r_consistency": True,
        "strict_r_check": False,
        "precision": "bf16",
        "device_map": "auto"
    }
    
    # è®°å½•æ‰€æœ‰configå‚æ•°
    logging.info("ä¼ å…¥çš„configå‚æ•°:")
    for key, value in config.items():
        if key in train_lora_defaults:
            default_value = train_lora_defaults[key]
            if value != default_value:
                logging.warning(f"  {key}: {value} [ä¸train_loraé»˜è®¤å€¼ {default_value} ä¸åŒ]")
            else:
                logging.info(f"  {key}: {value} [ä¸train_loraé»˜è®¤å€¼ä¸€è‡´]")
        else:
            logging.info(f"  {key}: {value}")
    
    # æ£€æŸ¥æ˜¯å¦ç¼ºå°‘é‡è¦å‚æ•°
    missing_params = []
    for key, default_value in train_lora_defaults.items():
        if key not in config:
            missing_params.append(key)
            logging.warning(f"  {key}: æœªè®¾ç½® [train_loraé»˜è®¤å€¼: {default_value}]")
    
    if missing_params:
        logging.warning(f"ç¼ºå°‘ä»¥ä¸‹å‚æ•°ï¼Œå°†ä½¿ç”¨å‡½æ•°å†…éƒ¨é»˜è®¤å€¼: {missing_params}")
    
    # è®°å½•LoRAç›¸å…³çš„æ ¸å¿ƒå‚æ•°
    logging.info("\nLoRAæ ¸å¿ƒå‚æ•°:")
    lora_core_params = ["model_name", "r", "alpha", "target_modules", "target_layers"]
    for param in lora_core_params:
        if param in config:
            logging.info(f"  {param}: {config[param]}")
        else:
            logging.error(f"  {param}: æœªè®¾ç½® [å¿…éœ€å‚æ•°]")
    
    # è®°å½•è®¾å¤‡æ˜ å°„ç›¸å…³å‚æ•°
    logging.info("\nè®¾å¤‡æ˜ å°„ç›¸å…³å‚æ•°:")
    device_params = ["use_balanced_device_map", "force_balance", "exclude_cpu", "device_map"]
    for param in device_params:
        value = config.get(param, train_lora_defaults.get(param, "æœªè®¾ç½®"))
        logging.info(f"  {param}: {value}")
    
    # è®°å½•rå€¼æ£€æŸ¥ç›¸å…³å‚æ•°
    logging.info("\nrå€¼æ£€æŸ¥ç›¸å…³å‚æ•°:")
    r_check_params = ["check_r_consistency", "strict_r_check"]
    for param in r_check_params:
        value = config.get(param, train_lora_defaults.get(param, "æœªè®¾ç½®"))
        logging.info(f"  {param}: {value}")
    
    logging.info("=" * 60)
    
    # æ¸…ç†ç°æœ‰çš„GPUç¼“å­˜
    torch.cuda.empty_cache()
    
    # æ£€æŸ¥è®¾å¤‡æ˜ å°„ç­–ç•¥
    use_balanced_device_map = config.get("use_balanced_device_map", False)
    use_dynamic_device_map = config.get("use_dynamic_device_map", False)
    
    logging.info(f"å‡è¡¡è®¾å¤‡æ˜ å°„å¯ç”¨çŠ¶æ€: {use_balanced_device_map}")
    logging.info(f"åŠ¨æ€è®¾å¤‡æ˜ å°„å¯ç”¨çŠ¶æ€: {use_dynamic_device_map}")
    
    # è·å–ç²¾åº¦è®¾ç½®
    precision = config.get("precision", "fp16")
    logging.info(f"ä½¿ç”¨ç²¾åº¦: {precision}")
    print(f"ä½¿ç”¨ç²¾åº¦: {precision}")
    
    # æ£€æŸ¥GPUå¯ç”¨æ€§
    num_gpus = torch.cuda.device_count()
    logging.info(f"æ£€æµ‹åˆ° {num_gpus} ä¸ªGPUè®¾å¤‡")
    print(f"æ£€æµ‹åˆ° {num_gpus} ä¸ªGPUè®¾å¤‡")
    
    # æ ¹æ®é…ç½®é€‰æ‹©è®¾å¤‡æ˜ å°„ç­–ç•¥
    if use_dynamic_device_map:
        # åŠ¨æ€ç­–ç•¥ï¼šå…ˆautoï¼Œæ£€æŸ¥å‡è¡¡æ€§ï¼Œä¸å‡è¡¡åˆ™é‡æ–°å¹³è¡¡
        balance_threshold = config.get("balance_threshold", 0.3)
        force_balance = config.get("force_balance", False)
        exclude_cpu = config.get("exclude_cpu", True)
        
        logging.info(f"ä½¿ç”¨åŠ¨æ€è®¾å¤‡æ˜ å°„ç­–ç•¥")
        logging.info(f"åŠ¨æ€æ˜ å°„å‚æ•°: balance_threshold={balance_threshold}, force_balance={force_balance}, exclude_cpu={exclude_cpu}")
        
        base_model, tokenizer, device_map_info = create_dynamic_device_map(
            config["model_name"],
            balance_threshold=balance_threshold,
            force_balance=force_balance,
            exclude_cpu=exclude_cpu
        )
        
        if base_model is None:
            logging.error("åŠ¨æ€è®¾å¤‡æ˜ å°„å¤±è´¥")
            raise RuntimeError("åŠ¨æ€è®¾å¤‡æ˜ å°„å¤±è´¥")
        
        logging.info(f"åŠ¨æ€è®¾å¤‡æ˜ å°„å®Œæˆ: ç­–ç•¥={device_map_info['strategy']}, åŸå› ={device_map_info['reason']}")
        print(f"åŠ¨æ€è®¾å¤‡æ˜ å°„å®Œæˆ: ç­–ç•¥={device_map_info['strategy']}")
        
        # è®°å½•å‡è¡¡æ€§ä¿¡æ¯
        if 'balance_info' in device_map_info and device_map_info['balance_info']:
            balance_info = device_map_info['balance_info']
            logging.info(f"è®¾å¤‡åˆ†å¸ƒ: {balance_info['device_distribution']}")
            logging.info(f"ä¸å‡è¡¡ç³»æ•°: {balance_info['imbalance_ratio']:.3f}")
        
    elif use_balanced_device_map:
        # å‡è¡¡ç­–ç•¥ï¼šç›´æ¥ä½¿ç”¨å‡è¡¡è®¾å¤‡æ˜ å°„
        force_balance = config.get("force_balance", False)
        exclude_cpu = config.get("exclude_cpu", True)
        
        logging.info(f"ä½¿ç”¨å‡è¡¡è®¾å¤‡æ˜ å°„ç­–ç•¥")
        logging.info(f"å‡è¡¡æ˜ å°„å‚æ•°: force_balance={force_balance}, exclude_cpu={exclude_cpu}")
        print("å¯ç”¨å‡è¡¡è®¾å¤‡æ˜ å°„...")
        
        device_map = create_balanced_device_map(
            config["model_name"],
            force_balance=force_balance,
            exclude_cpu=exclude_cpu
        )
        if device_map is None:
            logging.warning("å‡è¡¡è®¾å¤‡æ˜ å°„å¤±è´¥ï¼Œå›é€€åˆ°autoæ¨¡å¼")
            print("âš ï¸  å‡è¡¡è®¾å¤‡æ˜ å°„å¤±è´¥ï¼Œå›é€€åˆ°autoæ¨¡å¼")
            device_map = "auto"
        else:
            logging.info(f"å‡è¡¡è®¾å¤‡æ˜ å°„åˆ›å»ºæˆåŠŸ: {type(device_map)}")
        
        print(f"ä½¿ç”¨è®¾å¤‡æ˜ å°„: {device_map}")
        
        # åŠ è½½åŸºç¡€æ¨¡å‹å’Œtokenizer
        logging.info(f"å¼€å§‹åŠ è½½åŸºç¡€æ¨¡å‹: {config['model_name']}")
        print(f"åŠ è½½åŸºç¡€æ¨¡å‹: {config['model_name']}")
        try:
            base_model, tokenizer = load_base_model(config["model_name"], device_map, precision)
            logging.info("åŸºç¡€æ¨¡å‹åŠ è½½æˆåŠŸ")
            print("åŸºç¡€æ¨¡å‹åŠ è½½æˆåŠŸ")
        except Exception as e:
            logging.error(f"åŠ è½½åŸºç¡€æ¨¡å‹å¤±è´¥: {e}")
            print(f"åŠ è½½åŸºç¡€æ¨¡å‹å¤±è´¥: {e}")
            raise e
    
    else:
        # æ ‡å‡†ç­–ç•¥ï¼šä½¿ç”¨autoæˆ–ç”¨æˆ·æŒ‡å®šçš„è®¾å¤‡æ˜ å°„
        device_map = config.get("device_map", "auto")
        logging.info(f"ä½¿ç”¨æ ‡å‡†è®¾å¤‡æ˜ å°„: {device_map}")
        print(f"ä½¿ç”¨è®¾å¤‡æ˜ å°„: {device_map}")
        
        # åŠ è½½åŸºç¡€æ¨¡å‹å’Œtokenizer
        logging.info(f"å¼€å§‹åŠ è½½åŸºç¡€æ¨¡å‹: {config['model_name']}")
        print(f"åŠ è½½åŸºç¡€æ¨¡å‹: {config['model_name']}")
        try:
            base_model, tokenizer = load_base_model(config["model_name"], device_map, precision)
            logging.info("åŸºç¡€æ¨¡å‹åŠ è½½æˆåŠŸ")
            print("åŸºç¡€æ¨¡å‹åŠ è½½æˆåŠŸ")
        except Exception as e:
            logging.error(f"åŠ è½½åŸºç¡€æ¨¡å‹å¤±è´¥: {e}")
            print(f"åŠ è½½åŸºç¡€æ¨¡å‹å¤±è´¥: {e}")
            raise e
    
    # åˆ›å»ºLoRAé…ç½®
    logging.info("åˆ›å»ºLoRAé…ç½®...")
    logging.info(f"LoRAé…ç½®å‚æ•°: target_modules={config['target_modules']}, target_layers={config['target_layers']}, r={config['r']}, alpha={config['alpha']}")
    print("åˆ›å»ºLoRAé…ç½®...")
    lora_config = create_lora_config(
        config["target_modules"], 
        config["target_layers"], 
        config["r"], 
        config["alpha"]
    )
    
    # åˆ›å»ºLoRAæ¨¡å‹
    logging.info("åˆ›å»ºLoRAæ¨¡å‹...")
    print("åˆ›å»ºLoRAæ¨¡å‹...")
    lora_model = get_peft_model(base_model, lora_config)
    
    # ç®€åŒ–çš„æ¨¡å‹ä¿¡æ¯è¾“å‡º
    if hasattr(lora_model, 'hf_device_map'):
        device_map_info = str(lora_model.hf_device_map)
        logging.info(f"LoRAæ¨¡å‹è®¾å¤‡æ˜ å°„: {device_map_info}")
        print(f"LoRAæ¨¡å‹è®¾å¤‡æ˜ å°„: {lora_model.hf_device_map}")
    else:
        try:
            first_param_device = next(lora_model.parameters()).device
            logging.info(f"LoRAæ¨¡å‹è®¾å¤‡: {first_param_device}")
            print(f"LoRAæ¨¡å‹è®¾å¤‡: {first_param_device}")
        except:
            logging.warning("æ— æ³•ç¡®å®šæ¨¡å‹è®¾å¤‡")
            print("æ— æ³•ç¡®å®šæ¨¡å‹è®¾å¤‡")
    
    # æ‰“å°GPUå†…å­˜ä½¿ç”¨æƒ…å†µ
    if torch.cuda.is_available():
        logging.info("å½“å‰GPUå†…å­˜ä½¿ç”¨æƒ…å†µ:")
        print("\nå½“å‰GPUå†…å­˜ä½¿ç”¨æƒ…å†µ:")
        for i in range(torch.cuda.device_count()):
            try:
                usage = torch.cuda.memory_allocated(i)
                total = torch.cuda.get_device_properties(i).total_memory
                usage_percent = (usage / total) * 100
                gpu_info = f"cuda:{i}: {usage / (1024**2):.2f} MB / {total / (1024**3):.2f} GB ({usage_percent:.1f}%)"
                logging.info(f"- {gpu_info}")
                print(f"- {gpu_info}")
            except:
                error_info = f"cuda:{i}: æ— æ³•è·å–å†…å­˜ä¿¡æ¯"
                logging.warning(f"- {error_info}")
                print(f"- {error_info}")
    
    # æ£€æŸ¥rå€¼ä¸€è‡´æ€§ï¼ˆå¦‚æœé…ç½®ä¸­å¯ç”¨äº†æ£€æŸ¥ï¼‰
    check_r_consistency = config.get("check_r_consistency", False)
    logging.info(f"rå€¼ä¸€è‡´æ€§æ£€æŸ¥å¯ç”¨çŠ¶æ€: {check_r_consistency}")
    
    if check_r_consistency:
        strict_r_check = config.get("strict_r_check", False)
        logging.info(f"ä¸¥æ ¼rå€¼æ£€æŸ¥æ¨¡å¼: {strict_r_check}")
        logging.info("å¼€å§‹æ£€æŸ¥LoRAæ¨¡å‹rå€¼ä¸€è‡´æ€§...")
        print("\næ£€æŸ¥LoRAæ¨¡å‹rå€¼ä¸€è‡´æ€§...")
        
        consistency_result = check_lora_r_consistency(lora_model, config)
        
        if not consistency_result['is_consistent']:
            logging.warning("LoRAæ¨¡å‹rå€¼ä¸é…ç½®ä¸ä¸€è‡´")
            logging.warning(f"ä¸åŒ¹é…çš„å±‚: {consistency_result['mismatched_layers']}")
            logging.warning(f"æœŸæœ›rå€¼: {consistency_result['expected_r']}")
            logging.warning(f"å®é™…rå€¼: {consistency_result['actual_r_values']}")
            
            print("âš ï¸  è­¦å‘Šï¼šLoRAæ¨¡å‹rå€¼ä¸é…ç½®ä¸ä¸€è‡´")
            
            if strict_r_check:
                logging.error(f"ä¸¥æ ¼æ¨¡å¼ä¸‹rå€¼ä¸ä¸€è‡´ï¼Œä¸­æ­¢æ‰§è¡Œ: {consistency_result['mismatched_layers']}")
                raise ValueError(f"LoRAæ¨¡å‹rå€¼ä¸ä¸€è‡´: {consistency_result['mismatched_layers']}")
        else:
            logging.info("âœ… LoRAæ¨¡å‹rå€¼ä¸€è‡´æ€§æ£€æŸ¥é€šè¿‡")
    
    logging.info("LoRAæ¨¡å‹åˆ›å»ºå®Œæˆ")
    print("LoRAæ¨¡å‹åˆ›å»ºå®Œæˆ")
    return lora_model
def train_lora_model_withPEFT(lora_model, dataloader, config, output_adaptor_path):
    '''
        å¯¹äºpeftæ¨¡å‹è¿›è¡Œè®­ç»ƒ
    Args:
        lora_model: è·å–åˆ°çš„LoRAæ¨¡å‹
        dataloader: DataLoader, è®­ç»ƒæ•°æ®åŠ è½½å™¨
        config: è®­ç»ƒé…ç½®å­—å…¸ï¼ŒåŒ…å«ä»¥ä¸‹å¯é€‰å‚æ•°:
            - target_batch_size (int): ç›®æ ‡æ‰¹æ¬¡å¤§å°ï¼Œç”¨äºæ¢¯åº¦ç´¯ç§¯è®¡ç®—ï¼Œé»˜è®¤16
            - precision (str): è®­ç»ƒç²¾åº¦ï¼Œå¯é€‰["float32", "float16", "bfloat16"]ï¼Œé»˜è®¤"float32"
            - save_path_base (str): ä¿å­˜è·¯å¾„åŸºç¡€ç›®å½•ï¼Œé»˜è®¤"/datanfs2/chenrongyi/models/versiBCB"
            - num_epochs
            - learning_rate
        output_adaptor_path: è¾“å‡ºé€‚é…å™¨è·¯å¾„

    Returns:
        lora_model: è®­ç»ƒå¥½çš„LoRAæ¨¡å‹
    '''
    # æ£€æŸ¥CUDAå¯ç”¨æ€§å’Œè®¾å¤‡æƒ…å†µ
    print("æ£€æŸ¥æ¨¡å‹è®¾å¤‡åˆ†å¸ƒ...")
    if hasattr(lora_model, 'hf_device_map'):
        print(f"æ¨¡å‹å½“å‰device_map: {lora_model.hf_device_map}")

    # åˆ†ææ¨¡å‹çš„è®¾å¤‡åˆ†å¸ƒ
    device_distribution = {}
    for name, param in lora_model.named_parameters():
        device = param.device
        if device not in device_distribution:
            device_distribution[device] = 0
        device_distribution[device] += 1
    
    print("è®­ç»ƒå‰æ¨¡å‹å‚æ•°è®¾å¤‡åˆ†å¸ƒ:")
    for device, count in device_distribution.items():
        print(f"- {device}: {count} parameters")
    
    # æ£€æŸ¥æ¨¡å‹æ˜¯å¦åˆ†å¸ƒåœ¨å¤šä¸ªè®¾å¤‡ä¸Š
    is_multi_device = len(device_distribution) > 1
    
    if is_multi_device:
        print("æ£€æµ‹åˆ°å¤šè®¾å¤‡åˆ†å¸ƒæ¨¡å‹ï¼Œè®­ç»ƒå°†ä½¿ç”¨æ¨¡å‹è‡ªèº«çš„è®¾å¤‡ç®¡ç†")
        print("å¦‚æœé‡åˆ°è®¾å¤‡ä¸ä¸€è‡´é”™è¯¯ï¼Œç›¸å…³batchå°†è¢«è‡ªåŠ¨è·³è¿‡")
    else:
        model_device = list(device_distribution.keys())[0]
        print(f"å•è®¾å¤‡æ¨¡å‹ï¼Œè®¾å¤‡: {model_device}")
    
    # è®­ç»ƒæ¨¡å‹
    try:
        # ä½¿ç”¨configä¸­çš„å‚æ•°è®­ç»ƒLoRAæ¨¡å‹
        num_epochs = config.get("num_epochs", 5)
        learning_rate = config.get("learning_rate", 1e-3)
        # å°†strè½¬ä¸ºfloat
        learning_rate = float(learning_rate)
        print(f"å¼€å§‹è®­ç»ƒ: epochs={num_epochs}, lr={learning_rate}, target_batch_size={config.get('target_batch_size', 16)}")
        
        lora_model = train_lora_model(
            lora_model, 
            dataloader, 
            num_epochs, 
            learning_rate,
            config,
            output_adaptor_path
        )
        
        # å°†æ¨¡å‹ç§»åˆ°CPUå¹¶åˆ†ç¦»è®¡ç®—å›¾
        print("è®­ç»ƒå®Œæˆï¼Œå°†æ¨¡å‹ç§»åŠ¨åˆ°CPU...")
        lora_model = lora_model.cpu()
        for param in lora_model.parameters():
            param.requires_grad = False
            
        # æ¸…ç†GPUç¼“å­˜
        torch.cuda.empty_cache()
        return lora_model
        
    except Exception as e:
        print(f"è®­ç»ƒè¿‡ç¨‹ä¸­å‡ºé”™: {e}")
        # ç¡®ä¿æ¸…ç†GPUç¼“å­˜
        torch.cuda.empty_cache()
        raise e

def buildandTrainLoraModel(config, dataloader, precision='fp16',pkg=None,version=None,knowledge_type=None):
    '''
    Description:
        è®­ç»ƒloraæ¨¡å‹ï¼Œå¹¶ç¡®ä¿é€‚å½“çš„å†…å­˜ç®¡ç†
    Args:
        config: dict, é…ç½®ä¿¡æ¯
            - use_balanced_device_map: bool, æ˜¯å¦ä½¿ç”¨å‡è¡¡è®¾å¤‡æ˜ å°„
            - force_balance: bool, æ˜¯å¦å¼ºåˆ¶å‡è¡¡åˆ†é…
            - exclude_cpu: bool, æ˜¯å¦æ’é™¤CPUè®¾å¤‡
            - check_r_consistency: bool, æ˜¯å¦æ£€æŸ¥rå€¼ä¸€è‡´æ€§
        dataloader: DataLoader, è®­ç»ƒæ•°æ®åŠ è½½å™¨
        precision: str, æ¨¡å‹ç²¾åº¦ ('fp16', 'fp32', 'bf16')
        pkg: str, åŒ…å
        version: str, ç‰ˆæœ¬å·  
        knowledge_type: str, çŸ¥è¯†ç±»å‹
    Returns:
        lora_model: è®­ç»ƒå¥½çš„LoRAæ¨¡å‹
    '''
    # è®°å½•è®­ç»ƒå¼€å§‹å’Œé…ç½®ä¿¡æ¯
    logging.info("=" * 60)
    logging.info(f"buildandTrainLoraModel - å¼€å§‹è®­ç»ƒ: {pkg}-{version}")
    logging.info("=" * 60)
    
    # å®šä¹‰train_lora.pyä¸­çš„é»˜è®¤å‚æ•°ç”¨äºæ¯”è¾ƒ
    train_lora_defaults = {
        "use_balanced_device_map": True,
        "force_balance": True,
        "exclude_cpu": True,
        "check_r_consistency": True,
        "strict_r_check": False,
        "precision": "bf16",
        "device_map": "auto"
    }
    
    # è®°å½•ä¼ å…¥çš„precisionå‚æ•°
    logging.info(f"ä¼ å…¥çš„precisionå‚æ•°: {precision}")
    config_precision = config.get("precision", "fp16")
    if precision != config_precision:
        logging.warning(f"precisionå‚æ•°ä¸ä¸€è‡´: å‡½æ•°å‚æ•°={precision}, configä¸­={config_precision}")
    
    # è®°å½•åŒ…å’Œç‰ˆæœ¬ä¿¡æ¯
    logging.info(f"è®­ç»ƒç›®æ ‡: pkg={pkg}, version={version}, knowledge_type={knowledge_type}")
    
    model_name = config["model_name"].split("/")[-1]
    if pkg and version:
        pathConfig = pathConfigurator()
        output_adaptor_path = pathConfig.getPath(config, pkg, version,model_name,knowledge_type=knowledge_type)
        logging.info(f"è¾“å‡ºè·¯å¾„: {output_adaptor_path}")
    else:
        logging.error("pkgå’Œversionå¿…é¡»æä¾›")
        raise ValueError("pkg and version must be provided")
    
    try:
        # æ¸…ç†ç°æœ‰çš„GPUç¼“å­˜
        torch.cuda.empty_cache()
        
        # æ£€æŸ¥æ˜¯å¦å¯ç”¨å‡è¡¡è®¾å¤‡æ˜ å°„
        use_balanced_device_map = config.get("use_balanced_device_map", False)
        logging.info(f"å‡è¡¡è®¾å¤‡æ˜ å°„å¯ç”¨çŠ¶æ€: {use_balanced_device_map}")
        
        if use_balanced_device_map:
            force_balance = config.get("force_balance", False)
            exclude_cpu = config.get("exclude_cpu", True)
            logging.info(f"å‡è¡¡è®¾å¤‡æ˜ å°„å‚æ•°: force_balance={force_balance}, exclude_cpu={exclude_cpu}")
            print("å¯ç”¨å‡è¡¡è®¾å¤‡æ˜ å°„...")
            
            device_map = create_balanced_device_map(
                config["model_name"],
                force_balance=force_balance,
                exclude_cpu=exclude_cpu
            )
            if device_map is None:
                logging.warning("å‡è¡¡è®¾å¤‡æ˜ å°„å¤±è´¥ï¼Œå›é€€åˆ°autoæ¨¡å¼")
                print("âš ï¸  å‡è¡¡è®¾å¤‡æ˜ å°„å¤±è´¥ï¼Œå›é€€åˆ°autoæ¨¡å¼")
                device_map = "auto"
            else:
                logging.info(f"å‡è¡¡è®¾å¤‡æ˜ å°„åˆ›å»ºæˆåŠŸ: {type(device_map)}")
        else:
            # ä½¿ç”¨é…ç½®ä¸­çš„è®¾å¤‡æ˜ å°„ï¼Œæ”¯æŒå¤šGPUåˆ†å¸ƒ
            device_map = config.get("device_map", "auto")
            logging.info(f"ä½¿ç”¨æ ‡å‡†è®¾å¤‡æ˜ å°„: {device_map}")
        
        print(f"ä½¿ç”¨è®¾å¤‡æ˜ å°„: {device_map}")
        
        # åŠ è½½åŸºç¡€æ¨¡å‹å’Œtokenizerï¼Œä½¿ç”¨æŒ‡å®šçš„ç²¾åº¦å’Œè®¾å¤‡æ˜ å°„
        logging.info(f"å¼€å§‹åŠ è½½åŸºç¡€æ¨¡å‹: {config['model_name']}")
        logging.info(f"ä½¿ç”¨ç²¾åº¦: {precision}")


        # base_model, tokenizer = load_base_model(config["model_name"], device_map, precision)
        base_model = Model.from_pretrained(config["model_name"],torch_dtype=str2dtype(precision),device_map="auto")
        tokenizer = AutoTokenizer.from_pretrained(config["model_name"])
        logging.info("åˆ›å»ºLoRAé…ç½®...")
        logging.info(f"LoRAé…ç½®å‚æ•°: target_modules={config['target_modules']}, target_layers={config['target_layers']}, r={config['r']}, alpha={config['alpha']}")
        lora_config = create_lora_config(
            config["target_modules"], 
            config["target_layers"], 
            config["r"], 
            config["alpha"]
        )
        
        # åˆ›å»ºLoRAæ¨¡å‹
        logging.info("åˆ›å»ºLoRAæ¨¡å‹...")
        lora_model = get_peft_model(base_model, lora_config)
        profiler.record("åˆ›å»ºLoRAæ¨¡å‹")
        print("memory_usage")
        # åˆ†ææ¨¡å‹å‚æ•°åˆ†å¸ƒ
        devices_found = {}
        for name, param in lora_model.named_parameters():
            device = param.device
            if device not in devices_found:
                devices_found[device] = []
            devices_found[device].append(name)
        
        logging.info("è®­ç»ƒæ¨¡å‹å‚æ•°åˆ†å¸ƒ:")
        print("è®­ç»ƒæ¨¡å‹å‚æ•°åˆ†å¸ƒ:")
        for device, params in devices_found.items():
            device_info = f"{device}: {len(params)} parameters"
            logging.info(f"- {device_info}")
            print(f"- {device_info}")
        
        # ç¡®å®šä¸»è®¾å¤‡
        if len(devices_found) > 1:
            main_device = max(devices_found.keys(), key=lambda d: len(devices_found[d]))
            logging.info(f"è®­ç»ƒå°†ä½¿ç”¨ä¸»è®¾å¤‡: {main_device}")
            print(f"è®­ç»ƒå°†ä½¿ç”¨ä¸»è®¾å¤‡: {main_device}")
        else:
            main_device = list(devices_found.keys())[0]
            logging.info(f"è®­ç»ƒå°†åœ¨è®¾å¤‡: {main_device}")
            print(f"è®­ç»ƒå°†åœ¨è®¾å¤‡: {main_device}")
        
        # è®­ç»ƒå‰æ£€æŸ¥rå€¼ä¸€è‡´æ€§
        check_r_consistency = config.get("check_r_consistency", False)
        logging.info(f"è®­ç»ƒå‰rå€¼ä¸€è‡´æ€§æ£€æŸ¥å¯ç”¨çŠ¶æ€: {check_r_consistency}")
        
        if check_r_consistency:
            strict_r_check = config.get("strict_r_check", False)
            logging.info(f"ä¸¥æ ¼rå€¼æ£€æŸ¥æ¨¡å¼: {strict_r_check}")
            logging.info("å¼€å§‹è®­ç»ƒå‰LoRAæ¨¡å‹rå€¼ä¸€è‡´æ€§æ£€æŸ¥...")
            print("\nè®­ç»ƒå‰æ£€æŸ¥LoRAæ¨¡å‹rå€¼ä¸€è‡´æ€§...")
            
            consistency_result = check_lora_r_consistency(lora_model, config)
            
            if not consistency_result['is_consistent']:
                logging.warning("è®­ç»ƒå‰LoRAæ¨¡å‹rå€¼ä¸é…ç½®ä¸ä¸€è‡´")
                logging.warning(f"ä¸åŒ¹é…çš„å±‚: {consistency_result['mismatched_layers']}")
                logging.warning(f"æœŸæœ›rå€¼: {consistency_result['expected_r']}")
                logging.warning(f"å®é™…rå€¼: {consistency_result['actual_r_values']}")
                
                print("âš ï¸  è­¦å‘Šï¼šLoRAæ¨¡å‹rå€¼ä¸é…ç½®ä¸ä¸€è‡´")
                
                if strict_r_check:
                    logging.error(f"ä¸¥æ ¼æ¨¡å¼ä¸‹è®­ç»ƒå‰rå€¼ä¸ä¸€è‡´ï¼Œä¸­æ­¢æ‰§è¡Œ: {consistency_result['mismatched_layers']}")
                    raise ValueError(f"LoRAæ¨¡å‹rå€¼ä¸ä¸€è‡´: {consistency_result['mismatched_layers']}")
            else:
                logging.info("âœ… è®­ç»ƒå‰LoRAæ¨¡å‹rå€¼ä¸€è‡´æ€§æ£€æŸ¥é€šè¿‡")
        
        # è®­ç»ƒæ¨¡å‹
        logging.info("å¼€å§‹è®­ç»ƒæ¨¡å‹ï¼ˆæ”¯æŒå¤šGPUåˆ†å¸ƒï¼‰")
        logging.info(f"è®­ç»ƒå‚æ•°: epochs={config['num_epochs']}, lr={config['learning_rate']}")
        print(f"å¼€å§‹è®­ç»ƒæ¨¡å‹ï¼ˆæ”¯æŒå¤šGPUåˆ†å¸ƒï¼‰")
        profiler.record("å¼€å§‹è®­ç»ƒæ¨¡å‹")
        
        lora_model = train_lora_model(
            lora_model, 
            dataloader, 
            config["num_epochs"], 
            config["learning_rate"],
            config,
            output_adaptor_path
        )
        
        # è®­ç»ƒåå†æ¬¡æ£€æŸ¥rå€¼ä¸€è‡´æ€§
        if check_r_consistency:
            logging.info("å¼€å§‹è®­ç»ƒåLoRAæ¨¡å‹rå€¼ä¸€è‡´æ€§æ£€æŸ¥...")
            print("\nè®­ç»ƒåæ£€æŸ¥LoRAæ¨¡å‹rå€¼ä¸€è‡´æ€§...")
            
            consistency_result = check_lora_r_consistency(lora_model, config)
            
            if not consistency_result['is_consistent']:
                logging.warning("è®­ç»ƒåLoRAæ¨¡å‹rå€¼ä¸é…ç½®ä¸ä¸€è‡´")
                logging.warning(f"ä¸åŒ¹é…çš„å±‚: {consistency_result['mismatched_layers']}")
                logging.warning(f"æœŸæœ›rå€¼: {consistency_result['expected_r']}")
                logging.warning(f"å®é™…rå€¼: {consistency_result['actual_r_values']}")
                
                print("âš ï¸  è­¦å‘Šï¼šè®­ç»ƒåLoRAæ¨¡å‹rå€¼ä¸é…ç½®ä¸ä¸€è‡´")
                
                # ä¿å­˜æ£€æŸ¥ç»“æœåˆ°æ—¥å¿—
                import json
                consistency_log = os.path.join(output_adaptor_path, "r_consistency_check.json")
                with open(consistency_log, 'w') as f:
                    json.dump(consistency_result, f, indent=2)
                    
                logging.info(f"rå€¼ä¸€è‡´æ€§æ£€æŸ¥ç»“æœå·²ä¿å­˜åˆ°: {consistency_log}")
                print(f"rå€¼ä¸€è‡´æ€§æ£€æŸ¥ç»“æœå·²ä¿å­˜åˆ°: {consistency_log}")
            else:
                logging.info("âœ… è®­ç»ƒåLoRAæ¨¡å‹rå€¼ä¸€è‡´æ€§æ£€æŸ¥é€šè¿‡")
        
        # å°†æ¨¡å‹ç§»åˆ°CPUå¹¶åˆ†ç¦»è®¡ç®—å›¾
        logging.info("è®­ç»ƒå®Œæˆï¼Œå°†æ¨¡å‹ç§»åŠ¨åˆ°CPU...")
        lora_model = lora_model.cpu()
        for param in lora_model.parameters():
            param.requires_grad = False
            
        # æ¸…ç†ä¸éœ€è¦çš„å¯¹è±¡
        logging.info("æ¸…ç†è®­ç»ƒèµ„æº...")
        del base_model
        del tokenizer
        torch.cuda.empty_cache()
        
        logging.info(f"è®­ç»ƒå®Œæˆ: {pkg}-{version}")
        logging.info("=" * 60)
        
        return lora_model
        
    except Exception as e:
        logging.error(f"è®­ç»ƒè¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}")
        logging.error("é”™è¯¯è¯¦æƒ…:")
        logging.error(traceback.format_exc())
        
        print(f"åˆ›å»ºLoRAæ¨¡å‹æ—¶å‡ºé”™: {str(e)}")
        traceback.print_exc()
        
        # ç¡®ä¿æ¸…ç†æ‰€æœ‰å¯èƒ½çš„èµ„æº
        if 'base_model' in locals():
            del base_model
        if 'tokenizer' in locals():
            del tokenizer
        if 'lora_model' in locals():
            del lora_model
        torch.cuda.empty_cache()
        raise e
    
def merge_lora_weights(base_model, lora_models_paths, weights=None):
    """åˆå¹¶å¤šä¸ª LoRA æ¨¡å‹çš„æƒé‡"""
    if weights is None:
        weights = [1.0/len(lora_models_paths)] * len(lora_models_paths)
    if len(lora_models_paths) != len(weights):
        raise ValueError("æ¨¡å‹è·¯å¾„å’Œæƒé‡æ•°é‡å¿…é¡»ç›¸åŒ")
    
    # åŠ è½½ç¬¬ä¸€ä¸ªæ¨¡å‹ä½œä¸ºåŸºç¡€
    merged_model = load_lora_model_withPeft(base_model, lora_models_paths[0])
    
    # è·å–ç¬¬ä¸€ä¸ªæ¨¡å‹çš„æƒé‡å¹¶åº”ç”¨æƒé‡
    state_dict = merged_model.state_dict()
    for key in state_dict:
        if "lora" in key:
            state_dict[key] = state_dict[key] * weights[0]
    
    # åŠ è½½å…¶ä»–æ¨¡å‹å¹¶åˆå¹¶æƒé‡
    for i in range(1, len(lora_models_paths)):
        print(f"åŠ è½½ç¬¬{i}ä¸ªæ¨¡å‹{lora_models_paths[i]}")
        model_path = lora_models_paths[i]
        weight = weights[i]
        
        # ä¸´æ—¶åŠ è½½æ¨¡å‹
        temp_model = load_lora_model_withPeft(base_model, model_path)
        temp_state_dict = temp_model.state_dict()
        
        # åˆå¹¶æƒé‡
        for key in temp_state_dict:
            if "lora" in key and key in state_dict:
                state_dict[key] += temp_state_dict[key] * weight
    
    # å°†åˆå¹¶åçš„æƒé‡åŠ è½½åˆ°æ¨¡å‹ä¸­
    merged_model.load_state_dict(state_dict)
    return merged_model

# æ¨ç†


def inference(
        model, 
        tokenizer, 
        prompt,
        max_new_tokens=30,
        temperature=0.2,
        top_p=0.95,
        truncate=False,
        truncate_length=2048,
        inference_type="local",
        api_key=None,
        model_name=None,
        api_base_url=None,
        stop_tokens=None,
):
    """ä½¿ç”¨æ¨¡å‹è¿›è¡Œæ¨ç†ï¼Œæ”¯æŒæœ¬åœ°ã€HuggingFace APIå’ŒTogetherAI API
    Args:
        model: æœ¬åœ°æ¨¡å‹ï¼ˆä»…åœ¨inference_type="local"æ—¶ä½¿ç”¨ï¼‰
        tokenizer: åˆ†è¯å™¨ï¼ˆä»…åœ¨inference_type="local"æ—¶ä½¿ç”¨ï¼‰
        prompt: è¾“å…¥æç¤ºæ–‡æœ¬
        max_new_tokens: æœ€å¤§ç”Ÿæˆtokenæ•°
        temperature: æ¸©åº¦å‚æ•°
        top_p: top_på‚æ•°
        truncate: æ˜¯å¦æˆªæ–­è¾“å…¥
        truncate_length: æˆªæ–­é•¿åº¦
        inference_type: æ¨ç†ç±»å‹ ("local", "huggingface", "togetherai")
        api_key: APIå¯†é’¥ï¼ˆç”¨äºè¿œç¨‹APIï¼‰
        model_name: æ¨¡å‹åç§°ï¼ˆç”¨äºè¿œç¨‹APIï¼‰
        api_base_url: APIåŸºç¡€URLï¼ˆç”¨äºHuggingFace APIï¼‰
        stop_tokens: åœæ­¢è¯åˆ—è¡¨ï¼Œæ”¯æŒtokenåºåˆ—åŒ¹é…å’Œå­—ç¬¦ä¸²åŒ¹é…ï¼ˆä»…ç”¨äºæœ¬åœ°æ¨ç†ï¼‰
    Returns:
        str: ç”Ÿæˆçš„æ–‡æœ¬ï¼ˆä¸åŒ…å«åŸå§‹æç¤ºï¼‰
    """

    if inference_type == "local":
        return _local_inference(model, tokenizer, prompt, max_new_tokens, temperature, top_p, truncate, truncate_length, stop_tokens)
    else:
        from utils.callapi import _qdd_api_inference,_huggingface_api_inference,_togetherai_api_inference
        if inference_type == "huggingface":
            return _huggingface_api_inference(prompt, max_new_tokens, temperature, top_p, api_key, model_name, api_base_url)
        elif inference_type == "togetherai":
            return _togetherai_api_inference(prompt, max_new_tokens, temperature, top_p, api_key, model_name)
        elif inference_type == "qdd":
            return _qdd_api_inference(prompt, max_new_tokens, temperature, top_p, api_key, model_name, api_base_url)
        else:
            raise ValueError(f"Unsupported inference_type: {inference_type}")
from transformers import StoppingCriteria, StoppingCriteriaList
class MultiTokenStoppingCriteria(StoppingCriteria):
    def __init__(self, stop_tokens, tokenizer, original_input_length=None, check_last_chars=15, min_generated_length=30):
        """
        åœæ­¢æ¡ä»¶ç±»ï¼Œæ”¯æŒtokenåºåˆ—åŒ¹é…å’Œå­—ç¬¦ä¸²åŒ¹é…
        
        Args:
            stop_tokens: list of strings, åœæ­¢è¯åˆ—è¡¨
            tokenizer: åˆ†è¯å™¨
            original_input_length: int, åŸå§‹è¾“å…¥çš„é•¿åº¦ï¼ˆç”¨äºå­—ç¬¦ä¸²åŒ¹é…ï¼‰
            check_last_chars: int, æ£€æŸ¥æœ€åå‡ ä¸ªå­—ç¬¦ï¼ˆç”¨äºå­—ç¬¦ä¸²åŒ¹é…ï¼‰
            min_generated_length: int, æœ€å°ç”Ÿæˆé•¿åº¦ï¼ˆé¿å…è¿‡æ—©åœæ­¢ï¼‰
        """
        self.stop_tokens = stop_tokens
        self.tokenizer = tokenizer
        self.original_input_length = original_input_length
        self.check_last_chars = check_last_chars
        self.min_generated_length = min_generated_length
        
        # æå‰ç¼–ç æ‰€æœ‰åœè¯ï¼ˆæ”¯æŒå¤štokenåœè¯å¦‚ `<end>`ï¼‰
        self.encoded_stop_tokens = [
            self.tokenizer.encode(stop, add_special_tokens=False) 
            for stop in self.stop_tokens
        ]

    def __call__(self, input_ids, scores, **kwargs):
        """
        æ£€æŸ¥æ˜¯å¦åº”è¯¥åœæ­¢ç”Ÿæˆ
        åŒæ—¶æ”¯æŒtokenåºåˆ—åŒ¹é…å’Œå­—ç¬¦ä¸²åŒ¹é…ç­–ç•¥
        """
        current_tokens = input_ids[0].tolist()
        
        # å¦‚æœè®¾ç½®äº†åŸå§‹è¾“å…¥é•¿åº¦ï¼Œæ£€æŸ¥æ˜¯å¦è¾¾åˆ°æœ€å°ç”Ÿæˆé•¿åº¦
        if self.original_input_length is not None:
            generated_length = len(current_tokens) - self.original_input_length
            if generated_length < self.min_generated_length:
                return False
        
        # ç­–ç•¥1ï¼šTokenåºåˆ—åŒ¹é…ï¼ˆåŸæœ‰é€»è¾‘ï¼‰
        for stop_seq in self.encoded_stop_tokens:
            if len(stop_seq) > 0 and len(current_tokens) >= len(stop_seq):
                if current_tokens[-len(stop_seq):] == stop_seq:
                    return True
        
        # ç­–ç•¥2ï¼šå­—ç¬¦ä¸²åŒ¹é…ï¼ˆå…¼å®¹greedy_searchç­–ç•¥ï¼‰
        if self.original_input_length is not None and len(current_tokens) > self.original_input_length:
            # è·å–ç”Ÿæˆçš„éƒ¨åˆ†
            generated_tokens = current_tokens[self.original_input_length:]
            if len(generated_tokens) > 20:
                '''
                    ä»…å½“ç”Ÿæˆçš„tokené•¿åº¦å¤§äº20æ—¶ï¼Œæ‰è¿›è¡Œå­—ç¬¦ä¸²åŒ¹é…ï¼Œé˜²æ­¢å¼€å¤´çš„```pythonç›´æ¥è¢«æˆªæ–­
                '''
                try:
                    # Decodeç”Ÿæˆçš„éƒ¨åˆ†
                    generated_text = self.tokenizer.decode(generated_tokens, skip_special_tokens=True)
                    
                    # æ£€æŸ¥æœ€åNä¸ªå­—ç¬¦æ˜¯å¦åŒ…å«åœè¯
                    text_to_check = generated_text[-self.check_last_chars:] if len(generated_text) > self.check_last_chars else generated_text
                    
                    for stopword in self.stop_tokens:
                        if isinstance(stopword, str) and stopword in text_to_check:
                            return True
                            
                except Exception as e:
                    # å¦‚æœè§£ç å¤±è´¥ï¼Œè·³è¿‡å­—ç¬¦ä¸²æ£€æŸ¥
                    pass
        
        return False

# å®šä¹‰éœ€è¦åœæ­¢çš„æ ‡è®°ï¼ˆæ”¯æŒå¤šä¸ªï¼‰
def _local_inference(model, tokenizer, prompt, max_new_tokens, temperature, top_p, truncate, truncate_length, stop_tokens=None):
    """æœ¬åœ°æ¨ç†å®ç°
    
    Args:
        model: æ¨¡å‹
        tokenizer: åˆ†è¯å™¨
        prompt: è¾“å…¥æç¤º
        max_new_tokens: æœ€å¤§æ–°tokenæ•°
        temperature: æ¸©åº¦å‚æ•°
        top_p: top_på‚æ•°
        truncate: æ˜¯å¦æˆªæ–­
        truncate_length: æˆªæ–­é•¿åº¦
        stop_tokens: åœæ­¢è¯åˆ—è¡¨ï¼Œé»˜è®¤ä¸º["<end>","```","###"]
    """
    from utils.loraTrain.buildandloadData import encode_with_left_truncation    
    
    # ç¡®ä¿è¾“å…¥ä¸ä¼šå¤ªé•¿
    if truncate:
        max_input_length = truncate_length # è®¾ç½®åˆç†çš„æœ€å¤§è¾“å…¥é•¿åº¦
        inputs = encode_with_left_truncation(tokenizer,prompt,max_input_length,only_tokenize=False).to(model.device)
    else:
        inputs = tokenizer(
            prompt, 
            return_tensors="pt",
            truncation=False,
        ).to(model.device)

    # è·å–åŸå§‹è¾“å…¥é•¿åº¦
    original_input_length = len(inputs["input_ids"][0])
    
    # è®¾ç½®é»˜è®¤åœæ­¢è¯
    if stop_tokens is None:
        # ###æ˜¯loraä¸­å¸¸å‡ºç°çš„é—®é¢˜
        stop_tokens = ["<end>","```","###"]  # é»˜è®¤åœæ­¢è¯
    # åˆ›å»ºåœæ­¢æ¡ä»¶å®ä¾‹ï¼Œæ”¯æŒtokenåºåˆ—åŒ¹é…å’Œå­—ç¬¦ä¸²åŒ¹é…
    stopping_criteria = StoppingCriteriaList([
        MultiTokenStoppingCriteria(
            stop_tokens=stop_tokens, 
            tokenizer=tokenizer,
            original_input_length=original_input_length,
            check_last_chars=20,  # æ£€æŸ¥æœ€å20ä¸ªå­—ç¬¦
            min_generated_length=30  # æœ€å°ç”Ÿæˆé•¿åº¦
        )
    ])

    try:
        with torch.no_grad():
            outputs = model.generate(
                **inputs,
                max_new_tokens=max_new_tokens,
                temperature=temperature,     # è°ƒæ•´æ¸©åº¦
                top_p=top_p,         # è°ƒæ•´ top_p
                do_sample=True,
                pad_token_id=tokenizer.pad_token_id,
                eos_token_id=tokenizer.eos_token_id,
                use_cache=True,
                
                num_beams=1,        # ä½¿ç”¨ç®€å•é‡‡æ ·è€Œä¸æ˜¯æŸæœç´¢
                early_stopping=True,
                stopping_criteria=stopping_criteria,
                # min_length=10,      # è®¾ç½®æœ€å°é•¿åº¦
                # max_length=2048,    # è®¾ç½®æœ€å¤§é•¿åº¦
            )
        
        # åªè¿”å›æ–°ç”Ÿæˆçš„å†…å®¹ï¼ˆå»é™¤è¾“å…¥æç¤ºï¼‰
        prompt_length = len(inputs["input_ids"][0])
        generated_sequence = outputs[0][prompt_length:]
        
        return tokenizer.decode(generated_sequence, skip_special_tokens=True)
    
    except RuntimeError as e:
        traceback.print_exc()
        raise 


def check_lora_params(model):
    """
    æ£€æŸ¥æ¨¡å‹æ˜¯å¦åŒ…å«LoRAå‚æ•°
    Args:
        model: éœ€è¦æ£€æŸ¥çš„æ¨¡å‹
    Returns:
        has_lora: bool, æ˜¯å¦åŒ…å«LoRAå‚æ•°
        lora_params: list, æ‰€æœ‰LoRAå‚æ•°çš„åç§°å’Œå½¢çŠ¶
    """
    has_lora = False
    lora_params = []
    
    # éå†æ‰€æœ‰å‚æ•°
    for name, param in model.named_parameters():
        if 'lora' in name.lower():
            has_lora = True
            lora_params.append({
                'name': name,
                'shape': tuple(param.shape),
                'requires_grad': param.requires_grad
            })
    
    if has_lora:
        print("\nFound LoRA parameters:")
        for param in lora_params:
            print(f"Parameter: {param['name']}")
            print(f"Shape: {param['shape']}")
            print(f"Requires gradient: {param['requires_grad']}")
            print("-" * 40)
    else:
        print("\nNo LoRA parameters found in the model.")
    
    return has_lora, lora_params

def check_lora_r_consistency(model, config):
    """
    æ£€æŸ¥åŠ è½½åˆ°è®¾å¤‡çš„æ¨¡å‹çš„LoRAå‚æ•°çš„rå€¼æ˜¯å¦ä¸config["r"]ä¸€è‡´
    
    Args:
        model: å·²åŠ è½½çš„LoRAæ¨¡å‹
        config: é…ç½®å­—å…¸ï¼ŒåŒ…å«é¢„æœŸçš„rå€¼
    
    Returns:
        dict: åŒ…å«æ£€æŸ¥ç»“æœçš„å­—å…¸
            - is_consistent: bool, æ˜¯å¦ä¸€è‡´
            - expected_r: int, æœŸæœ›çš„rå€¼
            - actual_r_values: dict, å®é™…çš„rå€¼æ˜ å°„
            - mismatched_layers: list, ä¸åŒ¹é…çš„å±‚
    """
    expected_r = config.get("r", 8)  # é»˜è®¤rå€¼ä¸º8
    actual_r_values = {}
    mismatched_layers = []
    
    print(f"æ£€æŸ¥LoRAæ¨¡å‹çš„rå€¼ä¸€è‡´æ€§...")
    print(f"æœŸæœ›çš„rå€¼: {expected_r}")
    
    # æ£€æŸ¥æ˜¯å¦æœ‰LoRAé…ç½®
    if hasattr(model, 'peft_config') and model.peft_config:
        print(f"ä»PEFTé…ç½®ä¸­è·å–rå€¼:")
        for adapter_name, peft_config in model.peft_config.items():
            if hasattr(peft_config, 'r'):
                actual_r = peft_config.r
                actual_r_values[adapter_name] = actual_r
                print(f"  é€‚é…å™¨ '{adapter_name}': r = {actual_r}")
                
                if actual_r != expected_r:
                    mismatched_layers.append(adapter_name)
                    print(f"  âŒ ä¸åŒ¹é…: æœŸæœ› {expected_r}, å®é™… {actual_r}")
                else:
                    print(f"  âœ… åŒ¹é…")
    
    # é€šè¿‡å‚æ•°åç§°å’Œå½¢çŠ¶æ¨æ–­rå€¼
    print(f"\né€šè¿‡å‚æ•°å½¢çŠ¶æ¨æ–­rå€¼:")
    lora_a_params = {}
    lora_b_params = {}
    
    for name, param in model.named_parameters():
        if 'lora' in name.lower():
            if 'lora_a' in name.lower():
                # lora_Açš„å½¢çŠ¶é€šå¸¸æ˜¯ (r, input_dim)
                layer_name = name.replace('lora_A', '').replace('lora_a', '').replace('.weight', '')
                lora_a_params[layer_name] = param.shape[0]  # rå€¼
            elif 'lora_b' in name.lower():
                # lora_Bçš„å½¢çŠ¶é€šå¸¸æ˜¯ (output_dim, r)
                layer_name = name.replace('lora_B', '').replace('lora_b', '').replace('.weight', '')
                lora_b_params[layer_name] = param.shape[1]  # rå€¼
    
    # éªŒè¯lora_Aå’Œlora_Bçš„rå€¼ä¸€è‡´æ€§
    for layer_name in lora_a_params:
        if layer_name in lora_b_params:
            r_a = lora_a_params[layer_name]
            r_b = lora_b_params[layer_name]
            
            if r_a == r_b:
                actual_r_values[layer_name] = r_a
                print(f"  å±‚ '{layer_name}': r = {r_a}")
                
                if r_a != expected_r:
                    mismatched_layers.append(layer_name)
                    print(f"    âŒ ä¸åŒ¹é…: æœŸæœ› {expected_r}, å®é™… {r_a}")
                else:
                    print(f"    âœ… åŒ¹é…")
            else:
                print(f"  âŒ å±‚ '{layer_name}' çš„lora_Aå’Œlora_Bçš„rå€¼ä¸ä¸€è‡´: A={r_a}, B={r_b}")
                mismatched_layers.append(layer_name)
    
    # åˆ¤æ–­æ€»ä½“ä¸€è‡´æ€§
    is_consistent = len(mismatched_layers) == 0 and len(actual_r_values) > 0
    
    # ç»“æœæ€»ç»“
    print(f"\n=== LoRA rå€¼ä¸€è‡´æ€§æ£€æŸ¥ç»“æœ ===")
    print(f"æœŸæœ›rå€¼: {expected_r}")
    print(f"å®é™…æ£€æµ‹åˆ°çš„rå€¼: {set(actual_r_values.values()) if actual_r_values else 'æ— '}")
    print(f"æ€»ä½“ä¸€è‡´æ€§: {'âœ… ä¸€è‡´' if is_consistent else 'âŒ ä¸ä¸€è‡´'}")
    
    if mismatched_layers:
        print(f"ä¸åŒ¹é…çš„å±‚: {mismatched_layers}")
    
    if not actual_r_values:
        print("âš ï¸  è­¦å‘Š: æœªæ£€æµ‹åˆ°ä»»ä½•LoRAå‚æ•°")
    
    return {
        'is_consistent': is_consistent,
        'expected_r': expected_r,
        'actual_r_values': actual_r_values,
        'mismatched_layers': mismatched_layers
    }

def create_balanced_device_map(model_name_or_path, force_balance=False, exclude_cpu=True):
    """
    åˆ›å»ºå‡è¡¡çš„è®¾å¤‡æ˜ å°„ï¼Œå°†æ¨¡å‹å±‚å¹³å‡åˆ†é…åˆ°æ‰€æœ‰å¯ç”¨çš„GPUä¸Š
    
    Args:
        model_name_or_path: æ¨¡å‹åç§°æˆ–è·¯å¾„
        force_balance: bool, æ˜¯å¦å¼ºåˆ¶å‡è¡¡åˆ†é…ï¼ˆå³ä½¿æŸäº›GPUå†…å­˜ä¸è¶³ï¼‰
        exclude_cpu: bool, æ˜¯å¦æ’é™¤CPUè®¾å¤‡
    
    Returns:
        dict: å‡è¡¡çš„è®¾å¤‡æ˜ å°„å­—å…¸
    """
    print("åˆ›å»ºå‡è¡¡çš„è®¾å¤‡æ˜ å°„...")
    
    # æ£€æŸ¥CUDAå¯ç”¨æ€§
    if not torch.cuda.is_available():
        print("âŒ CUDAä¸å¯ç”¨ï¼Œæ— æ³•åˆ›å»ºGPUè®¾å¤‡æ˜ å°„")
        return "cpu" if not exclude_cpu else None
    
    # è·å–GPUæ•°é‡å’Œä¿¡æ¯
    num_gpus = torch.cuda.device_count()
    print(f"æ£€æµ‹åˆ° {num_gpus} ä¸ªGPUè®¾å¤‡")
    
    if num_gpus == 0:
        print("âŒ æ²¡æœ‰å¯ç”¨çš„GPUè®¾å¤‡")
        return "cpu" if not exclude_cpu else None
    
    # è·å–æ¯ä¸ªGPUçš„å†…å­˜ä¿¡æ¯
    gpu_memory_info = []
    for i in range(num_gpus):
        try:
            torch.cuda.set_device(i)
            torch.cuda.empty_cache()
            
            props = torch.cuda.get_device_properties(i)
            total_memory = props.total_memory
            allocated_memory = torch.cuda.memory_allocated(i)
            reserved_memory = torch.cuda.memory_reserved(i)
            free_memory = total_memory - max(allocated_memory, reserved_memory)
            
            gpu_info = {
                'device_id': i,
                'name': props.name,
                'total_memory_gb': total_memory / (1024**3),
                'free_memory_gb': free_memory / (1024**3),
                'utilization_percent': (allocated_memory / total_memory) * 100
            }
            gpu_memory_info.append(gpu_info)
            
            print(f"GPU {i} ({props.name}): "
                  f"{gpu_info['free_memory_gb']:.1f}GB free / "
                  f"{gpu_info['total_memory_gb']:.1f}GB total "
                  f"({gpu_info['utilization_percent']:.1f}% used)")
            
        except Exception as e:
            print(f"âŒ è·å–GPU {i} ä¿¡æ¯æ—¶å‡ºé”™: {e}")
            continue
    
    if not gpu_memory_info:
        print("âŒ æ— æ³•è·å–ä»»ä½•GPUä¿¡æ¯")
        return "cpu" if not exclude_cpu else None
    
    # è¿‡æ»¤å‡ºå¯ç”¨çš„GPUï¼ˆå†…å­˜è¶³å¤Ÿï¼‰
    min_memory_gb = 2.0  # æœ€å°å†…å­˜è¦æ±‚
    available_gpus = [gpu for gpu in gpu_memory_info if gpu['free_memory_gb'] >= min_memory_gb]
    
    if not available_gpus:
        print(f"âŒ æ²¡æœ‰GPUæœ‰è¶³å¤Ÿçš„å†…å­˜ï¼ˆéœ€è¦è‡³å°‘{min_memory_gb}GBï¼‰")
        if not force_balance:
            return "cpu" if not exclude_cpu else None
        else:
            print("âš ï¸  å¼ºåˆ¶å‡è¡¡æ¨¡å¼ï¼šå°†ä½¿ç”¨æ‰€æœ‰GPU")
            available_gpus = gpu_memory_info
    
    print(f"å¯ç”¨çš„GPU: {[gpu['device_id'] for gpu in available_gpus]}")
    
    # è·å–æ¨¡å‹å±‚ä¿¡æ¯
    try:
        from transformers import AutoConfig
        config = AutoConfig.from_pretrained(model_name_or_path, trust_remote_code=True)
        
        # å°è¯•è·å–å±‚æ•°
        num_layers = None
        if hasattr(config, 'num_hidden_layers'):
            num_layers = config.num_hidden_layers
        elif hasattr(config, 'num_layers'):
            num_layers = config.num_layers
        elif hasattr(config, 'n_layer'):
            num_layers = config.n_layer
        elif hasattr(config, 'n_layers'):
            num_layers = config.n_layers
        
        if num_layers is None:
            print("âš ï¸  æ— æ³•è‡ªåŠ¨æ£€æµ‹æ¨¡å‹å±‚æ•°ï¼Œä½¿ç”¨é»˜è®¤åˆ†é…ç­–ç•¥")
            # ä½¿ç”¨ç®€å•çš„è‡ªåŠ¨è®¾å¤‡æ˜ å°„
            device_map = "auto"
        else:
            print(f"æ£€æµ‹åˆ°æ¨¡å‹å±‚æ•°: {num_layers}")
            device_map = create_layer_balanced_mapping(num_layers, available_gpus, config)
            
    except Exception as e:
        print(f"âš ï¸  è·å–æ¨¡å‹é…ç½®æ—¶å‡ºé”™: {e}")
        print("ä½¿ç”¨ç®€å•çš„è‡ªåŠ¨è®¾å¤‡æ˜ å°„")
        device_map = "auto"
    
    return device_map

def create_layer_balanced_mapping(num_layers, available_gpus, model_config):
    """
    åˆ›å»ºå±‚çº§å‡è¡¡çš„è®¾å¤‡æ˜ å°„ï¼Œç¡®ä¿æ¯ä¸ªGPUåˆ†é…åˆ°å°½å¯èƒ½ç›¸ç­‰çš„å±‚æ•°
    
    Args:
        num_layers: æ¨¡å‹å±‚æ•°
        available_gpus: å¯ç”¨çš„GPUåˆ—è¡¨
        model_config: æ¨¡å‹é…ç½®
    
    Returns:
        dict: å±‚çº§è®¾å¤‡æ˜ å°„
    """
    num_gpus = len(available_gpus)
    device_map = {}
    
    # è®¡ç®—æ¯ä¸ªGPUåº”è¯¥åˆ†é…çš„å±‚æ•° - ä½¿ç”¨ç®€å•çš„å‡åŒ€åˆ†é…
    base_layers_per_gpu = num_layers // num_gpus
    extra_layers = num_layers % num_gpus
    
    print(f"å±‚æ•°å‡è¡¡åˆ†é…ç­–ç•¥:")
    print(f"  æ€»å±‚æ•°: {num_layers}")
    print(f"  å¯ç”¨GPU: {num_gpus}")
    print(f"  åŸºç¡€å±‚æ•°/GPU: {base_layers_per_gpu}")
    print(f"  é¢å¤–å±‚æ•°: {extra_layers}")
    
    # æ˜¾ç¤ºGPUå†…å­˜ä¿¡æ¯ï¼ˆä»…ä¾›å‚è€ƒï¼‰
    print(f"\nGPUå†…å­˜ä¿¡æ¯:")
    for gpu in available_gpus:
        print(f"  GPU {gpu['device_id']}: {gpu['free_memory_gb']:.1f}GB å¯ç”¨")
    
    # å‡åŒ€åˆ†é…å±‚æ•°ï¼Œé¢å¤–çš„å±‚åˆ†é…ç»™å‰å‡ ä¸ªGPU
    layer_assignments = []
    for i in range(num_gpus):
        # å‰ extra_layers ä¸ªGPUå¤šåˆ†é…ä¸€å±‚
        if i < extra_layers:
            assigned_layers = base_layers_per_gpu + 1
        else:
            assigned_layers = base_layers_per_gpu
        
        layer_assignments.append(assigned_layers)
        gpu_id = available_gpus[i]['device_id']
        print(f"  GPU {gpu_id}: {assigned_layers} å±‚")
    
    # éªŒè¯åˆ†é…æ˜¯å¦æ­£ç¡®
    total_assigned = sum(layer_assignments)
    assert total_assigned == num_layers, f"å±‚æ•°åˆ†é…é”™è¯¯: {total_assigned} != {num_layers}"
    print(f"âœ… éªŒè¯é€šè¿‡: æ€»åˆ†é…å±‚æ•° = {total_assigned}")
    
    # åˆ›å»ºè®¾å¤‡æ˜ å°„ - åªæ˜ å°„ç¡®å®å­˜åœ¨çš„ç»„ä»¶
    current_layer = 0
    
    # å°†åµŒå…¥å±‚åˆ†é…ç»™ç¬¬ä¸€ä¸ªGPUï¼Œè¾“å‡ºå±‚åˆ†é…ç»™æœ€åä¸€ä¸ªGPU
    first_gpu = available_gpus[0]['device_id']
    last_gpu = available_gpus[-1]['device_id']
    
    # åªåˆ†é…æ¨¡å‹å®é™…ä½¿ç”¨çš„å±‚ç»“æ„
    # åŸºäºæ¨¡å‹é…ç½®å’Œæ¶æ„æ¨æ–­å±‚åç§°
    # model_arch = getattr(model_config, 'architectures', [''])
    # arch_name = model_arch[0] if model_arch else ''
    arch_name = 'Llama'
    print(f"\næ£€æµ‹åˆ°æ¨¡å‹æ¶æ„: {arch_name}")
    
    # æ ¹æ®æ¶æ„ç¡®å®šå±‚å‘½åæ¨¡å¼
    layer_patterns = []
    embedding_patterns = []
    output_patterns = []
    norm_patterns = []
    rotary_patterns = []
    
    if 'Llama' in arch_name or 'llama' in arch_name.lower():
        layer_patterns = [f"model.layers.{i}" for i in range(num_layers)]
        embedding_patterns = ["model.embed_tokens"]
        output_patterns = ["lm_head"]
        norm_patterns = ["model.norm"]
        rotary_patterns = ["model.rotary_emb"]
    else:
        raise ValueError(f"ä¸æ”¯æŒçš„æ¨¡å‹æ¶æ„: {arch_name}")
    
    print(f"ä½¿ç”¨å±‚å‘½åæ¨¡å¼: {layer_patterns[:3]}...{layer_patterns[-3:] if len(layer_patterns) > 6 else layer_patterns[3:]}")
    
    # åˆ†é…åµŒå…¥å±‚åˆ°ç¬¬ä¸€ä¸ªGPU
    for pattern in embedding_patterns:
        device_map[pattern] = first_gpu
    
    # åˆ†é…è¾“å‡ºå±‚åˆ°æœ€åä¸€ä¸ªGPU
    for pattern in output_patterns:
        device_map[pattern] = last_gpu
    
    # åˆ†é…æ ‡å‡†åŒ–å±‚åˆ°æœ€åä¸€ä¸ªGPU
    for pattern in norm_patterns:
        device_map[pattern] = last_gpu
    for pattern in rotary_patterns:
        device_map[pattern] = first_gpu
    
    print(f"\nå±‚åˆ†é…è¯¦æƒ…:")
    
    # åˆ†é…transformerå±‚
    for gpu_idx, num_assigned_layers in enumerate(layer_assignments):
        device_id = available_gpus[gpu_idx]['device_id']
        
        start_layer = current_layer
        end_layer = current_layer + num_assigned_layers - 1
        
        if num_assigned_layers > 0:
            print(f"  GPU {device_id}: å±‚ {start_layer}-{end_layer} ({num_assigned_layers} å±‚)")
            
            for layer_idx in range(current_layer, current_layer + num_assigned_layers):
                if layer_idx < len(layer_patterns):
                    device_map[layer_patterns[layer_idx]] = device_id
            
            current_layer += num_assigned_layers
        else:
            print(f"  GPU {device_id}: æ— å±‚åˆ†é…")
    
    # ç»Ÿè®¡æ¯ä¸ªè®¾å¤‡çš„ç»„ä»¶æ•°é‡
    device_counts = {}
    for component, device in device_map.items():
        if device not in device_counts:
            device_counts[device] = 0
        device_counts[device] += 1
    
    print(f"\nè®¾å¤‡æ˜ å°„ç»Ÿè®¡:")
    for device_id in sorted(device_counts.keys()):
        print(f"  GPU {device_id}: {device_counts[device_id]} ä¸ªç»„ä»¶")
    
    print(f"\nåˆ›å»ºçš„è®¾å¤‡æ˜ å°„æ ·æœ¬:")
    # æŒ‰å±‚åºå·æ’åºæ˜¾ç¤ºæ ·æœ¬
    layer_keys = []
    other_keys = []
    
    for key in device_map.keys():
        if any(layer_pattern in key for layer_pattern in ["layers.", "h.", "block."]):
            layer_keys.append(key)
        else:
            other_keys.append(key)
    
    # æ˜¾ç¤ºä¸€äº›å±‚æ˜ å°„
    if layer_keys:
        layer_keys.sort()
        sample_layer_keys = layer_keys[:3] + layer_keys[-3:] if len(layer_keys) > 6 else layer_keys
        
        print("  å±‚æ˜ å°„:")
        for key in sample_layer_keys[:3]:
            print(f"    {key}: cuda:{device_map[key]}")
        
        if len(layer_keys) > 6:
            print(f"    ... ä¸­é—´ {len(layer_keys) - 6} å±‚ ...")
            for key in sample_layer_keys[-3:]:
                print(f"    {key}: cuda:{device_map[key]}")
    
    if other_keys:
        print("  å…¶ä»–ç»„ä»¶:")
        for key in other_keys:
            print(f"    {key}: cuda:{device_map[key]}")
    
    print(f"\næ€»æ˜ å°„æ•°é‡: {len(device_map)} ä¸ªç»„ä»¶")
    
    return device_map

def apply_balanced_device_map(model_name_or_path, device_map_config=None):
    """
    åº”ç”¨å‡è¡¡çš„è®¾å¤‡æ˜ å°„æ¥åŠ è½½æ¨¡å‹
    
    Args:
        model_name_or_path: æ¨¡å‹è·¯å¾„
        device_map_config: è®¾å¤‡æ˜ å°„é…ç½®å­—å…¸
            - force_balance: bool, æ˜¯å¦å¼ºåˆ¶å‡è¡¡
            - exclude_cpu: bool, æ˜¯å¦æ’é™¤CPU
            - min_memory_gb: float, æœ€å°å†…å­˜è¦æ±‚
    
    Returns:
        tuple: (model, tokenizer, device_map)
    """
    config = device_map_config or {}
    
    # åˆ›å»ºå‡è¡¡çš„è®¾å¤‡æ˜ å°„
    device_map = create_balanced_device_map(
        model_name_or_path,
        force_balance=config.get('force_balance', False),
        exclude_cpu=config.get('exclude_cpu', True)
    )
    
    if device_map is None:
        raise RuntimeError("æ— æ³•åˆ›å»ºæœ‰æ•ˆçš„è®¾å¤‡æ˜ å°„")
    
    print(f"ä½¿ç”¨è®¾å¤‡æ˜ å°„åŠ è½½æ¨¡å‹: {model_name_or_path}")
    
    # ä½¿ç”¨å‡è¡¡çš„è®¾å¤‡æ˜ å°„åŠ è½½æ¨¡å‹
    model, tokenizer = load_base_model(
        model_name_or_path,
        device_map=device_map,
        precision_from_arg=config.get('precision', 'fp16')
    )
    
    return model, tokenizer, device_map

def create_dynamic_device_map(model_name_or_path, balance_threshold=0.3, force_balance=False, exclude_cpu=True):
    """
    åˆ›å»ºåŠ¨æ€è®¾å¤‡æ˜ å°„ï¼šå…ˆå°è¯•autoåŠ è½½ï¼Œæ£€æŸ¥æ˜¯å¦å‡è¡¡ï¼Œå¦‚æœä¸å‡è¡¡åˆ™é‡æ–°å¹³è¡¡
    
    Args:
        model_name_or_path: æ¨¡å‹åç§°æˆ–è·¯å¾„
        balance_threshold: ä¸å‡è¡¡é˜ˆå€¼ (0.0-1.0)ï¼Œè¶…è¿‡æ­¤å€¼è®¤ä¸ºéœ€è¦é‡æ–°å¹³è¡¡
        force_balance: æ˜¯å¦å¼ºåˆ¶æ‰§è¡Œå¹³è¡¡
        exclude_cpu: æ˜¯å¦æ’é™¤CPUè®¾å¤‡
    
    Returns:
        tuple: (model, tokenizer, device_map_info)
    """
    print("ğŸ”„ å¯åŠ¨åŠ¨æ€è®¾å¤‡æ˜ å°„ç­–ç•¥...")
    
    # æ£€æŸ¥CUDAå¯ç”¨æ€§
    if not torch.cuda.is_available():
        print("âŒ CUDAä¸å¯ç”¨ï¼Œä½¿ç”¨CPU")
        model, tokenizer = load_base_model(model_name_or_path, device_map="cpu")
        return model, tokenizer, {"strategy": "cpu", "reason": "cuda_unavailable"}
    
    num_gpus = torch.cuda.device_count()
    if num_gpus <= 1:
        print(f"ğŸ”§ åªæœ‰ {num_gpus} ä¸ªGPUï¼Œä½¿ç”¨autoç­–ç•¥")
        model, tokenizer = load_base_model(model_name_or_path, device_map="auto")
        return model, tokenizer, {"strategy": "auto", "reason": "single_gpu"}
    
    # ç¬¬ä¸€æ­¥ï¼šå°è¯•autoåŠ è½½
    print("ğŸ“¥ ç¬¬1æ­¥ï¼šå°è¯•autoç­–ç•¥åŠ è½½æ¨¡å‹...")
    try:
        model, tokenizer = load_base_model(model_name_or_path, device_map="auto")
        print("âœ… autoç­–ç•¥åŠ è½½æˆåŠŸ")
        
        # æ£€æŸ¥æ¨¡å‹æ˜¯å¦æœ‰è®¾å¤‡æ˜ å°„
        if hasattr(model, 'hf_device_map'):
            device_map = model.hf_device_map
            print(f"ğŸ“Š æ£€æµ‹åˆ°è®¾å¤‡æ˜ å°„: {len(device_map)} ä¸ªç»„ä»¶")
            
            # åˆ†æåˆ†é…å‡è¡¡æ€§
            balance_info = analyze_device_balance(device_map)
            print(f"âš–ï¸  åˆ†é…å‡è¡¡æ€§åˆ†æ:")
            print(f"  ä¸å‡è¡¡ç³»æ•°: {balance_info['imbalance_ratio']:.3f}")
            print(f"  è®¾å¤‡åˆ†å¸ƒ: {balance_info['device_distribution']}")
            
            # åˆ¤æ–­æ˜¯å¦éœ€è¦é‡æ–°å¹³è¡¡
            needs_rebalance = balance_info['imbalance_ratio'] > balance_threshold
            
            if not needs_rebalance and not force_balance:
                print("âœ… åˆ†é…å·²ç»è¶³å¤Ÿå‡è¡¡ï¼Œä½¿ç”¨autoç­–ç•¥ç»“æœ")
                return model, tokenizer, {
                    "strategy": "auto", 
                    "reason": "already_balanced",
                    "balance_info": balance_info
                }
            else:
                print(f"âš ï¸  åˆ†é…ä¸å‡è¡¡ (é˜ˆå€¼: {balance_threshold:.2f})ï¼Œéœ€è¦é‡æ–°å¹³è¡¡")
                
                # é‡Šæ”¾å½“å‰æ¨¡å‹
                del model
                torch.cuda.empty_cache()
                
        else:
            print("âš ï¸  æ¨¡å‹æ²¡æœ‰è®¾å¤‡æ˜ å°„ä¿¡æ¯ï¼Œå°è¯•é‡æ–°å¹³è¡¡")
            del model
            torch.cuda.empty_cache()
            
    except Exception as e:
        print(f"âŒ autoç­–ç•¥åŠ è½½å¤±è´¥: {e}")
        print("ğŸ”„ å°è¯•ä½¿ç”¨balancedç­–ç•¥...")
    
    # ç¬¬äºŒæ­¥ï¼šä½¿ç”¨balancedç­–ç•¥é‡æ–°åŠ è½½
    print("ğŸ“¥ ç¬¬2æ­¥ï¼šä½¿ç”¨balancedç­–ç•¥é‡æ–°åŠ è½½...")
    try:
        balanced_device_map = create_balanced_device_map(
            model_name_or_path, 
            force_balance=force_balance, 
            exclude_cpu=exclude_cpu
        )
        
        if balanced_device_map is None:
            print("âŒ æ— æ³•åˆ›å»ºbalancedè®¾å¤‡æ˜ å°„")
            return None, None, {"strategy": "failed", "reason": "no_balanced_map"}
        
        model, tokenizer = load_base_model(model_name_or_path, device_map=balanced_device_map)
        print("âœ… balancedç­–ç•¥åŠ è½½æˆåŠŸ")
        
        # åˆ†ææ–°çš„åˆ†é…
        balance_info = None
        if hasattr(model, 'hf_device_map'):
            balance_info = analyze_device_balance(model.hf_device_map)
            print(f"ğŸ“Š é‡æ–°å¹³è¡¡åçš„åˆ†é…:")
            print(f"  ä¸å‡è¡¡ç³»æ•°: {balance_info['imbalance_ratio']:.3f}")
            print(f"  è®¾å¤‡åˆ†å¸ƒ: {balance_info['device_distribution']}")
        
        return model, tokenizer, {
            "strategy": "balanced", 
            "reason": "rebalanced",
            "balance_info": balance_info
        }
        
    except Exception as e:
        print(f"âŒ balancedç­–ç•¥ä¹Ÿå¤±è´¥: {e}")
        
        # ç¬¬ä¸‰æ­¥ï¼šå›é€€åˆ°autoç­–ç•¥
        print("ğŸ“¥ ç¬¬3æ­¥ï¼šå›é€€åˆ°autoç­–ç•¥...")
        try:
            model, tokenizer = load_base_model(model_name_or_path, device_map="auto")
            print("âœ… å›é€€åˆ°autoç­–ç•¥æˆåŠŸ")
            
            balance_info = None
            if hasattr(model, 'hf_device_map'):
                balance_info = analyze_device_balance(model.hf_device_map)
            
            return model, tokenizer, {
                "strategy": "auto_fallback", 
                "reason": "balanced_failed",
                "balance_info": balance_info
            }
            
        except Exception as fallback_error:
            print(f"âŒ æ‰€æœ‰ç­–ç•¥éƒ½å¤±è´¥: {fallback_error}")
            return None, None, {"strategy": "failed", "reason": "all_failed"}

def analyze_device_balance(device_map):
    """
    åˆ†æè®¾å¤‡æ˜ å°„çš„å‡è¡¡æ€§
    
    Args:
        device_map: è®¾å¤‡æ˜ å°„å­—å…¸
    
    Returns:
        dict: å‡è¡¡æ€§åˆ†æç»“æœ
    """
    # ç»Ÿè®¡æ¯ä¸ªè®¾å¤‡çš„ç»„ä»¶æ•°é‡
    device_counts = {}
    for component, device in device_map.items():
        device_str = str(device)
        if device_str not in device_counts:
            device_counts[device_str] = 0
        device_counts[device_str] += 1
    
    # è®¡ç®—æ€»ç»„ä»¶æ•°
    total_components = sum(device_counts.values())
    
    # è®¡ç®—ç†æƒ³çš„æ¯ä¸ªè®¾å¤‡ç»„ä»¶æ•°
    num_devices = len(device_counts)
    ideal_per_device = total_components / num_devices
    
    # è®¡ç®—ä¸å‡è¡¡ç³»æ•°
    max_deviation = 0
    for device, count in device_counts.items():
        deviation = abs(count - ideal_per_device) / ideal_per_device
        max_deviation = max(max_deviation, deviation)
    
    # åˆ†æå±‚åˆ†å¸ƒ (åªè€ƒè™‘transformerå±‚)
    layer_distribution = {}
    for component, device in device_map.items():
        if any(pattern in component for pattern in ['layers.', 'h.', 'block.']):
            device_str = str(device)
            if device_str not in layer_distribution:
                layer_distribution[device_str] = 0
            layer_distribution[device_str] += 1
    
    return {
        "imbalance_ratio": max_deviation,
        "device_distribution": device_counts,
        "layer_distribution": layer_distribution,
        "total_components": total_components,
        "ideal_per_device": ideal_per_device
    }

def get_precision_info():
    """
    è·å–æ”¯æŒçš„ç²¾åº¦ä¿¡æ¯å’Œé…ç½®ç¤ºä¾‹
    """
    info = """
    æ”¯æŒçš„æ¨¡å‹ç²¾åº¦é€‰é¡¹:
    
    1. 'fp16' (é»˜è®¤): åŠç²¾åº¦æµ®ç‚¹ï¼ŒèŠ‚çœå†…å­˜ï¼Œæ¨ç†é€Ÿåº¦å¿«
    2. 'fp32': å…¨ç²¾åº¦æµ®ç‚¹ï¼Œç²¾åº¦æœ€é«˜ï¼Œå ç”¨å†…å­˜æœ€å¤š
    3. 'bf16': Brain float 16ï¼Œåœ¨æŸäº›GPUä¸Šæ€§èƒ½æ›´å¥½
    
    é…ç½®ç¤ºä¾‹ï¼š
    åœ¨æ‚¨çš„é…ç½®æ–‡ä»¶ä¸­æ·»åŠ ï¼š
    {
        "precision": "fp16",  // æˆ– "fp32", "bf16"
        "model_name": "your_model_path",
        ...
    }
    
    æˆ–åœ¨å‡½æ•°è°ƒç”¨ä¸­ä¼ é€’ï¼š
    load_base_model(model_path, device_map="auto", precision="fp16")
    """
    print(info)
    return info

# ä½¿ç”¨ç¤ºä¾‹å’Œæ–‡æ¡£
"""
å¢å¼ºçš„åœæ­¢æ¡ä»¶ä½¿ç”¨ç¤ºä¾‹ï¼š

1. åŸºç¡€ä½¿ç”¨ï¼ˆé»˜è®¤åœæ­¢è¯ï¼‰ï¼š
   result = inference(model, tokenizer, prompt, max_new_tokens=100)

2. è‡ªå®šä¹‰åœæ­¢è¯ï¼ˆtokenåºåˆ—åŒ¹é…ï¼‰ï¼š
   stop_tokens = ["<end>", "</s>", "<|endoftext|>"]
   result = inference(model, tokenizer, prompt, max_new_tokens=100, stop_tokens=stop_tokens)

3. è‡ªå®šä¹‰åœæ­¢è¯ï¼ˆå­—ç¬¦ä¸²åŒ¹é…ï¼‰ï¼š
   stop_tokens = ["END", "STOP", "##"]
   result = inference(model, tokenizer, prompt, max_new_tokens=100, stop_tokens=stop_tokens)

4. æ··åˆåœæ­¢è¯ï¼ˆåŒæ—¶æ”¯æŒtokenåºåˆ—å’Œå­—ç¬¦ä¸²åŒ¹é…ï¼‰ï¼š
   stop_tokens = ["<end>", "END", "STOP", "</s>"]
   result = inference(model, tokenizer, prompt, max_new_tokens=100, stop_tokens=stop_tokens)

åœæ­¢æ¡ä»¶ç­–ç•¥è¯´æ˜ï¼š
- ç­–ç•¥1ï¼šTokenåºåˆ—åŒ¹é… - æ£€æŸ¥ç”Ÿæˆçš„tokenåºåˆ—æ˜¯å¦ä»¥åœæ­¢è¯çš„tokenåºåˆ—ç»“å°¾
- ç­–ç•¥2ï¼šå­—ç¬¦ä¸²åŒ¹é… - å°†ç”Ÿæˆçš„tokenè§£ç ä¸ºæ–‡æœ¬ï¼Œæ£€æŸ¥æœ€åNä¸ªå­—ç¬¦æ˜¯å¦åŒ…å«åœæ­¢è¯
- ä¸¤ç§ç­–ç•¥å¹¶è¡Œå·¥ä½œï¼Œä»»ä¸€ç­–ç•¥åŒ¹é…éƒ½ä¼šè§¦å‘åœæ­¢
- è®¾ç½®æœ€å°ç”Ÿæˆé•¿åº¦ï¼ˆé»˜è®¤30ä¸ªtokenï¼‰ä»¥é¿å…è¿‡æ—©åœæ­¢
- å…¼å®¹ greedy_search ä¸­çš„åœæ­¢ç­–ç•¥

å‚æ•°è¯´æ˜ï¼š
- stop_tokens: åœæ­¢è¯åˆ—è¡¨ï¼Œæ”¯æŒå¤šç§æ ¼å¼çš„åœæ­¢è¯
- check_last_chars: å­—ç¬¦ä¸²åŒ¹é…æ—¶æ£€æŸ¥çš„æœ€åå­—ç¬¦æ•°ï¼ˆé»˜è®¤15ï¼‰
- min_generated_length: æœ€å°ç”Ÿæˆé•¿åº¦ï¼Œé¿å…è¿‡æ—©åœæ­¢ï¼ˆé»˜è®¤30ï¼‰

=====================================================================

æ–°å¢åŠŸèƒ½ä½¿ç”¨ç¤ºä¾‹ï¼š

1. æ£€æŸ¥LoRAæ¨¡å‹çš„rå€¼ä¸€è‡´æ€§ï¼š
   ```python
   # åŠ è½½LoRAæ¨¡å‹
   lora_model = getEquipAdaptorModel(config)
   
   # æ£€æŸ¥rå€¼ä¸€è‡´æ€§
   result = check_lora_r_consistency(lora_model, config)
   
   if result['is_consistent']:
       print("âœ… LoRA rå€¼ä¸€è‡´")
   else:
       print(f"âŒ LoRA rå€¼ä¸ä¸€è‡´: {result['mismatched_layers']}")
       print(f"æœŸæœ›: {result['expected_r']}")
       print(f"å®é™…: {result['actual_r_values']}")
   ```

2. åˆ›å»ºå‡è¡¡çš„è®¾å¤‡æ˜ å°„ï¼š
   ```python
   # åˆ›å»ºå‡è¡¡çš„è®¾å¤‡æ˜ å°„
   device_map = create_balanced_device_map(
       model_name_or_path="your_model_path",
       force_balance=False,  // æ˜¯å¦å¼ºåˆ¶å‡è¡¡
       exclude_cpu=True      // æ˜¯å¦æ’é™¤CPU
   )
   
   # ä½¿ç”¨å‡è¡¡çš„è®¾å¤‡æ˜ å°„åŠ è½½æ¨¡å‹
   model, tokenizer, actual_device_map = apply_balanced_device_map(
       model_name_or_path="your_model_path",
       device_map_config={
           'force_balance': False,
           'exclude_cpu': True,
           'precision': 'fp16'
       }
   )
   ```

3. åœ¨ç°æœ‰è®­ç»ƒæµç¨‹ä¸­é›†æˆï¼š
   ```python
   # åœ¨é…ç½®ä¸­æ·»åŠ å‡è¡¡è®¾å¤‡æ˜ å°„é€‰é¡¹
   config = {
       "model_name": "your_model_path",
       "r": 16,
       "alpha": 32,
       "target_modules": ["q_proj", "v_proj"],
       "target_layers": [0, 1, 2, 3],
       "use_balanced_device_map": True,  // å¯ç”¨å‡è¡¡è®¾å¤‡æ˜ å°„
       "force_balance": False,
       "exclude_cpu": True
   }
   
   # è®­ç»ƒå‰æ£€æŸ¥
   if config.get("use_balanced_device_map", False):
       print("ä½¿ç”¨å‡è¡¡è®¾å¤‡æ˜ å°„...")
       device_map = create_balanced_device_map(
           config["model_name"],
           force_balance=config.get("force_balance", False),
           exclude_cpu=config.get("exclude_cpu", True)
       )
       config["device_map"] = device_map
   
   # è®­ç»ƒLoRAæ¨¡å‹
   lora_model = buildandTrainLoraModel(config, dataloader, precision='fp16')
   
   # è®­ç»ƒåæ£€æŸ¥rå€¼ä¸€è‡´æ€§
   consistency_result = check_lora_r_consistency(lora_model, config)
   if not consistency_result['is_consistent']:
       print("âš ï¸  è­¦å‘Šï¼šè®­ç»ƒåçš„æ¨¡å‹rå€¼ä¸é…ç½®ä¸ä¸€è‡´")
   ```

4. è®¾å¤‡æ˜ å°„é…ç½®é€‰é¡¹ï¼š
   - force_balance: å¼ºåˆ¶å‡è¡¡åˆ†é…ï¼Œå³ä½¿æŸäº›GPUå†…å­˜ä¸è¶³
   - exclude_cpu: æ’é™¤CPUè®¾å¤‡ï¼Œåªä½¿ç”¨GPU
   - min_memory_gb: æœ€å°å†…å­˜è¦æ±‚ï¼ˆé»˜è®¤2GBï¼‰
   - precision: æ¨¡å‹ç²¾åº¦ï¼ˆfp16/fp32/bf16ï¼‰

5. é«˜çº§ç”¨æ³• - è‡ªå®šä¹‰å†…å­˜æƒé‡ï¼š
   ```python
   # è·å–GPUä¿¡æ¯å¹¶è‡ªå®šä¹‰åˆ†é…ç­–ç•¥
   device_map = create_balanced_device_map(
       model_name_or_path="your_model_path",
       force_balance=True,    // å¼ºåˆ¶ä½¿ç”¨æ‰€æœ‰GPU
       exclude_cpu=True       // æ’é™¤CPU
   )
   
   # æ‰‹åŠ¨è°ƒæ•´è®¾å¤‡æ˜ å°„ï¼ˆå¦‚æœéœ€è¦ï¼‰
   if isinstance(device_map, dict):
       # å¯ä»¥æ‰‹åŠ¨è°ƒæ•´ç‰¹å®šå±‚çš„è®¾å¤‡åˆ†é…
       device_map["model.layers.0"] = 0  // å°†ç¬¬0å±‚å¼ºåˆ¶åˆ†é…ç»™GPU 0
   ```

åŠŸèƒ½ç‰¹ç‚¹ï¼š
- ğŸ” è‡ªåŠ¨æ£€æŸ¥LoRAå‚æ•°çš„rå€¼ä¸€è‡´æ€§
- âš–ï¸ æ ¹æ®GPUå†…å­˜å®¹é‡æ™ºèƒ½åˆ†é…æ¨¡å‹å±‚
- ğŸ¯ æ”¯æŒå¤šç§æ¨¡å‹æ¶æ„çš„å±‚å‘½åæ¨¡å¼
- ğŸ›¡ï¸ åŒ…å«é”™è¯¯å¤„ç†å’Œå›é€€æœºåˆ¶
- ğŸ“Š è¯¦ç»†çš„è®¾å¤‡ä½¿ç”¨æƒ…å†µæŠ¥å‘Š
- ğŸ”§ çµæ´»çš„é…ç½®é€‰é¡¹

æ³¨æ„äº‹é¡¹ï¼š
- å‡è¡¡è®¾å¤‡æ˜ å°„ä¸»è¦é’ˆå¯¹å¤šGPUç¯å¢ƒä¼˜åŒ–
- åœ¨å•GPUç¯å¢ƒä¸­ä¼šè‡ªåŠ¨å›é€€åˆ°æ ‡å‡†çš„device_map="auto"
- å¼ºåˆ¶å‡è¡¡æ¨¡å¼å¯èƒ½ä¼šå¯¼è‡´æŸäº›GPUè¿‡è½½ï¼Œè¯·è°¨æ…ä½¿ç”¨
- rå€¼æ£€æŸ¥æ”¯æŒPEFTé…ç½®å’Œå‚æ•°å½¢çŠ¶ä¸¤ç§æ£€æŸ¥æ–¹å¼
"""