'''
æ•°æ®é¢„è¿‡æ»¤ï¼Œæ£€æŸ¥æ˜¯å¦éœ€è¦è®­ç»ƒ
'''
import json
import os
import logging
from utils.loraTrain.loraTrainUtils import loraModelExists


def getTrainDataItems(corpus_path, pkg, version, model_config):
    """
    è·å–è®­ç»ƒæ•°æ®é¡¹
    
    Args:
        corpus_path: è¯­æ–™åº“è·¯å¾„
        pkg: åŒ…å
        version: ç‰ˆæœ¬å·
        model_config: æ¨¡å‹é…ç½®
        
    Returns:
        tuple: (original_count, files_info) - (åŸå§‹æ•°æ®é‡, è¿‡æ»¤åçš„æ•°æ®)
    """
    try:
        files_info = []
        data_file_path = f"{corpus_path}/{pkg}/{version}.jsonl"
        with open(data_file_path, "r", encoding="utf-8") as f:
            for line in f:
                files_info.append(json.loads(line))
    except FileNotFoundError:
        logging.error(f"æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {data_file_path}")
        return None, None
        
    original_count = len(files_info)
    if model_config["override_data_percentage"] is not None:
        files_info = files_info[:int(len(files_info)*float(model_config["override_data_percentage"]))]
    else:
        files_info = files_info[:int(len(files_info)*model_config["traindata_percentage"])]
    return original_count, files_info


def prefilter_package_version(pkg, version, config, corpus_path, knowledge_type='docstring'):
    """
    é¢„è¿‡æ»¤åŒ…ç‰ˆæœ¬ï¼Œæ£€æŸ¥æ˜¯å¦éœ€è¦è®­ç»ƒ
    
    Args:
        pkg: åŒ…å
        version: ç‰ˆæœ¬å·  
        config: é…ç½®ä¿¡æ¯
        corpus_path: è¯­æ–™åº“è·¯å¾„
        knowledge_type: çŸ¥è¯†ç±»å‹
        
    Returns:
        tuple: (should_train, reason, data_count)
        - should_train: æ˜¯å¦éœ€è¦è®­ç»ƒ
        - reason: è·³è¿‡è®­ç»ƒçš„åŸå› ï¼ˆå¦‚æœä¸éœ€è¦è®­ç»ƒï¼‰
        - data_count: å¯ç”¨è®­ç»ƒæ•°æ®æ¡æ•°
    """
    try:
        model_name = config.get("model_name").split("/")[-1]
        
        # 1. æ£€æŸ¥LoRAæ¨¡å‹æ˜¯å¦å·²å­˜åœ¨
        if loraModelExists(pkg, version, model_name, config, knowledge_type=knowledge_type):
            return False, "lora_model_exists", 0
        
        # 2. è·å–å¹¶æ£€æŸ¥è®­ç»ƒæ•°æ®
        original_count, files_info = getTrainDataItems(corpus_path, pkg, version, config)
        
        if original_count is None or files_info is None:
            return False, "data_file_not_found", 0
            
        if len(files_info) == 0:
            return False, "no_training_data_after_percentage", original_count
        
        return True, "needs_training", len(files_info)
        
    except Exception as e:
        logging.error(f"é¢„è¿‡æ»¤åŒ…ç‰ˆæœ¬æ—¶å‡ºé”™ {pkg}-{version}: {e}")
        return False, f"error: {str(e)}", 0


def apply_prefilter_to_package_versions(pack_versions, config, corpus_path, knowledge_type='docstring', log_details=True):
    """
    å¯¹æ‰€æœ‰åŒ…ç‰ˆæœ¬åº”ç”¨é¢„è¿‡æ»¤
    
    Args:
        pack_versions: åŒ…ç‰ˆæœ¬å­—å…¸
        config: é…ç½®ä¿¡æ¯
        corpus_path: è¯­æ–™åº“è·¯å¾„  
        knowledge_type: çŸ¥è¯†ç±»å‹
        log_details: æ˜¯å¦è¾“å‡ºè¯¦ç»†æ—¥å¿—
        
    Returns:
        tuple: (filtered_pack_versions, stats)
        - filtered_pack_versions: è¿‡æ»¤åçš„åŒ…ç‰ˆæœ¬å­—å…¸
        - stats: ç»Ÿè®¡ä¿¡æ¯å­—å…¸
    """
    filtered_pack_versions = {}
    stats = {
        'total': 0,
        'needs_training': 0,
        'lora_exists': 0,
        'no_data': 0,
        'errors': 0,
        'details': []
    }
    
    if log_details:
        logging.info("ğŸ” å¼€å§‹é¢„è¿‡æ»¤åŒ…ç‰ˆæœ¬...")
    
    for pkg, versions in pack_versions.items():
        filtered_versions = []
        
        for version in versions:
            stats['total'] += 1
            
            should_train, reason, data_count = prefilter_package_version(
                pkg, version, config, corpus_path, knowledge_type
            )
            
            if should_train:
                filtered_versions.append(version)
                stats['needs_training'] += 1
                if log_details:
                    logging.debug(f"âœ… éœ€è¦è®­ç»ƒ: {pkg}-{version} (æ•°æ®é‡: {data_count})")
            else:
                if reason == "lora_model_exists":
                    stats['lora_exists'] += 1
                elif "no_training_data" in reason or "data_file_not_found" in reason:
                    stats['no_data'] += 1
                elif "error:" in reason:
                    stats['errors'] += 1
                
                if log_details:
                    logging.debug(f"â­ï¸ è·³è¿‡: {pkg}-{version} ({reason})")
                    
                stats['details'].append({
                    'pkg': pkg,
                    'version': version,
                    'reason': reason,
                    'data_count': data_count
                })
        
        if filtered_versions:
            filtered_pack_versions[pkg] = filtered_versions
    
    if log_details:
        logging.info(f"ğŸ“Š é¢„è¿‡æ»¤ç»Ÿè®¡:")
        logging.info(f"  æ€»åŒ…ç‰ˆæœ¬: {stats['total']}")
        logging.info(f"  éœ€è¦è®­ç»ƒ: {stats['needs_training']} ({stats['needs_training']/stats['total']*100:.1f}%)")
        logging.info(f"  æ¨¡å‹å·²å­˜åœ¨: {stats['lora_exists']} ({stats['lora_exists']/stats['total']*100:.1f}%)")  
        logging.info(f"  æ— è®­ç»ƒæ•°æ®: {stats['no_data']} ({stats['no_data']/stats['total']*100:.1f}%)")
        logging.info(f"  æ£€æŸ¥é”™è¯¯: {stats['errors']}")
    
    return filtered_pack_versions, stats