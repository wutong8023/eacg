import json
import sys
import os
import asyncio
import aiofiles
from concurrent.futures import ThreadPoolExecutor, as_completed
import time
from threading import Lock

# 添加项目根目录到路径
sys.path.append(os.path.join(os.path.dirname(__file__), '../../..'))
from utils.callapi import _qdd_api_inference
from config.apikey import QDD_APIKEY

# 线程锁，用于安全写入文件
write_lock = Lock()

with open("data/VersiBCB_Benchmark/vscc_datas.json","r") as f:
    vscc_datas = json.load(f)

def getIDcode(datas, id):
    for data in datas:
        if data["id"] == id:
            return data
    return None

def getErrorInfos(datas, id):
    for data in datas:
        if data["id"] == id:
            return data["error_infos"]
    return None

def buildQueryOnly(codeinfo, error_infos):
    '''
    仅根据error_infos生成query，不生成fix
    '''
    code = codeinfo["code"]
    dependency = codeinfo["dependency"]
    
    # 格式化error_infos为字符串
    error_infos_str = ""
    for error_info in error_infos:
        error_infos_str += f"Error ID: {error_info.get('error_id', 'N/A')}\n"
        error_infos_str += f"Error: {error_info.get('error_info', 'N/A')}\n\n"
    
    prompt = f"""
You are a helpful assistant that generates queries for code errors that need more information or clarification.

Dependency:
{dependency}

Here is the code:
{code}

Here is the error infos generated by static analysis for the code:
{error_infos_str}

Your task is to analyze these errors and generate queries for situations where you need more information to provide a proper fix. You should generate queries for:
1. Errors related to external APIs or libraries where the correct usage might have changed
2. Errors where the intended behavior is unclear
3. Errors that might be false positives from static analysis tools
4. Complex errors that require domain knowledge

For each query, provide:
* **`error_ids`**: An array of strings, listing the IDs of the errors addressed by this query.
* **`target_api_path`**: The API path that the error is related to (e.g., "sklearn.feature_extraction.text.TfidfVectorizer.get_feature_names_out").
* **`query_content`**: A clear question asking for more information to resolve the error.
* **`explanation`**: Brief explanation of why this query is needed.

## Examples:
- target_api_path: "sklearn.feature_extraction.text.TfidfVectorizer"
- query_content: "What is the correct method to get feature names from TfidfVectorizer in the current version?"
- explanation: "The error indicates get_feature_names_out is unknown, but this might be a version issue."

## Notes:
1. Focus on errors that genuinely require external information or clarification
2. Avoid generating queries for simple syntax errors or obvious missing imports
3. Consider that some static analysis errors might be false positives
4. Group related errors into single queries when appropriate

The final output should be a JSON object with queries array:
{{
    "queries": [{{
        "error_ids": ["error_0001", "error_0002"],
        "target_api_path": "matplotlib.pyplot.subplots",
        "query_content": "What is the correct way to use plt.subplots with ax parameter in seaborn functions?",
        "explanation": "The error suggests ax parameter issue with seaborn.pairplot, need to clarify correct usage pattern."
    }}]
}}

Please respond with ONLY the JSON object, no additional text.
"""

    try:
        # 调用QDD API进行推理
        response = _qdd_api_inference(
            prompt=prompt,
            max_new_tokens=1024,
            temperature=0.7,
            top_p=0.95,
            api_key=QDD_APIKEY,
            model_name="@cf/meta/llama-3.1-8b-instruct",
            api_base_url=None
        )
        
        # 尝试解析JSON响应
        try:
            result = json.loads(response)
            return result
        except json.JSONDecodeError:
            # 如果直接解析失败，尝试提取JSON部分
            import re
            json_match = re.search(r'\{.*\}', response, re.DOTALL)
            if json_match:
                result = json.loads(json_match.group())
                return result
            else:
                return {"error": f"无法解析API响应: {response[:100]}..."}
                
    except Exception as e:
        return {"error": f"调用API时发生错误: {str(e)}"}

def process_single_id(data_item, output_file):
    """
    处理单个ID的函数，用于并发执行
    """
    id = data_item["id"]
    start_time = time.time()
    
    # 初始化结果对象
    result = {
        "id": id,
        "timestamp": time.strftime("%Y-%m-%d %H:%M:%S"),
        "status": "processing"
    }
    
    try:
        # 获取代码信息
        codeinfo = getIDcode(vscc_datas, id)
        if codeinfo is None:
            result.update({
                "status": "error",
                "error": f"未找到ID {id} 对应的代码信息",
                "processing_time": time.time() - start_time
            })
            write_result_to_jsonl(result, output_file)
            return result
            
        # 获取错误信息
        error_infos = data_item.get("error_infos", [])
        if not error_infos:
            result.update({
                "status": "error", 
                "error": f"未找到ID {id} 对应的错误信息",
                "processing_time": time.time() - start_time
            })
            write_result_to_jsonl(result, output_file)
            return result
            
        # 生成查询
        query_info = buildQueryOnly(codeinfo, error_infos)
        
        if query_info and "queries" in query_info and query_info["queries"]:
            # 为每个query添加原始ID信息
            for query in query_info["queries"]:
                query["original_id"] = id
                
            result.update({
                "status": "success",
                "queries": query_info["queries"],
                "query_count": len(query_info["queries"]),
                "error_count": len(error_infos),
                "processing_time": time.time() - start_time
            })
        elif query_info and "error" in query_info:
            result.update({
                "status": "api_error",
                "error": query_info["error"],
                "processing_time": time.time() - start_time
            })
        else:
            result.update({
                "status": "no_queries",
                "message": "未生成查询（可能是简单错误或静态分析误报）",
                "error_count": len(error_infos),
                "processing_time": time.time() - start_time
            })
            
    except Exception as e:
        result.update({
            "status": "exception",
            "error": str(e),
            "processing_time": time.time() - start_time
        })
    
    # 写入结果
    write_result_to_jsonl(result, output_file)
    return result

def write_result_to_jsonl(result, output_file):
    """
    线程安全地将结果写入JSONL文件
    """
    with write_lock:
        with open(output_file, 'a', encoding='utf-8') as f:
            f.write(json.dumps(result, ensure_ascii=False) + '\n')

def run_concurrent_processing(combined_errors_vscc, max_workers=5, output_file="data/temp/query_results_concurrent.jsonl"):
    """
    并发处理所有ID
    """
    # 清空输出文件
    with open(output_file, 'w', encoding='utf-8') as f:
        pass
    
    print(f"开始并发处理 {len(combined_errors_vscc)} 个数据项，最大并发数: {max_workers}")
    print(f"结果将保存到: {output_file}")
    
    start_time = time.time()
    successful_count = 0
    error_count = 0
    
    # 使用ThreadPoolExecutor进行并发处理
    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        # 提交所有任务
        future_to_id = {
            executor.submit(process_single_id, data_item, output_file): data_item["id"] 
            for data_item in combined_errors_vscc
        }
        
        # 处理完成的任务
        for i, future in enumerate(as_completed(future_to_id)):
            id = future_to_id[future]
            try:
                result = future.result()
                if result["status"] == "success":
                    successful_count += 1
                    print(f"✓ [{i+1}/{len(combined_errors_vscc)}] ID {id}: 成功生成 {result.get('query_count', 0)} 个查询 ({result.get('processing_time', 0):.2f}s)")
                elif result["status"] == "no_queries":
                    successful_count += 1
                    print(f"- [{i+1}/{len(combined_errors_vscc)}] ID {id}: 无需生成查询 ({result.get('processing_time', 0):.2f}s)")
                else:
                    error_count += 1
                    print(f"✗ [{i+1}/{len(combined_errors_vscc)}] ID {id}: {result.get('error', 'Unknown error')} ({result.get('processing_time', 0):.2f}s)")
                    
            except Exception as exc:
                error_count += 1
                print(f"✗ [{i+1}/{len(combined_errors_vscc)}] ID {id}: 处理异常 - {exc}")
    
    total_time = time.time() - start_time
    
    print(f"\n=== 处理完成 ===")
    print(f"总处理时间: {total_time:.2f}s")
    print(f"成功处理: {successful_count}")
    print(f"处理失败: {error_count}")
    print(f"平均处理时间: {total_time/len(combined_errors_vscc):.2f}s")
    print(f"结果已保存到: {output_file}")

def analyze_results(output_file):
    """
    分析处理结果
    """
    print(f"\n=== 结果分析 ===")
    try:
        with open(output_file, 'r', encoding='utf-8') as f:
            results = [json.loads(line) for line in f if line.strip()]
        
        total_queries = 0
        status_counts = {}
        
        for result in results:
            status = result.get("status", "unknown")
            status_counts[status] = status_counts.get(status, 0) + 1
            
            if result.get("queries"):
                total_queries += len(result["queries"])
        
        print(f"总结果数: {len(results)}")
        print(f"状态分布:")
        for status, count in status_counts.items():
            print(f"  {status}: {count}")
        print(f"总查询数: {total_queries}")
        
    except Exception as e:
        print(f"分析结果时出错: {e}")

if __name__ == "__main__":
    # 加载数据
    with open("data/temp/combined_errors_vscc_depre_new.json","r") as f:
        combined_errors_vscc = json.load(f)
    
    # 运行并发处理
    output_file = "data/generated_queries/queries_for_vscc_bd.jsonl"
    max_workers = 3  # 可调整并发数
    
    run_concurrent_processing(combined_errors_vscc, max_workers, output_file)
    
    # 分析结果
    analyze_results(output_file) 