# GPUå†…å­˜åˆ†æå™¨ (GPUMemoryProfiler)

ä¸€ä¸ªåŠŸèƒ½å¼ºå¤§çš„GPUå†…å­˜ç›‘æ§å’Œåˆ†æå·¥å…·ï¼Œä¸“é—¨ä¸ºæ·±åº¦å­¦ä¹ è®­ç»ƒï¼ˆç‰¹åˆ«æ˜¯LoRAå¾®è°ƒï¼‰è®¾è®¡ã€‚

## ğŸš€ ä¸»è¦åŠŸèƒ½

### 1. å®æ—¶å†…å­˜ç›‘æ§
- è·Ÿè¸ªGPUå†…å­˜åˆ†é…å’Œä¿ç•™æƒ…å†µ
- è®°å½•æœ€å¤§å†…å­˜ä½¿ç”¨é‡
- æ—¶é—´æˆ³è®°å½•å’Œè€—æ—¶ç»Ÿè®¡

### 2. è¯¦ç»†æ—¥å¿—è®°å½•
- è‡ªåŠ¨ç”Ÿæˆå¸¦æ—¶é—´æˆ³çš„æ—¥å¿—æ–‡ä»¶
- åŒæ—¶è¾“å‡ºåˆ°æ§åˆ¶å°å’Œæ–‡ä»¶
- æ”¯æŒé¢å¤–ä¿¡æ¯è®°å½•

### 3. å¼ é‡å’Œæ¨¡å‹ä¿¡æ¯è®°å½•
- è®°å½•å¼ é‡çš„å½¢çŠ¶ã€æ•°æ®ç±»å‹ã€å¤§å°
- ç»Ÿè®¡æ¨¡å‹å‚æ•°æ•°é‡å’Œå¤§å°
- åˆ†æå¯è®­ç»ƒå‚æ•°

### 4. å¤šç§æŠ¥å‘Šæ ¼å¼
- æ§åˆ¶å°æ—¶é—´çº¿æŠ¥å‘Š
- è¯¦ç»†çš„æ‘˜è¦æŠ¥å‘Š
- JSONæ ¼å¼æ•°æ®å¯¼å‡º

## ğŸ“¦ å®‰è£…å’Œä½¿ç”¨

### åŸºæœ¬ä½¿ç”¨

```python
from memoryCheck import GPUMemoryProfiler

# åˆ›å»ºåˆ†æå™¨
profiler = GPUMemoryProfiler(
    log_dir="logs/my_training",  # æ—¥å¿—ç›®å½•
    enable_file_logging=True     # å¯ç”¨æ–‡ä»¶æ—¥å¿—
)

# è®°å½•äº‹ä»¶
profiler.record("æ¨¡å‹åˆ›å»º")
profiler.record("å‰å‘ä¼ æ’­", "loss=0.1234")

# è®°å½•è¯¦ç»†ä¿¡æ¯
tensor_info = {'input': input_tensor, 'output': output_tensor}
model_info = {'total_params': 1000000, 'trainable_params': 500000}
profiler.record_detailed("è®­ç»ƒæ­¥éª¤", tensor_info=tensor_info, model_info=model_info)

# ç”ŸæˆæŠ¥å‘Š
profiler.print_report()
summary = profiler.generate_summary_report()
json_file = profiler.save_to_json()

# æ¸…ç†èµ„æº
profiler.cleanup()
```

### åœ¨LoRAè®­ç»ƒä¸­ä½¿ç”¨

```python
def train_lora_with_profiling():
    profiler = GPUMemoryProfiler(log_dir="logs/lora_training")
    
    # è®°å½•è®­ç»ƒå¼€å§‹
    profiler.record("è®­ç»ƒå¼€å§‹")
    
    # æ¨¡å‹åˆ›å»º
    lora_A = torch.randn(r, hidden_size, device='cuda', requires_grad=True)
    lora_B = torch.randn(hidden_size, r, device='cuda', requires_grad=True)
    
    tensor_info = {'lora_A': lora_A, 'lora_B': lora_B}
    model_info = {
        'total_params': lora_A.numel() + lora_B.numel(),
        'trainable_params': lora_A.numel() + lora_B.numel()
    }
    profiler.record_detailed("LoRAæ¨¡å‹åˆ›å»º", tensor_info=tensor_info, model_info=model_info)
    
    # è®­ç»ƒå¾ªç¯
    for epoch in range(num_epochs):
        profiler.record(f"Epoch {epoch+1} å¼€å§‹")
        
        for batch in dataloader:
            # å‰å‘ä¼ æ’­
            loss = model(batch)
            profiler.record("å‰å‘ä¼ æ’­", f"loss={loss.item():.4f}")
            
            # åå‘ä¼ æ’­
            loss.backward()
            profiler.record("åå‘ä¼ æ’­")
            
            # å‚æ•°æ›´æ–°
            optimizer.step()
            optimizer.zero_grad()
            profiler.record("å‚æ•°æ›´æ–°")
    
    # ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š
    profiler.print_report()
    profiler.generate_summary_report()
    profiler.save_to_json()
    profiler.cleanup()
```

## ğŸ“Š è¾“å‡ºç¤ºä¾‹

### æ§åˆ¶å°è¾“å‡º
```
==== GPU Memory Timeline =====
åˆå§‹åŒ–               | Allocated:    0.0MB | Reserved:    0.0MB
æ¨¡å‹åˆ›å»º             | Allocated:  128.0MB | Reserved:  256.0MB
å‰å‘ä¼ æ’­             | Allocated:  512.0MB | Reserved:  768.0MB
åå‘ä¼ æ’­             | Allocated:  768.0MB | Reserved: 1024.0MB
å‚æ•°æ›´æ–°             | Allocated:  512.0MB | Reserved:  768.0MB
```

### æ—¥å¿—æ–‡ä»¶å†…å®¹
```
2024-01-15 10:30:15 - MemoryProfiler_20240115_103015 - INFO - ================================================================================
2024-01-15 10:30:15 - MemoryProfiler_20240115_103015 - INFO - GPUå†…å­˜åˆ†æå™¨åˆå§‹åŒ–
2024-01-15 10:30:15 - MemoryProfiler_20240115_103015 - INFO - ================================================================================
2024-01-15 10:30:15 - MemoryProfiler_20240115_103015 - INFO - æ—¥å¿—æ–‡ä»¶: logs/lora_training/memory_profiler_20240115_103015.log
2024-01-15 10:30:15 - MemoryProfiler_20240115_103015 - INFO - CUDAå¯ç”¨: True
2024-01-15 10:30:15 - MemoryProfiler_20240115_103015 - INFO - GPUæ•°é‡: 4
2024-01-15 10:30:15 - MemoryProfiler_20240115_103015 - INFO - GPU 0: NVIDIA A100-SXM4-40GB (40.0GB)
2024-01-15 10:30:16 - MemoryProfiler_20240115_103015 - INFO - äº‹ä»¶: è®­ç»ƒå¼€å§‹ | åˆ†é…:    0.0MB | ä¿ç•™:    0.0MB | æœ€å¤§åˆ†é…:    0.0MB | æœ€å¤§ä¿ç•™:    0.0MB | è€—æ—¶: 0.00s
2024-01-15 10:30:17 - MemoryProfiler_20240115_103015 - INFO - äº‹ä»¶: æ¨¡å‹åˆ›å»º | åˆ†é…:  128.0MB | ä¿ç•™:  256.0MB | æœ€å¤§åˆ†é…:  128.0MB | æœ€å¤§ä¿ç•™:  256.0MB | è€—æ—¶: 1.23s
```

### JSONæ•°æ®æ ¼å¼
```json
{
  "è®­ç»ƒå¼€å§‹": [
    {
      "time": 0.0,
      "allocated": 0.0,
      "reserved": 0.0,
      "max_allocated": 0.0,
      "max_reserved": 0.0,
      "timestamp": "2024-01-15T10:30:16.123456"
    }
  ],
  "æ¨¡å‹åˆ›å»º": [
    {
      "time": 1.23,
      "allocated": 128.0,
      "reserved": 256.0,
      "max_allocated": 128.0,
      "max_reserved": 256.0,
      "timestamp": "2024-01-15T10:30:17.456789"
    }
  ]
}
```

## ğŸ”§ é«˜çº§åŠŸèƒ½

### 1. å†…å­˜æ³„æ¼æ£€æµ‹
```python
# ç›‘æ§å†…å­˜å¢é•¿
initial_memory = torch.cuda.memory_allocated()
# ... æ‰§è¡Œæ“ä½œ ...
final_memory = torch.cuda.memory_allocated()
growth = final_memory - initial_memory

if growth > threshold:
    profiler.record("å†…å­˜æ³„æ¼è­¦å‘Š", f"å¢é•¿={growth:.2f}MB")
```

### 2. å³°å€¼å†…å­˜åˆ†æ
```python
# è·å–å³°å€¼å†…å­˜ä½¿ç”¨
peak_allocated = torch.cuda.max_memory_allocated()
peak_reserved = torch.cuda.max_memory_reserved()

profiler.record("å³°å€¼å†…å­˜", f"åˆ†é…={peak_allocated:.2f}MB, ä¿ç•™={peak_reserved:.2f}MB")
```

### 3. è‡ªå®šä¹‰å†…å­˜æ¸…ç†
```python
def custom_memory_cleanup():
    torch.cuda.empty_cache()
    torch.cuda.synchronize()
    profiler.record("è‡ªå®šä¹‰æ¸…ç†")
```

## ğŸ“ˆ æ€§èƒ½ä¼˜åŒ–å»ºè®®

### 1. å†…å­˜ä½¿ç”¨ä¼˜åŒ–
- ä½¿ç”¨è¾ƒå°çš„æ‰¹æ¬¡å¤§å°
- å¯ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹
- ä½¿ç”¨æ··åˆç²¾åº¦è®­ç»ƒ
- åŠæ—¶æ¸…ç†ä¸­é—´å˜é‡

### 2. ç›‘æ§ç­–ç•¥
- åœ¨å…³é”®èŠ‚ç‚¹è®°å½•å†…å­˜ä½¿ç”¨
- å®šæœŸç”Ÿæˆæ‘˜è¦æŠ¥å‘Š
- è®¾ç½®å†…å­˜ä½¿ç”¨é˜ˆå€¼è­¦å‘Š
- ä¿å­˜å†å²æ•°æ®ç”¨äºåˆ†æ

### 3. æ—¥å¿—ç®¡ç†
- å®šæœŸæ¸…ç†æ—§æ—¥å¿—æ–‡ä»¶
- ä½¿ç”¨æœ‰æ„ä¹‰çš„æ—¥å¿—ç›®å½•ç»“æ„
- ä¸ºä¸åŒå®éªŒä½¿ç”¨ä¸åŒçš„æ—¥å¿—ç›®å½•

## ğŸ› æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

1. **CUDAä¸å¯ç”¨**
   ```python
   if not torch.cuda.is_available():
       print("CUDAä¸å¯ç”¨ï¼Œä½¿ç”¨CPUæ¨¡å¼")
   ```

2. **å†…å­˜ä¸è¶³**
   ```python
   try:
       # æ‰§è¡Œå†…å­˜å¯†é›†å‹æ“ä½œ
       pass
   except torch.cuda.OutOfMemoryError:
       profiler.record("å†…å­˜ä¸è¶³é”™è¯¯")
       torch.cuda.empty_cache()
   ```

3. **æ—¥å¿—æ–‡ä»¶è¿‡å¤§**
   ```python
   # å®šæœŸæ¸…ç†æ—¥å¿—
   import os
   if os.path.getsize(log_file) > max_size:
       # å‹ç¼©æˆ–åˆ é™¤æ—§æ—¥å¿—
       pass
   ```

## ğŸ“ æµ‹è¯•

è¿è¡Œæµ‹è¯•å¥—ä»¶ï¼š
```bash
python tests/testProfiler.py
```

è¿è¡Œä½¿ç”¨ç¤ºä¾‹ï¼š
```bash
python utils/memoryDebug/example_usage.py
```

## ğŸ¤ è´¡çŒ®

æ¬¢è¿æäº¤Issueå’ŒPull Requestæ¥æ”¹è¿›è¿™ä¸ªå·¥å…·ï¼

## ï¿½ï¿½ è®¸å¯è¯

MIT License 