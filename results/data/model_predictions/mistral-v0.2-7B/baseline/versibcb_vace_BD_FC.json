[
    {
        "id": 0,
        "answer": " <start>\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\ndef task_func(df, target_values=[1, 3, 4]):\n    df = df.fillna(0).astype(int)\n    df[~df.isin(target_values).all(axis=1)] = 0\n    plt.figure(figsize=(10, 5))\n    for column in df.columns:\n        sns.kdeplot(df[column], label=column, warn_singular=False)\n    plt.legend()\n    return df\n<end>"
    },
    {
        "id": 1,
        "answer": " <start>\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\ndef task_func(df, target_values=[1, 3, 4]):\n    df = df.fillna(0)  # Fill NaN values with 0\n    df = df.mask(df.isin(target_values), other=1).astype(int)  # Replace non-target values with 0 and convert to int\n    df = df.astype(float)  # Convert back to float for kdeplot\n\n    plt.figure(figsize=(10, 5))\n    sns.kdeplot(df, shade=True)  # Plot the distribution of each column\n    for column in df.columns:\n        sns.kdeplot(df[column], shade=False, label=column)  # Plot each column separately with no shade\n    plt.legend()\n    return df, plt.gca()\n<end>"
    },
    {
        "id": 2,
        "answer": " <start>\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\ndef task_func(df, target_values=[1, 3, 4]):\n    # Replace elements not in target_values with 0 using .mask()\n    df = df.mask(df.isin(target_values).all(axis=1), other=0, axis=0)\n\n    # Plot the distribution of each column\n    plt.figure(figsize=(10, 5))\n    for column in df.columns:\n        # Check if the column has non-zero values to avoid KDE error\n        if df[column].nunique() > 1:  # Ensure there is variation in the data\n            sns.kdeplot(df[column], label=column)\n        else:\n            # If all values are zero, plot a vertical line at zero\n            plt.axvline(0, label=column, linestyle='--', color='gray')\n\n    plt.legend()\n    return df, plt.gca()\n<end>"
    },
    {
        "id": 3,
        "answer": " <start>\nimport numpy as np\nimport pandas as pd\nfrom scipy import stats\nimport matplotlib.pyplot as plt\n\nTARGET_VALUES = np.array([1, 3, 4])\n\ndef task_func(df):\n    # Ensure the DataFrame contains only positive values\n    if (df <= 0).any().any():\n        raise ValueError(\"Input DataFrame should contain only positive values.\")\n\n    df = df.mask(df.isin(TARGET_VALUES), other=0)\n\n    transformed_df = pd.DataFrame()\n\n    fig, ax = plt.subplots(figsize=(10, 8))\n\n    for column in df.columns:\n        # Check if data is constant\n        if df[column].nunique() == 1:\n            transformed_df[column] = df[column]\n        else:\n            transformed_data, _ = stats.boxcox(\n                df[column] + 1\n            )  # Add 1 since the are some null values\n            transformed_df[column] = transformed_data\n\n            # Using matplotlib's kde method to plot the KDE\n            kde = stats.gaussian_kde(transformed_df[column])\n            ax.plot(kde.support, kde(kde.support), label=column)\n\n    ax.legend()\n    plt.show()\n    return transformed_df\n<end>"
    },
    {
        "id": 4,
        "answer": " <start>\n```python\nimport time\nimport random\nimport matplotlib.pyplot as plt\nfrom datetime import datetime as dt\nfrom dateutil.relativedelta import relativedelta\n\n# Constants\nDATE_FORMAT = \"%Y-%m-%d %H:%M:%S\"\n\ndef task_func(n, output_path=None):\n    timestamps = []\n    for _ in range(n):\n        timestamp = int(round(time.time() * 1000))  # Use int() to ensure timestamp is an integer\n        formatted_time = dt.utcfromtimestamp(timestamp / 1000).strftime(DATE_FORMAT)\n        timestamps.append(formatted_time)\n\n    timestamps_as_datetime = [dt.strptime(t, DATE_FORMAT) for t in timestamps]\n    plt.hist(timestamps_as_datetime)\n\n    if output_path:\n        plt.savefig(output_path)\n    else:\n        plt.show()\n    return timestamps\n```\n<end>"
    },
    {
        "id": 5,
        "answer": " <start>\nimport pandas as pd\nimport seaborn as sns\n\n# Constants\nCOLUMNS = ['col1', 'col2', 'col3']\n\ndef task_func(data):\n    df = pd.DataFrame(data, columns=COLUMNS)\n\n    # Group by 'col1' and 'col2' and perform aggregation using nunique() on 'col3'\n    analyzed_df = df.groupby(COLUMNS[:-1])['col3'].nunique().reset_index()\n\n    # Create a distribution plot of the 'col3' column of the previous dataframe using seaborn\n    ax = sns.distplot(analyzed_df['col3'])\n\n    return analyzed_df, ax\n<end>"
    },
    {
        "id": 6,
        "answer": " <start>\n```python\nimport pandas as pd\nfrom datetime import datetime\nimport holidays\n\ndef task_func(start_date: datetime = datetime(2023, 1, 1), end_date: datetime = datetime(2023, 12, 31), country: str = 'US'):\n    if not isinstance(start_date, datetime) or not isinstance(end_date, datetime):\n        raise ValueError(\"start_date and end_date must be datetime objects.\")\n    if start_date > end_date:\n        raise ValueError(\"start_date must not be after end_date.\")\n\n    # For UK in holidays 0.64, we need to specify state\n    if country == 'GB':\n        country_holidays = holidays.CountryHoliday(country, province='England')\n    else:\n        country_holidays = holidays.CountryHoliday(country)\n\n    dates = pd.date_range(start_date, end_date)\n    business_days = [date for date in dates if date.weekday() < 5 and date not in country_holidays]\n\n    return business_days\n```\n<end>"
    },
    {
        "id": 7,
        "answer": " <start>\nimport pandas as pd\nfrom datetime import datetime\nfrom holidays import HolidayCalendar, USFederalHolidayCalendar\n\ndef task_func(start_date=datetime(2023, 1, 1), end_date=datetime(2023, 12, 31), country='US'):\n    if not isinstance(start_date, datetime) or not isinstance(end_date, datetime):\n        raise ValueError(\"start_date and end_date must be datetime objects.\")\n    if start_date > end_date:\n        raise ValueError(\"start_date must not be after end_date.\")\n\n    calendar = HolidayCalendar(country=country, baseurl='https://github.com/garybernhardt/holidays/releases/download/v0.64/')\n    if country == 'US':\n        calendar += USFederalHolidayCalendar()\n\n    dates = pd.date_range(start_date, end_date)\n    business_days = [date for date in dates if date.weekday() < 5 and date not in calendar.holidays()]\n\n    return business_days\n<end>"
    },
    {
        "id": 8,
        "answer": " <start>\n```python\nimport json\nimport random\nimport pytz\nfrom datetime import datetime\n\n# Constants\nDATA = [\n    {'name': 'John', 'age': 30, 'city': 'New York'},\n    {'name': 'Peter', 'age': 35, 'city': 'London'},\n    {'name': 'Susan', 'age': 25, 'city': 'Sydney'},\n    {'name': 'Alice', 'age': 28, 'city': 'Paris'},\n    {'name': 'Bob', 'age': 40, 'city': 'Tokyo'},\n    {'name': 'Charlie', 'age': 22, 'city': 'Beijing'},\n    {'name': 'David', 'age': 33, 'city': 'Mumbai'},\n    {'name': 'Eve', 'age': 27, 'city': 'Berlin'},\n    {'name': 'Frank', 'age': 32, 'city': 'Moscow'},\n    {'name': 'Grace', 'age': 29, 'city': 'Rome'}\n]\n\ndef task_func(utc_datetime, seed=0):\n    random.seed(seed)\n\n    # Import pytz to create a UTC timezone object\n    utc = pytz.utc\n\n    # Choose a random person\n    person = random.choice(DATA)\n\n    # Set the UTC timestamp\n    person['timestamp'] = utc.localize(utc_datetime).isoformat()\n\n    # Encode the person's data as a JSON string\n    person_json_str = json.dumps(person)\n\n    return person_json_str\n```\n<end>"
    },
    {
        "id": 9,
        "answer": " <start>\nimport http.server\nimport json\nfrom typing import Dict\n\nclass PostRequestHandler(http.server.BaseHTTPRequestHandler):\n\n    def do_POST(self):\n        content_type = self.headers.get('Content-Type')\n\n        if content_type != 'application/json':\n            self.send_error(400, 'Content-Type header is not application/json')\n            return\n\n        length = int(self.headers.get('content-length'))\n        data = json.loads(self.rfile.read(length))\n\n        if 'data' not in data:\n            self.send_error(400, 'No data received')\n            return\n\n        self.send_response(200)\n        self.send_header('Content-type', 'application/json')\n        self.end_headers()\n        self.wfile.write(json.dumps({'status': 'success', 'message': 'Data received successfully.'}).encode())\n\n    def send_error(self, status_code: int, message: str):\n        error_response: Dict[str, str] = {'status': 'error', 'message': message}\n        self.send_response(status_code)\n        self.send_header('Content-type', 'application/json')\n        self.end_headers()\n        self.wfile.write(json.dumps(error_response).encode())\n<end>"
    },
    {
        "id": 10,
        "answer": " <start>\nimport math\nimport numpy as np\nfrom datetime import datetime\nimport pandas as pd\n\ndef task_func(\n    start_time,\n    end_time,\n    step,\n    columns=pd.DataFrame.columns,\n    sensor_statuses=pd.DataFrame.columns,\n    random_seed=42,\n):\n    np.random.seed(random_seed)\n\n    if start_time > end_time:\n        raise ValueError(\"start_time cannot be after end_time\")\n    if step <= 0:\n        raise ValueError(\"step must be positive\")\n    if len(columns) != 5:\n        raise ValueError(\"columns must have exactly 5 elements\")\n\n    timestamps = list(range(start_time, end_time, step))\n\n    data = []\n    for ts in timestamps:\n        dt = datetime.utcfromtimestamp(ts / 1000).strftime(\"%Y-%m-%d %H:%M:%S.%f\")\n        sensor1 = math.sin(ts / 1000) + np.random.normal(0, 0.1)\n        sensor2 = math.cos(ts / 1000) + np.random.normal(0, 0.1)\n        sensor3 = math.tan(ts / 1000) + np.random.normal(0, 0.1)\n        status = np.random.choice(sensor_statuses)\n        row = [dt, sensor1, sensor2, sensor3, status]\n        data.append(row)\n\n    return pd.DataFrame(data, columns=columns)\n<end>"
    },
    {
        "id": 11,
        "answer": " <start>\nimport math\nimport numpy as np\nfrom datetime import datetime\nimport pandas as pd\n\ndef task_func(\n    start_time,\n    end_time,\n    step,\n    columns=pd.DataFrame.columns,\n    sensor_statuses=pd.DataFrame.columns,\n    random_seed=42,\n):\n    np.random.seed(random_seed)\n\n    if start_time > end_time:\n        raise ValueError(\"start_time cannot be after end_time\")\n    if step < 0:\n        raise ValueError(\"step must be positive\")\n\n    timestamps = list(range(start_time, end_time, step))\n\n    data = []\n    for ts in timestamps:\n        dt = datetime.utcfromtimestamp(ts / 1000).strftime(\"%Y-%m-%d %H:%M:%S.%f\")\n        sensor1 = math.sin(ts / 1000) + np.random.normal(0, 0.1)\n        sensor2 = math.cos(ts / 1000) + np.random.normal(0, 0.1)\n        sensor3 = math.tan(ts / 1000) + np.random.normal(0, 0.1)\n        status = np.random.choice(sensor_statuses)\n        row = [dt] + [sensor1, sensor2, sensor3] + [status]\n        data.append(row)\n\n    return pd.DataFrame(data, columns=columns + [sensor_statuses[0]])\n<end>"
    },
    {
        "id": 12,
        "answer": " <start>\n```python\nimport datetime\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef task_func(start_time, end_time, step, amplitude, period, seed=0):\n    if period <= 0 or step < 1:\n        raise ValueError(\"Invalid input values\")\n\n    timestamps = pd.date_range(start=datetime.utcfromtimestamp(start_time / 1000), end=datetime.utcfromtimestamp(end_time / 1000), freq='{}ms'.format(step))\n\n    if amplitude == 0:\n        values = timestamps\n    else:\n        values = np.random.normal(size=len(timestamps))\n\n    data = []\n    for i, ts in enumerate(timestamps):\n        value = values[i] + amplitude * np.sin(2 * np.pi * (timestamps.index - timestamps.first_valid_index()) / period.total_seconds())\n        data.append([ts, value])\n\n    df = pd.DataFrame(data, columns=[\"Timestamp\", \"Value\"])\n\n    ax = df.plot(x=\"Timestamp\", y=\"Value\", title=\"Time Series with Seasonality\")\n    ax.set_ylabel(\"Value\")\n    return ax\n```\n<end>"
    },
    {
        "id": 13,
        "answer": " <start>\n```python\nimport random\nimport datetime\nimport matplotlib.pyplot as plt\n\ndef task_func(epoch_milliseconds: int, seed: int = None):\n    CATEGORIES = [\"Electronics\", \"Clothing\", \"Home\", \"Books\", \"Sports\"]\n\n    if seed is not None:\n        random.seed(seed)\n\n    start_time = datetime.utcfromtimestamp(epoch_milliseconds // 1000)\n    current_time = datetime.utcnow()\n\n    if start_time > current_time:\n        raise ValueError(\"Start date must be before current time.\")\n\n    days_diff = (current_time - start_time).days\n    sales_data = {category: [0] * days_diff for category in CATEGORIES}\n\n    for i in range(days_diff):\n        for category in CATEGORIES:\n            sales = random.randint(10, 50)\n            sales_data[category][i] += sales\n\n    fig, ax = plt.subplots()\n    for category, sales in sales_data.items():\n        ax.plot(range(days_diff), sales, label=category)\n\n    ax.set_xlabel(\"Days since \" + start_time.strftime(\"%Y-%m-%d %H:%M:%S\"))\n    ax.set_ylabel(\"Sales\")\n    ax.legend()\n\n    return sales_data, ax\n```\n<end>"
    },
    {
        "id": 14,
        "answer": " <start>\nimport pandas as pd\nimport openpyxl\nimport os\n\ndef task_func(json_str, filename, sheet_name=\"sheet1\"):\n\n    if not isinstance(json_str, (str, bytes, bytearray)):\n        raise TypeError(\"json_str must be a string, bytes, or bytearray\")\n\n    try:\n        data = pd.read_json(json_str)\n\n        # Initialize Excel workbook and sheet\n        workbook = openpyxl.Workbook()\n        worksheet = workbook.active\n\n        # Check if DataFrame is empty and proceed accordingly\n        if not data.empty:\n            for col_index, col in enumerate(data.columns):\n                worksheet.cell(row=1, column=col_index+1, value=col)\n            for row_index, row in data.iterrows():\n                for col_index, col in enumerate(data.columns):\n                    worksheet.cell(row=row_index+2, column=col_index+1, value=row[col])\n        workbook.save(filename)\n        return os.path.abspath(filename)\n    except ValueError as e:\n        raise ValueError(f\"Invalid JSON string: {e}\")\n    except Exception as e:\n        raise Exception(f\"Error in file writing: {e}\")\n<end>"
    },
    {
        "id": 15,
        "answer": " <start>\n```python\nimport collections\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport seaborn as sns\n\ndef task_func(list_of_menuitems):\n    if not list_of_menuitems:\n        print(\"No items to plot.\")\n        return None\n\n    # Flatten the nested list into a single list of items\n    flat_list = list(flatten(list_of_menuitems))\n    if not flat_list:\n        print(\"No items to plot.\")\n        return None\n\n    # Count the occurrence of each item\n    counter = collections.Counter(flat_list)\n\n    # Convert the counter to a DataFrame\n    df = pd.DataFrame(list(counter.items()), columns=['Item', 'Count'])\n\n    # Ensure there is data to plot\n    if df.empty:\n        print(\"No items to plot.\")\n        return None\n\n    # Create a seaborn barplot\n    sns.set(style=\"whitegrid\")\n    ax = sns.barplot(x='Count', y='Item', data=df, palette=\"viridis\")\n\n    plt.tight_layout()  # Adjust the layout to make room for the item labels\n    return ax\n\ndef flatten(nested_list):\n    return [item for sublist in nested_list for item in flatten(sublist) if item is not None]\n```\n<end>"
    },
    {
        "id": 16,
        "answer": " <start>\nimport numpy as np\nimport pandas as pd\nfrom pathlib import Path\n\n# Constants\nLETTERS = list('abcdefghijklmnopqrstuvwxyz')\nOUTPUT_DIR = Path('./output')\n\ndef task_func(file_path: str, output_dir: Path = OUTPUT_DIR):\n    if not output_dir.exists():\n        output_dir.mkdir(parents=True, exist_ok=True)\n    matrix = pd.DataFrame(np.random.choice(LETTERS, (10, 10)))\n    matrix.to_csv(file_path, sep='\\t', header=False, index=False)\n\n    return None\n<end>"
    },
    {
        "id": 17,
        "answer": " <start>\n```python\nfrom random import randint\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pandas as pd\n\n# Constants\nTEAMS = ['Team A', 'Team B', 'Team C', 'Team D', 'Team E']\nPENALTY_COST = 1000  # in dollars\n\ndef task_func(goals, penalties):\n    match_results = []\n\n    for team in TEAMS:\n        team_goals = randint(0, goals)\n        team_penalties = randint(0, penalties)\n        penalty_cost = PENALTY_COST * team_penalties\n        match_results.append([team, team_goals, penalty_cost])\n\n    results_df = pd.DataFrame(match_results, columns=['Team', 'Goals', 'Penalty Cost'])\n\n    # Create subplots for goals and penalty costs\n    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n\n    # Plot goals\n    sns.barplot(x='Team', y='Goals', data=results_df, ax=ax1, palette='viridis')\n\n    # Plot penalty costs\n    sns.barplot(x='Team', y='Penalty Cost', data=results_df, ax=ax2, palette='viridis')\n\n    # Hide unused subplots\n    fig.tight_layout()\n    plt.show()\n\n    return results_df\n```\n<end>"
    },
    {
        "id": 18,
        "answer": " <start>\n```python\nimport pytz\nfrom dateutil.parser import parse\n\ndef task_func(date_str, from_tz, to_tz):\n    # Get timezone objects for the source and destination timezones\n    from_tz_obj = pytz.timezone(from_tz)\n    to_tz_obj = pytz.timezone(to_tz)\n\n    # Parse the given date string using dateutil.parser\n    given_date = parse(date_str)\n\n    # Localize the given date using the source timezone\n    given_date = given_date.replace(tzinfo=from_tz_obj)\n\n    # Convert the given date to the destination timezone\n    given_date_in_to_tz = given_date.astimezone(to_tz_obj)\n\n    # Get the current time in the destination timezone\n    current_date_in_to_tz = datetime.now(to_tz_obj)\n\n    # Calculate the time difference in seconds\n    time_difference = (current_date_in_to_tz - given_date_in_to_tz).total_seconds()\n\n    return int(time_difference)\n```\n<end>"
    },
    {
        "id": 19,
        "answer": " <start>\nimport pytz\nfrom dateutil.parser import parse\nfrom datetime import datetime\n\ndef task_func(date_str, from_tz, to_tz):\n    # Get timezone objects for the source and destination timezones\n    from_tz_obj = pytz.timezone(from_tz)\n    to_tz_obj = pytz.timezone(to_tz)\n\n    # Parse the given date string and localize it to the source timezone\n    given_date_naive = parse(date_str)\n    given_date = from_tz_obj.normalize(given_date_naive)\n\n    # Convert the given date to the destination timezone\n    given_date_in_to_tz = given_date.astimezone(to_tz_obj)\n\n    # Get the current time in the destination timezone\n    current_date_in_to_tz = datetime.now(to_tz_obj)\n\n    # Calculate the time difference in seconds\n    time_difference = (current_date_in_to_tz - given_date_in_to_tz).total_seconds()\n\n    return int(time_difference)\n<end>"
    },
    {
        "id": 20,
        "answer": " <start>\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pandas as pd\n\ndef task_func(dataframe, target_value='332'):\n    mask = dataframe.eq(target_value)  # Using the .eq() method for equality comparison instead of .applymap()\n\n    # Plot the heatmap\n    fig, ax = plt.subplots(figsize=(8, 6))\n    sns.heatmap(mask, cmap='Blues', cbar=False, ax=ax)\n\n    return mask, ax\n<end>"
    },
    {
        "id": 21,
        "answer": " <start>\nimport pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing import StandardScaler\n\ndef task_func(df, features):\n    if not features:\n        return df\n\n    # Initialize the StandardScaler\n    scaler = StandardScaler()\n\n    # Apply StandardScaler to the specified features\n    df[features] = pd.DataFrame(scaler.fit_transform(df[features]), columns=features, index=df.index)\n\n    # Example of explicit np usage, even though not necessary for this function\n    # Just for demonstration: add a dummy operation using np\n    df['dummy'] = np.zeros(len(df))\n\n    return df.drop('dummy', axis=1)\n<end>"
    },
    {
        "id": 22,
        "answer": " <start>\nimport numpy as np\nimport pandas as pd\nfrom sklearn.linear_model import LinearRegression\n\ndef task_func(df, target_column, target_values=None):\n\n    if not df.isna().sum().all():\n        raise ValueError(\"df should contain only numeric values.\")\n\n    if target_column not in df.columns:\n        raise ValueError(\"target_column should be in DataFrame.\")\n\n    if target_values is not None:\n        df[target_column] = df[target_column].mask(~df[target_column].isin(target_values), 0)\n\n    X = df.drop(target_column, axis=1)\n    y = df[target_column]\n\n    model = LinearRegression().fit(X, y)\n\n    return model\n<end>"
    },
    {
        "id": 23,
        "answer": " <start>\nimport re\nimport pandas as pd\n\ndef task_func(df: pd.DataFrame) -> int:\n    if not isinstance(df, pd.DataFrame):\n        raise TypeError(\"df should be a DataFrame.\")\n\n    # Constants\n    BRACKETS_PATTERN = '[(){}[\\\\]]'\n\n    # If DataFrame is empty, return 0\n    if df.empty:\n        return 0\n\n    # Apply function to each element in the DataFrame\n    bracket_counts = df.apply(\n        lambda x: len(re.findall(BRACKETS_PATTERN, str(x)))\n    )\n\n    # Sum the bracket counts across all columns\n    total_count = bracket_counts.sum().sum()\n\n    return total_count\n<end>"
    },
    {
        "id": 24,
        "answer": " <start>\nimport re\nimport pandas as pd\n\ndef task_func(df: pd.DataFrame) -> int:\n\n    if not isinstance(df, pd.DataFrame):\n        raise TypeError(\"df should be a DataFrame.\")\n\n    # Constants\n    BRACKETS_PATTERN = '[(){}[\\\\]]'\n\n    return df.apply(\n        lambda row: sum(len(re.findall(BRACKETS_PATTERN, str(cell))) for cell in row)\n    ).sum()\n<end>"
    },
    {
        "id": 25,
        "answer": " <start>\nimport os\nimport pandas as pd\n\ndef task_func(data_dir: str, csv_file: str) -> pd.DataFrame:\n    file_path = os.path.join(data_dir, csv_file)\n    try:\n        df = pd.read_csv(file_path)\n    except FileNotFoundError:\n        return pd.DataFrame()\n\n    df.fillna(df.mean(), inplace=True)\n    df.select_dtypes(include=np.number).fillna(df.mean(), inplace=True)\n\n    return df\n<end>"
    },
    {
        "id": 26,
        "answer": " <start>\nimport pandas as pd\nimport re\n\ndef task_func(data, mapping):\n    df = pd.DataFrame(data)\n\n    # Create a function to replace acronyms in a single string\n    def replace_acronym(acronym, full_word):\n        return re.sub(f'\\\\b{acronym}\\\\b', full_word, string)\n\n    # Apply the function to each string column in the DataFrame\n    df = df.apply(lambda row: pd.Series(\n        [replace_acronym(acronym, full_word) for acronym, full_word in mapping.items() if isinstance(row[acronym], str)]\n    ))\n\n    return df\n<end>"
    },
    {
        "id": 27,
        "answer": " <start>\n```python\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib.pyplot import figure, axis\nfrom matplotlib.dates import DateFormatter\n\ndef task_func(start_date='2016-01-01', periods=13, freq='WOM-2FRI', seed=None):\n    if seed is not None:\n        np.random.seed(seed)\n    date_range = pd.date_range(start=start_date, periods=periods, freq=freq)\n    stock_prices = np.random.uniform(low=100, high=500, size=periods)\n\n    prices_df = pd.DataFrame({'Date': date_range, 'Price': stock_prices})\n    prices_df.set_index('Date', inplace=True)\n\n    fig = figure(figsize=(10, 6))\n    ax = axis(fig)\n    ax.plot(prices_df.index, prices_df['Price'], marker='o')\n\n    ax.set_title('Stock Prices')\n    ax.set_xlabel('Date')\n    ax.set_ylabel('Price')\n    ax.grid(True)\n    ax.xaxis.set_major_formatter(DateFormatter('%Y-%m-%d'))\n\n    return prices_df, ax\n```\n<end>"
    },
    {
        "id": 28,
        "answer": " <start>\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef task_func(start_date='2016-01-01', periods=13, freq='WOM-2FRI', seed=None):\n    if seed is not None:\n        np.random.seed(seed)\n\n    date_range = pd.date_range(start=start_date, periods=periods, freq=freq)\n    stock_prices = np.random.uniform(low=100, high=500, size=len(date_range))\n\n    prices_df = pd.DataFrame({'Date': date_range, 'Price': stock_prices})\n    prices_df.set_index('Date', inplace=True)\n\n    fig, ax = plt.subplots(figsize=(10, 6))\n    prices_df.plot(ax=ax, marker='o')\n\n    ax.set_title('Stock Prices')\n    ax.set_xlabel('Date')\n    ax.set_ylabel('Price')\n    ax.grid(True)\n\n    return prices_df, ax\n<end>"
    },
    {
        "id": 29,
        "answer": " <start>\n```python\nimport numpy as np\nfrom scipy.stats import ttest_ind\nimport matplotlib.pyplot as plt\nfrom matplotlib.pyplot import Axes\nfrom scipy.require_dependency import requires\n\nrequires(\"numpy\", \"2.2.1\")\nrequires(\"scipy\", \"1.15.1\")\nrequires(\"matplotlib\", \"3.10.0\")\n\ndef task_func(kwargs):\n    alpha = 0.05  # Define the significance level\n\n    group1 = np.array(kwargs.get(\"group1\", []))\n    group2 = np.array(kwargs.get(\"group2\", []))\n\n    # Check for empty or all-NaN groups\n    if (\n        len(group1) == 0\n        or len(group2) == 0\n        or np.all(np.isnan(group1))\n        or np.all(np.isnan(group2))\n    ):\n        raise ValueError(\"One or both groups are empty or contain only NaN values.\")\n\n    # Removing NaN values and ensuring sufficient data\n    valid_group1 = np.nan_to_num(group1)\n    valid_group2 = np.nan_to_num(group2)\n\n    # Check for sufficient size and variance\n    if len(valid_group1) < 2 or len(valid_group2) < 2:\n        raise ValueError(\"Each group must have at least two non-NaN values.\")\n\n    if np.var(valid_group1) < 1e-8 or np.var(valid_group2) < 1e-8:\n        raise ValueError(\"Variance in one or both groups is too low.\")\n\n    # Perform t-test\n    _, p_val = ttest_ind(valid_group1, valid_group2, nan_policy=\"omit\")\n\n    significant = p_val < alpha\n\n    # Calculate descriptive statistics\n    group1_stats = {\"mean\": np.mean(valid_group1), \"std\": np.std(valid_group1)}\n    group2_stats = {\"mean\": np.mean(valid_group2), \"std\": np.std(valid_group2)}\n\n    # Plotting\n    fig, (ax_boxplot, ax_histogram) = plt.subplots(2, 1, figsize=(8, 12))\n\n    # Boxplot\n    ax_boxplot.boxplot([valid_group1, valid_group2], labels=[\"group1\", \"group2\"])\n\n    # Histogram\n    ax_histogram.hist(valid_group1, alpha=0.5, label=\"group1\")\n    ax_histogram.hist(valid_group2, alpha=0.5, label=\"group2\")\n    ax_histogram.legend()\n\n    return {\n        \"significant\": significant,\n        \"group1_stats\": group1_stats,\n        \"group2_stats\": group2_stats,\n        \"ax_boxplot\": ax_boxplot,\n        \"ax_histogram\": ax_histogram,\n    }\n```\n<end>"
    },
    {
        "id": 30,
        "answer": " <start>\n```python\nfrom datetime import datetime\nimport pytz\nfrom dateutil.tz import tzutc\n\nDATE_FORMAT = '%Y-%m-%d %H:%M:%S'\n\ndef task_func(unix_timestamp, target_timezone):\n    # Convert the Unix timestamp to a UTC datetime object\n    datetime_utc = datetime.fromtimestamp(unix_timestamp, tzutc())\n\n    # Convert the UTC datetime to the target timezone\n    datetime_in_target_timezone = datetime_utc.astimezone(pytz.timezone(target_timezone))\n\n    # Format the datetime object in the target timezone to the specified string format\n    formatted_datetime = datetime_in_target_timezone.strftime(DATE_FORMAT)\n\n    return formatted_datetime\n```\n<end>"
    }
]