[{"id": 0, "answer": " <start>\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\ndef task_func(df, target_values=[1, 3, 4]):\n    df.replace(to_replace=df.iloc[:, ~df.columns.isin(target_values)], value=0, inplace=True)\n    plt.figure(figsize=(10, 5))\n    for column in df.columns:\n        sns.kdeplot(df[column], label=column, warn_singular=False)\n    plt.legend()\n    return df, plt.gca()\n<end>"}, {"id": 1, "answer": " <start>\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\ndef task_func(df, target_values=[1, 3, 4]):\n    df.replace(to_replace=df.values[~np.isin(df.values, target_values)], value=0, inplace=True)\n    plt.figure(figsize=(10, 5))\n    for column in df.columns:\n        if not df[column].eq(0).all():\n            sns.kdeplot(df[column], label=column)\n    plt.legend()\n    return df, plt.gca()\n<end>"}, {"id": 2, "answer": " <start>\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\ndef task_func(df, target_values=[1, 3, 4]):\n    # Replace elements not in target_values with 0\n    df.replace(regex=False, to_replace=set(df.values) - set(target_values), value=0, inplace=True)\n\n    # Plot the distribution of each column\n    fig, ax = plt.subplots(figsize=(10, 5))\n    for column in df.columns:\n        # Check if the column has non-zero values to avoid KDE error\n        if df[column].nunique() > 1:  # Ensure there is variation in the data\n            sns.kdeplot(df[column], label=column, ax=ax)\n        else:\n            # If all values are zero, plot a vertical line at zero\n            ax.axvline(0, label=column, linestyle='--', color='gray')\n\n    ax.legend()\n    return df, ax\n<end>"}, {"id": 3, "answer": " <start>\nimport numpy as np\nfrom scipy import stats\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nTARGET_VALUES = np.array([1, 3, 4])\n\ndef box_cox_transform_and_kde(df):\n    # Ensure the DataFrame contains only positive values\n    if (df <= 0).any().any():\n        raise ValueError(\"Input DataFrame should contain only positive values.\")\n\n    df = df.mask(df.isin(TARGET_VALUES), 0)\n\n    transformed_df = df.copy()\n\n    fig, ax = plt.subplots(figsize=(10, 8))\n\n    for column in transformed_df.columns:\n        # Check if data is constant\n        if transformed_df[column].nunique() == 1:\n            transformed_df[column] = transformed_df[column]\n        else:\n            transformed_data, _ = stats.boxcox(\n                transformed_df[column] + 1\n            )  # Add 1 since the are some null values\n            transformed_df[column] = transformed_data\n\n            # Using matplotlib's kde method to plot the KDE\n            kde = stats.gaussian_kde(transformed_df[column])\n            ax.plot(kde.support, kde(kde.support), label=column)\n\n    ax.legend()\n\n    return transformed_df, fig\n<end>"}, {"id": 4, "answer": " <start>\nimport time\nfrom datetime import datetime\nimport random\nimport matplotlib.pyplot as plt\nfrom matplotlib.dates import DateFormatter\n\n# Constants\nDATE_FORMAT = \"%Y-%m-%d %H:%M:%S\"\n\ndef task_func(n, output_path=None):\n    timestamps = []\n    for _ in range(n):\n        timestamp = random.randint(0, int(time.time()))\n        formatted_time = datetime.utcfromtimestamp(timestamp).strftime(DATE_FORMAT)\n        timestamps.append(formatted_time)\n\n    fig, ax = plt.subplots()\n    ax.hist([datetime.strptime(t, DATE_FORMAT) for t in timestamps], bins=365)\n    ax.xaxis.set_major_formatter(DateFormatter(DATE_FORMAT))\n\n    if output_path:\n        plt.savefig(output_path)\n    else:\n        plt.show()\n    return timestamps\n<end>"}, {"id": 5, "answer": " <start>\nimport pandas as pd\nimport seaborn as sns\n\n# Constants\nCOLUMNS = ['col1', 'col2', 'col3']\n\ndef task_func(data):\n    df = pd.DataFrame(data, columns=COLUMNS)\n    analyzed_df = df.groupby(COLUMNS[:-1]).agg({COLUMNS[-1]: 'nunique'}).reset_index()\n    ax = sns.displot(analyzed_df[COLUMNS[-1]], x=COLUMNS[-1])\n\n    ax.set_xlabel(COLUMNS[-1])\n\n    return analyzed_df, ax\n<end>"}, {"id": 6, "answer": " <start>\nimport pandas as pd\nfrom datetime import datetime\nfrom holidays import Holiday, HolidayCalendar\n\ndef task_func(start_date=datetime(2023, 1, 1), end_date=datetime(2023, 12, 31), country='US'):\n    if not isinstance(start_date, datetime) or not isinstance(end_date, datetime):\n        raise ValueError(\"start_date and end_date must be datetime objects.\")\n    if start_date > end_date:\n        raise ValueError(\"start_date must not be after end_date.\")\n\n    # Create a HolidayCalendar for the specified country\n    calendar = HolidayCalendar(country, firstweekday=HolidayCalendar.MONDAY)\n\n    # Add custom holidays for the specific year\n    if country == 'US':\n        calendar.add_holiday(Holiday(\"New Year's Day\", date=datetime(2023, 1, 1)), calendar=calendar)\n        calendar.add_holiday(Holiday(\"Independence Day\", date=datetime(2023, 7, 4)), calendar=calendar)\n        calendar.add_holiday(Holiday(\"Labor Day\", date=datetime(2023, 9, 4)), calendar=calendar)\n        calendar.add_holiday(Holiday(\"Thanksgiving Day\", date=datetime(2023, 11, 23)), calendar=calendar)\n        calendar.add_holiday(Holiday(\"Christmas Day\", date=datetime(2023, 12, 25)), calendar=calendar)\n\n    dates = pd.date_range(start_date, end_date)\n    business_days = [date for date in dates if date.weekday() < 5 and date not in calendar.holidays()]\n\n    return business_days\n<end>"}, {"id": 7, "answer": " <start>\nimport pandas as pd\nfrom datetime import datetime\nfrom holidays import Holiday, HolidayCalendar\n\ndef task_func(start_date=datetime(2023, 1, 1), end_date=datetime(2023, 12, 31), country='US'):\n    if not isinstance(start_date, datetime) or not isinstance(end_date, datetime):\n        raise ValueError(\"start_date and end_date must be datetime objects.\")\n    if start_date > end_date:\n        raise ValueError(\"start_date must not be after end_date.\")\n\n    us_calendar = HolidayCalendar(country='US')\n    dates = pd.date_range(start_date, end_date)\n    business_days = [date for date in dates if date.weekday() < 5 and date not in us_calendar.holidays(date)]\n\n    return business_days\n<end>"}, {"id": 8, "answer": " <start>\nimport json\nimport random\nfrom datetime import datetime, timezone\n\n# Constants\nDATA = [\n    {'name': 'John', 'age': 30, 'city': 'New York'},\n    {'name': 'Peter', 'age': 35, 'city': 'London'},\n    {'name': 'Susan', 'age': 25, 'city': 'Sydney'},\n    {'name': 'Alice', 'age': 28, 'city': 'Paris'},\n    {'name': 'Bob', 'age': 40, 'city': 'Tokyo'},\n    {'name': 'Charlie', 'age': 22, 'city': 'Beijing'},\n    {'name': 'David', 'age': 33, 'city': 'Mumbai'},\n    {'name': 'Eve', 'age': 27, 'city': 'Berlin'},\n    {'name': 'Frank', 'age': 32, 'city': 'Moscow'},\n    {'name': 'Grace', 'age': 29, 'city': 'Rome'}\n]\n\ndef task_func(utc_datetime, seed=0):\n    random.seed(seed)\n    # Choose a random person\n    person = random.choice(DATA)\n\n    # Convert the UTC datetime to a timezone-aware datetime\n    person['timestamp'] = utc_datetime.replace(tzinfo=timezone.utc).isoformat()\n\n    # Encode the person's data as a JSON string\n    person_json_str = json.dumps(person)\n\n    return person_json_str\n<end>"}, {"id": 9, "answer": " <start>\nimport requests\nimport json\n\nclass PostRequestHandler(requests.models.Response):\n    def __init__(self, status_code, content=None, headers=None, request=None):\n        super().__init__(status_code, content, headers, request)\n\n    def json_response(self, status, message):\n        self.status_code = status\n        self.headers['Content-type'] = 'application/json'\n        self.content = json.dumps({'status': status, 'message': message})\n\n    def do_post(self):\n        if self.request.headers.get('Content-Type') != 'application/json':\n            self.json_response(400, 'Content-Type header is not application/json')\n            return\n\n        try:\n            data = json.loads(self.request.body)\n        except json.JSONDecodeError:\n            self.json_response(400, 'No data received')\n            return\n\n        self.json_response(200, 'Data received successfully.')\n<end>"}, {"id": 10, "answer": " <start>\n\n```python\nimport math\nimport numpy as np\nimport pandas as pd\nfrom datetime import timedelta\n\ndef task_func(\n    start_time,\n    end_time,\n    step,\n    columns=[\"Timestamp\", \"Sensor1\", \"Sensor2\", \"Sensor3\", \"SensorStatus\"],\n    sensor_statuses=[\"OK\", \"MAINTENANCE_REQUIRED\", \"ERROR\"],\n    random_seed=42,\n):\n    np.random.seed(random_seed)\n\n    if start_time > end_time:\n        raise ValueError(\"start_time cannot be after end_time\")\n    if step <= 0:\n        raise ValueError(\"step must be positive\")\n    if len(columns) != 5:\n        raise ValueError(\"columns must have exactly 5 elements\")\n\n    timestamps = list(range(start_time, end_time, step))\n\n    data = []\n    for ts in timestamps:\n        dt = (timedelta(milliseconds=ts) if isinstance(ts, int) else ts).strftime(\"%Y-%m-%d %H:%M:%S.%f\")\n        sensor1 = math.sin(ts / 1000) + np.random.normal(0, 0.1)\n        sensor2 = math.cos(ts / 1000) + np.random.normal(0, 0.1)\n        sensor3 = math.tan(ts / 1000) + np.random.normal(0, 0.1)\n        status = np.random.choice(sensor_statuses)\n        row = [dt, sensor1, sensor2, sensor3, status]\n        data.append(row)\n\n    return pd.DataFrame(data, columns=columns)\n```\n\n<end>"}, {"id": 11, "answer": " <start>\nimport math\nimport numpy as np\nimport pandas as pd\n\ndef task_func(\n    start_time,\n    end_time,\n    step,\n    columns=[\"Timestamp\", \"Sensor1\", \"Sensor2\", \"Sensor3\", \"SensorStatus\"],\n    sensor_statuses=[\"OK\", \"MAINTENANCE_REQUIRED\", \"ERROR\"],\n    random_seed=42,\n):\n    np.random.seed(random_seed)\n\n    if start_time > end_time:\n        raise ValueError(\"start_time cannot be after end_time\")\n    if step < 0:\n        raise ValueError(\"step must be positive\")\n\n    timestamps = pd.date_range(start=pd.Timestamp(start_time), end=pd.Timestamp(end_time), freq=\"ms\").to_list()\n\n    data = []\n    for ts in timestamps:\n        dt = ts.strftime(\"%Y-%m-%d %H:%M:%S.%f\")\n        sensor1 = math.sin(ts.total_seconds()) + np.random.normal(0, 0.1)\n        sensor2 = math.cos(ts.total_seconds()) + np.random.normal(0, 0.1)\n        sensor3 = math.tan(ts.total_seconds()) + np.random.normal(0, 0.1)\n        status = np.random.choice(sensor_statuses)\n        row = [dt, sensor1, sensor2, sensor3, status]\n        data.append(row)\n\n    return pd.DataFrame(data, columns=columns)\n<end>"}, {"id": 12, "answer": " <start>\n```python\nimport datetime\nimport pandas as pd\nimport numpy as np\nfrom matplotlib import pyplot as plt\n\ndef task_func(start_time, end_time, step, amplitude, period, seed=0):\n    np.random.seed(seed)\n\n    if period <= 0 or step < 1:\n        raise ValueError(\"Invalid input values\")\n\n    timestamps = pd.date_range(start=datetime.utcfromtimestamp(start_time / 1000), end=datetime.utcfromtimestamp(end_time / 1000), freq=\"{:.6f}ms\".format(step))\n    df = pd.DataFrame({\"Timestamp\": timestamps, \"Value\": np.random.normal(size=len(timestamps))})\n\n    if amplitude == 0:\n        pass\n    else:\n        df[\"Value\"] += amplitude * np.sin(2 * np.pi * df[\"Timestamp\"].map(lambda x: x.timestamp()) / period.total_seconds())\n\n    ax = df.plot(x=\"Timestamp\", y=\"Value\", title=\"Time Series with Seasonality\")\n    ax.set_ylabel(\"Value\")\n    return ax\n```\n<end>"}, {"id": 13, "answer": " <start>\nimport random\nfrom datetime import datetime\nimport matplotlib.pyplot as plt\nfrom matplotlib.dates import DateFormatter\n\ndef task_func(epoch_milliseconds, seed=None):\n    CATEGORIES = [\"Electronics\", \"Clothing\", \"Home\", \"Books\", \"Sports\"]\n\n    if seed is not None:\n        random.seed(seed)\n\n    if epoch_milliseconds < 0:\n        raise ValueError(\"Start time cannot be negative.\")\n\n    start_time = datetime.utcfromtimestamp(epoch_milliseconds / 1000.0)\n    current_time = datetime.utcnow()\n    days_diff = (current_time - start_time).days\n    if days_diff <= 0:\n        raise ValueError(\"Start date must be before current time.\")\n\n    sales_data = {category: [0] * days_diff for category in CATEGORIES}\n\n    for i in range(days_diff):\n        for category in CATEGORIES:\n            sales = random.randint(10, 50)\n            sales_data[category][i] += sales\n\n    fig, ax = plt.subplots()\n    ax.plot(range(days_diff), [sales_data[category][i] for category in CATEGORIES], label=\", \".join(CATEGORIES))\n\n    ax.set_xlabel(\"Days since \" + start_time.strftime(\"%Y-%m-%d %H:%M:%S\"))\n    ax.set_ylabel(\"Sales\")\n    ax.legend()\n\n    # Set x-axis to display dates\n    ax.xaxis.set_major_formatter(DateFormatter('%Y-%m-%d'))\n\n    return sales_data, ax\n<end>"}, {"id": 14, "answer": " <start>\n\n```python\nimport xlrd\nimport os\nimport pandas as pd\nfrom pandas.io.excel import ExcelWriter\nfrom pandas.io.excel._xlsxwriter import _XlsxStyler\n\ndef task_func(json_str, filename, sheet_name=\"sheet1\"):\n\n    if not isinstance(json_str, (str, bytes, bytearray)):\n        raise TypeError(\"json_str must be a string, bytes, or bytearray\")\n\n    try:\n        data = pd.read_json(json_str)\n\n        # Initialize Excel workbook and sheet\n        writer = ExcelWriter(filename, engine=\"xlsx\", engine_kwargs={\"date_format\": None})\n        writer.book = writer.sheets[sheet_name] = writer._xlsx.Workbook()\n\n        # Check if DataFrame is empty and proceed accordingly\n        if not data.empty:\n            for col_index, col in enumerate(data.columns):\n                writer.sheets[sheet_name].write(0, col_index, col)\n            for row_index, row in data.iterrows():\n                for col_index, col in enumerate(data.columns):\n                    writer.sheets[sheet_name].write(row_index + 1, col_index, row[col])\n        writer.save()\n        return os.path.abspath(filename)\n    except ValueError as e:\n        raise ValueError(f\"Invalid JSON string: {e}\")\n    except Exception as e:\n        raise Exception(f\"Error in file writing: {e}\")\n</end>\n```\n</start>"}, {"id": 15, "answer": " <start>\n```python\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport seaborn as sns\nfrom collections.abc import Iterable\n\ndef task_func(list_of_menuitems):\n    if not list_of_menuitems:\n        print(\"No items to plot.\")\n        return None\n\n    # Flatten the nested list into a single list of items\n    flat_list = [item for sublist in list_of_menuitems if isinstance(sublist, Iterable) for item in sublist]\n    if not flat_list:\n        print(\"No items to plot.\")\n        return None\n\n    # Count the occurrence of each item\n    counter = pd.Series(flat_list).value_counts()\n\n    # Create a seaborn barplot\n    sns.set(style=\"whitegrid\")\n    ax = sns.barplot(x=counter.index, y=counter.values, palette=\"viridis\")\n\n    plt.tight_layout()  # Adjust the layout to make room for the item labels\n    return ax\n```\n<end>"}, {"id": 16, "answer": " <start>\nimport numpy as np\nimport pandas as pd\n\n# Constants\nLETTERS = list('abcdefghijklmnopqrstuvwxyz')\nOUTPUT_DIR = './output'\n\ndef task_func(file_path, output_dir=OUTPUT_DIR):\n    if not os.path.exists(output_dir):\n        os.makedirs(output_dir, exist_ok=True)\n\n    matrix = pd.DataFrame(np.random.choice(LETTERS, (10, 10)))\n    matrix.to_csv(os.path.join(output_dir, file_path), sep='\\t', header=False, index=False)\n\n    return None\n<end>"}, {"id": 17, "answer": " <start>\n```python\nimport random\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport seaborn as sns\n\n# Constants\nTEAMS = ['Team A', 'Team B', 'Team C', 'Team D', 'Team E']\nPENALTY_COST = 1000  # in dollars\n\ndef task_func(goals, penalties):\n    match_results = []\n\n    for team in TEAMS:\n        team_goals = random.randint(0, goals)\n        team_penalties = random.randint(0, penalties)\n        penalty_cost = PENALTY_COST * team_penalties\n        match_results.append([team, team_goals, penalty_cost])\n\n    results_df = pd.DataFrame(match_results, columns=['Team', 'Goals', 'Penalty Cost'])\n\n    fig, (ax1, ax2) = plt.subplots(nrows=2, figsize=(10, 8))\n    sns.barplot(x='Team', y='Goals', data=results_df, ax=ax1, palette='viridis')\n    sns.barplot(x='Team', y='Penalty Cost', data=results_df, ax=ax2, palette='viridis')\n\n    return results_df, [ax1, ax2]\n```\n<end>"}, {"id": 18, "answer": " <start>\n```python\nfrom datetime import datetime\nfrom dateutil.parser import parse\nfrom pytz import timezone, utc\n\ndef task_func(date_str, from_tz, to_tz):\n    # Parse the given date string using dateutil.parser\n    given_date = parse(date_str)\n\n    # Convert the given date to the source timezone\n    given_date_in_from_tz = given_date.astimezone(timezone(from_tz))\n\n    # Convert the given date to the destination timezone\n    given_date_in_to_tz = given_date_in_from_tz.astimezone(timezone(to_tz))\n\n    # Get the current time in the destination timezone\n    current_date_in_to_tz = datetime.now(utc).astimezone(timezone(to_tz))\n\n    # Calculate the time difference in seconds\n    time_difference = current_date_in_to_tz - given_date_in_to_tz\n\n    return int(time_difference.total_seconds())\n```\n<end>"}, {"id": 19, "answer": " <start>\nimport pytz\nfrom dateutil.parser import parse\nfrom dateutil.tz import tzutc\n\ndef task_func(date_str, from_tz, to_tz):\n    # Get timezone objects for the source and destination timezones\n    from_tz_obj = pytz.timezone(from_tz)\n    to_tz_obj = pytz.timezone(to_tz)\n\n    # Parse the given date string and localize it to the source timezone\n    given_date_naive = parse(date_str)\n    given_date = from_tz_obj.normalize(given_date_naive)\n\n    # Convert the given date to the destination timezone\n    given_date_in_to_tz = given_date.astimezone(to_tz_obj)\n\n    # Get the current time in the destination timezone\n    current_date_in_to_tz = tzutc().normalize(tzutc().localize(datetime.now()))\n\n    # Calculate the time difference in seconds\n    time_difference = (current_date_in_to_tz - given_date_in_to_tz).total_seconds()\n\n    return int(time_difference)\n<end>"}, {"id": 20, "answer": " <start>\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\ndef task_func(dataframe, target_value='332'):\n    mask = dataframe.eq(target_value)\n\n    # Plot the heatmap\n    fig, ax = plt.subplots(figsize=(8, 6))\n    sns.heatmap(mask, cmap='Blues', cbar=False, ax=ax)\n\n    return mask, ax\n<end>"}, {"id": 21, "answer": " <start>\nimport pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing import StandardScaler\n\ndef task_func(df, features):\n    if not features:\n        return df\n\n    # Initialize the StandardScaler\n    scaler = StandardScaler()\n\n    # Apply StandardScaler to the specified features\n    df[features] = scaler.fit_transform(df[features])\n\n    # Example of explicit np usage, even though not necessary for this function\n    # Just for demonstration: add a dummy operation using np\n    df['dummy'] = np.zeros(len(df))\n\n    return df.drop('dummy', axis=1)\n<end>"}, {"id": 22, "answer": " <start>\nimport numpy as np\nimport pandas as pd\nfrom sklearn.linear_model import LinearRegression\n\ndef task_func(df, target_column, target_values=None):\n\n    if not df.is_valid():\n        raise ValueError(\"df should be a valid DataFrame.\")\n\n    if df.empty:\n        raise ValueError(\"df should contain at least one row\")\n\n    if target_column not in df.columns:\n        raise ValueError(\"target_column should be in DataFrame\")\n\n    if not df.dtypes.all(include=np.number):\n        raise ValueError(\"df values should be numeric only\")\n\n    if target_values is not None:\n        df = df.mask(~df[target_column].isin(target_values), 0)\n\n    X = df.drop(target_column, axis=1)\n    y = df[target_column]\n\n    model = LinearRegression().fit(X, y)\n\n    return model\n<end>"}, {"id": 23, "answer": " <start>\nimport re\nimport pandas as pd\n\ndef task_func(df: pd.DataFrame) -> int:\n    if not isinstance(df, pd.DataFrame):\n        raise TypeError(\"df should be a DataFrame.\")\n\n    # Constants\n    BRACKETS_PATTERN = '[(){}[\\\\]]'\n\n    # If DataFrame is empty, return 0\n    if df.empty:\n        return 0\n\n    # Use apply() instead of applymap() for better performance\n    return df.apply(\n        lambda row: sum(len(re.findall(BRACKETS_PATTERN, str(cell))) for cell in row),\n        axis=1\n    ).sum()\n<end>"}, {"id": 24, "answer": " <start>\nimport re\nimport pandas as pd\n\ndef task_func(df: pd.DataFrame) -> int:\n\n    if not isinstance(df, pd.DataFrame):\n        raise TypeError(\"df should be a DataFrame.\")\n\n    # Constants\n    BRACKETS_PATTERN = '[(){}[\\]]'\n\n    return df.apply(\n        lambda row: sum(len(re.findall(BRACKETS_PATTERN, str(cell))) for cell in row),\n        axis=1\n    ).sum()\n<end>"}, {"id": 25, "answer": " <start>\nimport os\nimport pandas as pd\nimport numpy as np\n\ndef task_func(data_dir: str, csv_file: str) -> pd.DataFrame:\n    file_path = os.path.join(data_dir, csv_file)\n    try:\n        df = pd.read_csv(file_path)\n    except FileNotFoundError:\n        return pd.DataFrame()\n\n    df.fillna(df.mean(), inplace=True)\n    return df\n<end>"}, {"id": 26, "answer": " <start>\nimport pandas as pd\nimport re\n\ndef replace_acronyms(data, mapping):\n    df = pd.DataFrame(data)\n\n    # Create a function to replace acronyms in a single string\n    def replace_acronym(acronym, full_word):\n        return re.sub(f\"\\\\b{acronym}\\\\b\", full_word, string)\n\n    # Apply the function to each string cell in the DataFrame\n    df = df.applymap(lambda x: replace_acronym(x, mapping.get(x, x)) if isinstance(x, str) else x)\n\n    return df\n<end>"}, {"id": 27, "answer": " <start>\n```python\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef task_func(start_date='2016-01-01', periods=13, freq='WOM-2FRI', seed=None):\n    if seed is not None:\n        np.random.seed(seed)\n    date_range = pd.date_range(start=start_date, periods=periods, freq=freq)\n    stock_prices = np.random.uniform(low=100, high=500, size=periods)\n\n    prices_df = pd.DataFrame({'Date': date_range, 'Price': stock_prices})\n    prices_df.set_index('Date', inplace=True)\n\n    fig, ax = plt.subplots(figsize=(10, 6))\n    ax.plot(prices_df.index, prices_df['Price'], marker='o')\n    ax.set_title('Stock Prices')\n    ax.set_xlabel('Date')\n    ax.set_ylabel('Price')\n    ax.grid(True)\n\n    return prices_df, ax\n```\n<end>"}, {"id": 28, "answer": " <start>\n```python\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef task_func(start_date='2016-01-01', periods=13, freq='WOM-2FRI', seed=0):\n    if seed is not None:\n        np.random.seed(seed)\n    date_range = pd.date_range(start=start_date, periods=periods, freq=freq)\n    stock_prices = np.random.uniform(low=100, high=500, size=periods)\n\n    prices_df = pd.DataFrame({'Date': date_range, 'Price': stock_prices})\n    prices_df.set_index('Date', inplace=True)\n\n    with plt.subplots(figsize=(10, 6)) as fig:\n        ax = fig.axes\n        prices_df.plot(ax=ax, marker='o')\n\n    fig.suptitle('Stock Prices')\n    ax.set_xlabel('Date')\n    ax.set_ylabel('Price')\n    ax.grid(True)\n\n    return prices_df, fig\n```\n<end>"}, {"id": 29, "answer": " <start>\n\n```python\nimport numpy as np\nfrom scipy.stats import ttest_ind\nimport matplotlib.pyplot as plt\n\ndef task_func(kwargs):\n    alpha = 0.05  # Define the significance level\n\n    group1 = np.array(kwargs.get(\"group1\", []))\n    group2 = np.array(kwargs.get(\"group2\", []))\n\n    # Check for empty or all-NaN groups\n    if (\n        len(group1) == 0\n        or len(group2) == 0\n        or np.all(np.isnan(group1))\n        or np.all(np.isnan(group2))\n    ):\n        raise ValueError(\"One or both groups are empty or contain only NaN values.\")\n\n    # Removing NaN values and ensuring sufficient data\n    valid_group1 = np.nan_to_num(group1)\n    valid_group2 = np.nan_to_num(group2)\n\n    # Check for sufficient size and variance\n    if len(valid_group1) < 2 or len(valid_group2) < 2:\n        raise ValueError(\"Each group must have at least two non-NaN values.\")\n\n    if np.var(valid_group1) < 1e-8 or np.var(valid_group2) < 1e-8:\n        raise ValueError(\"Variance in one or both groups is too low.\")\n\n    # Perform t-test\n    _, p_val = ttest_ind(valid_group1, valid_group2, nan_policy=\"omit\")\n\n    significant = p_val < alpha\n\n    # Calculate descriptive statistics\n    group1_stats = {\"mean\": np.nanmean(valid_group1), \"std\": np.nanstd(valid_group1)}\n    group2_stats = {\"mean\": np.nanmean(valid_group2), \"std\": np.nanstd(valid_group2)}\n\n    # Plotting\n    _, (ax_boxplot, ax_histogram) = plt.subplots(2, 1, figsize=(8, 12))\n\n    # Boxplot\n    ax_boxplot.boxplot([valid_group1, valid_group2], labels=[\"group1\", \"group2\"])\n\n    # Histogram\n    ax_histogram.hist(valid_group1, alpha=0.5, label=\"group1\")\n    ax_histogram.hist(valid_group2, alpha=0.5, label=\"group2\")\n    ax_histogram.legend()\n\n    return {\n        \"significant\": significant,\n        \"group1_stats\": group1_stats,\n        \"group2_stats\": group2_stats,\n        \"ax_boxplot\": ax_boxplot,\n        \"ax_histogram\": ax_histogram,\n    }\n```\n\n<end>"}, {"id": 30, "answer": " <start>\n```python\nfrom datetime import datetime\nfrom pytz import timezone\n\n# Constants\nDATE_FORMAT = '%Y-%m-%d %H:%M:%S'\n\ndef task_func(unix_timestamp: int, target_timezone: str):\n    # Convert the Unix timestamp to a UTC datetime object\n    datetime_utc = datetime.utcfromtimestamp(unix_timestamp)\n\n    # Convert the UTC datetime to the target timezone\n    datetime_in_target_timezone = datetime_utc.astimezone(timezone(target_timezone))\n\n    # Format the datetime object in the target timezone to the specified string format\n    formatted_datetime = datetime_in_target_timezone.strftime(DATE_FORMAT)\n\n    return formatted_datetime\n```\n<end>"}]