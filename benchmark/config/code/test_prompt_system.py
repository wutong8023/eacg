#!/usr/bin/env python3
"""
Promptç®¡ç†ç³»ç»Ÿæµ‹è¯•è„šæœ¬
=====================

è¯¥è„šæœ¬ç”¨äºéªŒè¯é‡æ„åçš„promptç®¡ç†ç³»ç»Ÿçš„æ­£ç¡®æ€§å’Œå‘åå…¼å®¹æ€§ã€‚
"""

import sys
import os
import traceback

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))

def test_prompt_manager():
    """æµ‹è¯•PromptManagerçš„åŸºæœ¬åŠŸèƒ½"""
    print("ğŸ” Testing PromptManager basic functionality...")
    
    try:
        from benchmark.config.code.dataset2prompt_refactored import prompt_manager
        
        # æµ‹è¯•1: è·å–ä»»åŠ¡ç±»å‹
        task_types = prompt_manager.list_task_types()
        expected_types = ['VACE_CODE_GENERATION', 'VACE_CODE_REVIEW', 'VACE_ERROR_FIX', 'VSCC_CODE_REVIEW', 'GENERAL_ERROR_FIX']
        
        print(f"   âœ“ Task types: {task_types}")
        assert all(t in task_types for t in expected_types), f"Missing task types: {set(expected_types) - set(task_types)}"
        
        # æµ‹è¯•2: è·å–ç‰ˆæœ¬åˆ—è¡¨
        vace_versions = prompt_manager.list_versions('VACE_CODE_GENERATION')
        expected_versions = ['V1_BASIC', 'V2_ENHANCED', 'V3_ADVANCED', 'V4_PROFESSIONAL']
        
        print(f"   âœ“ VACE versions: {vace_versions}")
        assert all(v in vace_versions for v in expected_versions), f"Missing versions: {set(expected_versions) - set(vace_versions)}"
        
        # æµ‹è¯•3: è·å–promptå†…å®¹
        prompt = prompt_manager.get_prompt('VACE_CODE_GENERATION', 'V1_BASIC')
        assert isinstance(prompt, str) and len(prompt) > 100, "Prompt should be a non-empty string"
        print(f"   âœ“ Prompt length: {len(prompt)} chars")
        
        # æµ‹è¯•4: è·å–ä»»åŠ¡ä¿¡æ¯
        task_info = prompt_manager.get_task_info()
        assert 'VACE_CODE_GENERATION' in task_info
        assert 'versions' in task_info['VACE_CODE_GENERATION']
        assert 'total_versions' in task_info['VACE_CODE_GENERATION']
        print(f"   âœ“ Task info: {len(task_info)} task types")
        
        # æµ‹è¯•5: é”™è¯¯å¤„ç†
        try:
            prompt_manager.get_prompt('NONEXISTENT_TASK', 'V1_BASIC')
            assert False, "Should raise ValueError for unknown task type"
        except ValueError:
            print("   âœ“ Error handling for unknown task type")
        
        try:
            prompt_manager.get_prompt('VACE_CODE_GENERATION', 'NONEXISTENT_VERSION')
            assert False, "Should raise ValueError for unknown version"
        except ValueError:
            print("   âœ“ Error handling for unknown version")
        
        print("âœ… PromptManager tests passed!")
        return True
        
    except Exception as e:
        print(f"âŒ PromptManager test failed: {e}")
        traceback.print_exc()
        return False

def test_backward_compatibility():
    """æµ‹è¯•å‘åå…¼å®¹æ€§"""
    print("\nğŸ”„ Testing backward compatibility...")
    
    try:
        # æµ‹è¯•åŸæœ‰å˜é‡åæ˜¯å¦ä»ç„¶å¯ç”¨
        from benchmark.config.code.dataset2prompt_refactored import (
            versiBCB_vace_prompt_override,
            versiBCB_vace_prompt_override_v1,
            versiBCB_vace_prompt_override_v2,
            versiBCB_vace_prompt_override_v3,
            VersiBCB_VACE_RAG_complete_withTargetCode_v1_review,
            VersiBCB_VSCC_RAG_complete_withTargetCode_v1_review,
            VersiBCB_VSCC_RAG_complete_withTargetCode_v1_review_nodesc_errorfixonly,
            VersiBCB_VSCC_RAG_complete_withTargetCode_v1_review_nodesc,
            VersiBCB_VSCC_RAG_complete_withTargetCode_v1_review_nocode,
            versiBCB_VACE_Prompt_errorfix,
            versiBCB_VACE_Prompt_errorfix_retrieve,
            VACE_Prompt_withPyError,
            dataset2prompt
        )
        
        # éªŒè¯å˜é‡ç±»å‹å’Œå†…å®¹
        variables_to_test = [
            ('versiBCB_vace_prompt_override', versiBCB_vace_prompt_override),
            ('versiBCB_vace_prompt_override_v1', versiBCB_vace_prompt_override_v1),
            ('versiBCB_vace_prompt_override_v2', versiBCB_vace_prompt_override_v2),
            ('versiBCB_vace_prompt_override_v3', versiBCB_vace_prompt_override_v3),
            ('VersiBCB_VACE_RAG_complete_withTargetCode_v1_review', VersiBCB_VACE_RAG_complete_withTargetCode_v1_review),
            ('VersiBCB_VSCC_RAG_complete_withTargetCode_v1_review', VersiBCB_VSCC_RAG_complete_withTargetCode_v1_review),
            ('VersiBCB_VSCC_RAG_complete_withTargetCode_v1_review_nodesc_errorfixonly', VersiBCB_VSCC_RAG_complete_withTargetCode_v1_review_nodesc_errorfixonly),
            ('VersiBCB_VSCC_RAG_complete_withTargetCode_v1_review_nodesc', VersiBCB_VSCC_RAG_complete_withTargetCode_v1_review_nodesc),
            ('VersiBCB_VSCC_RAG_complete_withTargetCode_v1_review_nocode', VersiBCB_VSCC_RAG_complete_withTargetCode_v1_review_nocode),
            ('versiBCB_VACE_Prompt_errorfix', versiBCB_VACE_Prompt_errorfix),
            ('versiBCB_VACE_Prompt_errorfix_retrieve', versiBCB_VACE_Prompt_errorfix_retrieve),
            ('VACE_Prompt_withPyError', VACE_Prompt_withPyError),
        ]
        
        for var_name, var_value in variables_to_test:
            assert isinstance(var_value, str), f"{var_name} should be a string"
            assert len(var_value) > 50, f"{var_name} should be a non-empty prompt"
            print(f"   âœ“ {var_name}: {len(var_value)} chars")
        
        # éªŒè¯dataset2promptæ˜ å°„
        assert isinstance(dataset2prompt, dict), "dataset2prompt should be a dictionary"
        assert len(dataset2prompt) > 0, "dataset2prompt should not be empty"
        print(f"   âœ“ dataset2prompt: {len(dataset2prompt)} entries")
        
        # éªŒè¯æ˜ å°„ä¸­çš„æ‰€æœ‰å€¼éƒ½æ˜¯å­—ç¬¦ä¸²
        for key, value in dataset2prompt.items():
            assert isinstance(value, str), f"dataset2prompt[{key}] should be a string"
            assert len(value) > 50, f"dataset2prompt[{key}] should be a non-empty prompt"
        
        print("âœ… Backward compatibility tests passed!")
        return True
        
    except Exception as e:
        print(f"âŒ Backward compatibility test failed: {e}")
        traceback.print_exc()
        return False

def test_prompt_content_integrity():
    """æµ‹è¯•promptå†…å®¹å®Œæ•´æ€§"""
    print("\nğŸ” Testing prompt content integrity...")
    
    try:
        from benchmark.config.code.dataset2prompt_refactored import prompt_manager
        
        # æµ‹è¯•æ‰€æœ‰promptéƒ½åŒ…å«å¿…è¦çš„å ä½ç¬¦
        test_cases = [
            ('VACE_CODE_GENERATION', 'V1_BASIC', ['{context}', '{description}', '{origin_dependency}', '{origin_code}', '{target_dependency}']),
            ('VACE_CODE_GENERATION', 'V3_ADVANCED', ['{context}', '{description}', '{origin_dependency}', '{origin_code}', '{target_dependency}']),
            ('VSCC_CODE_REVIEW', 'V1_COMPREHENSIVE', ['{description}', '{dependency}', '{generated_target_code}', '{error_info}', '{context}']),
            ('VACE_ERROR_FIX', 'V1_BASIC', ['{description}', '{target_dependency}', '{generated_target_code}', '{error_info}']),
        ]
        
        for task_type, version, expected_placeholders in test_cases:
            prompt = prompt_manager.get_prompt(task_type, version)
            
            for placeholder in expected_placeholders:
                assert placeholder in prompt, f"Missing placeholder '{placeholder}' in {task_type} {version}"
            
            print(f"   âœ“ {task_type} {version}: All placeholders present")
        
        # æµ‹è¯•promptç»“æ„
        vace_basic = prompt_manager.get_prompt('VACE_CODE_GENERATION', 'V1_BASIC')
        assert 'You are now a professional Python programming engineer' in vace_basic
        assert 'Context from target dependency' in vace_basic
        assert 'Refactored new code' in vace_basic
        print("   âœ“ Prompt structure validation passed")
        
        print("âœ… Prompt content integrity tests passed!")
        return True
        
    except Exception as e:
        print(f"âŒ Prompt content integrity test failed: {e}")
        traceback.print_exc()
        return False

def test_new_vs_old_system():
    """æ¯”è¾ƒæ–°æ—§ç³»ç»Ÿçš„è¾“å‡º"""
    print("\nâš–ï¸  Comparing new vs old system...")
    
    try:
        # å°è¯•å¯¼å…¥æ—§ç³»ç»Ÿï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        old_system_available = True
        try:
            from benchmark.config.code.dataset2prompt import versiBCB_vace_prompt_override as old_prompt
        except ImportError:
            old_system_available = False
            print("   â„¹ï¸  Old system not available for comparison")
        
        from benchmark.config.code.dataset2prompt_refactored import versiBCB_vace_prompt_override as new_prompt
        
        if old_system_available:
            # æ¯”è¾ƒå†…å®¹
            assert isinstance(old_prompt, str), "Old prompt should be string"
            assert isinstance(new_prompt, str), "New prompt should be string"
            
            # å†…å®¹åº”è¯¥ç›¸ä¼¼ï¼ˆå…è®¸æ ¼å¼åŒ–å·®å¼‚ï¼‰
            old_words = set(old_prompt.lower().split())
            new_words = set(new_prompt.lower().split())
            common_words = old_words & new_words
            similarity = len(common_words) / max(len(old_words), len(new_words))
            
            print(f"   âœ“ Content similarity: {similarity:.2%}")
            assert similarity > 0.8, f"Content similarity too low: {similarity:.2%}"
        else:
            print("   âœ“ New system prompt loaded successfully")
        
        print("âœ… New vs old system comparison passed!")
        return True
        
    except Exception as e:
        print(f"âŒ New vs old system comparison failed: {e}")
        traceback.print_exc()
        return False

def run_all_tests():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("ğŸš€ Starting Prompt Management System Tests")
    print("=" * 60)
    
    test_results = []
    
    # è¿è¡Œæ‰€æœ‰æµ‹è¯•
    tests = [
        ("PromptManager Basic Functionality", test_prompt_manager),
        ("Backward Compatibility", test_backward_compatibility),
        ("Prompt Content Integrity", test_prompt_content_integrity),
        ("New vs Old System", test_new_vs_old_system),
    ]
    
    for test_name, test_func in tests:
        print(f"\nğŸ“‹ Running: {test_name}")
        result = test_func()
        test_results.append((test_name, result))
    
    # æ±‡æ€»ç»“æœ
    print("\n" + "=" * 60)
    print("ğŸ¯ Test Results Summary:")
    
    passed = 0
    failed = 0
    
    for test_name, result in test_results:
        status = "âœ… PASSED" if result else "âŒ FAILED"
        print(f"   {status}: {test_name}")
        if result:
            passed += 1
        else:
            failed += 1
    
    print(f"\nğŸ“Š Overall: {passed} passed, {failed} failed")
    
    if failed == 0:
        print("ğŸ‰ All tests passed! The prompt management system is working correctly.")
        return True
    else:
        print("âš ï¸  Some tests failed. Please check the system.")
        return False

if __name__ == "__main__":
    success = run_all_tests()
    sys.exit(0 if success else 1) 